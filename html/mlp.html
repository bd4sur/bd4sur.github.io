<!-- Framework Iroha -->
<!DOCTYPE html>
<html lang="zh-CN">
<head>
<meta charset="utf-8">
<link rel="stylesheet" type="text/css" href="../style/framework.css" charset="utf-8"/>
<link rel="stylesheet" type="text/css" href="../style/markdown.css" charset="utf-8"/>
<title>多层感知机（前馈神经网络）训练和推理</title>
<script src="../script/framework/jquery/jquery.min.js"></script>
<style>


</style>
</head>
<body>


<script src="../script/canvas.js"></script>
<script>

function assert(test, msg) {
    if(!test) throw msg;
}

function Tensor(shape) {
    this.shape = shape || [];
    this.ndim = this.shape.length;
    this.array =[];
    let arr_len = this.shape.reduce((pv, cv) => (pv * cv) , 1);
    for(let i = 0; i < arr_len; i++) {
        this.array.push(Math.random());
    }
}

Tensor.prototype = {
    init: function(nested_list) {
        let arr = [];
        let nesting_stack = [];
        let shape_count = [];

        //递归检查输入列表的同质性，即输入列表必须构成绝对平衡树
        function check_type(lst) {
            if(typeof(lst) === "number") {
                nesting_stack.push(true);
                let prev_length = shape_count[nesting_stack.length-1];
                if(prev_length !== undefined && prev_length !== -1)
                    return ["inhomo", NaN];
                else {
                    shape_count[nesting_stack.length-1] = -1;
                    nesting_stack.pop();
                    arr.push(lst); // 将列表元素（叶节点）以深度优先遍历顺序塞进线性表
                    return ["scalar", -1]; // 标量的长度设为-1表示比列表还短
                }
            }
            else if(lst instanceof Array) {
                nesting_stack.push(true);
                if(lst.length > 0) {
                    let prev_type = check_type(lst[0]);
                    if(prev_type[0] === "inhomo")
                        return ["inhomo", NaN];
                    for(let i = 1; i < lst.length; i++) { //从1开始
                        let ctype = check_type(lst[i]);
                        if(ctype[0] === "inhomo")
                            return ["inhomo", NaN];
                        else if(ctype[0] !== prev_type[0] || ctype[1] !== prev_type[1])
                            return ["inhomo", NaN];
                        else
                            prev_type = ctype;
                    }
                }
                let prev_length = shape_count[nesting_stack.length-1];
                if(prev_length !== undefined && prev_length !== lst.length)
                    return ["inhomo", NaN];
                else {
                    shape_count[nesting_stack.length-1] = lst.length;
                    nesting_stack.pop();
                    return ["tensor", lst.length];
                }
            }
            else return ["inhomo", NaN];
        }

        let t = check_type(nested_list);
        if(t[0] === "tensor" || t[0] === "scalar") {
            if(shape_count[shape_count.length-1] < 0)
                shape_count.pop(); //去掉叶子节点的shape（-1）
            this.shape = shape_count;
            this.ndim = this.shape.length;
            this.array = arr;
        }
        else throw "In-homo list not allowed.";
    },

    get_cell_index: function(pos) {
        assert(pos.length === this.ndim);
        let s = this.shape;
        let index = 0;
        for(let d = 0; d < this.ndim; d++) {
            pi = pos[d];
            for(let i = d + 1; i < this.ndim; i++) {
                pi = pi * s[i];
            }
            index += pi;
        }
        return index;
    },

    get_cell: function(pos) {
        assert(pos.length === this.ndim);
        let index = this.get_cell_index(pos);
        return this.array[index];
    },

    set_cell: function(pos, value) {
        assert(pos.length === this.ndim);
        let index = this.get_cell_index(pos);
        this.array[index] = value;
    },

    dot: function(b) {
        let a = this;
        // 内积
        if(a.ndim === 1 && b.ndim === 1) {
            assert(a.shape[0] === b.shape[0], "点乘的两个向量长度不同");
            let len = a.shape[0];
            let s = 0;
            for(let i= 0; i < len; i++) {
                s += a.get_cell([i]) * b.get_cell([i]);
            }
            return s;
        }
        // 矩阵乘
        else if(a.ndim === 2 && b.ndim === 2) {
            assert(a.shape[1] === b.shape[0], "相乘的两个矩阵尺寸不匹配 (n,k) @ (k,m) → (n,m)");
            let res = new Tensor([a.shape[0], b.shape[1]]);
            for(let n = 0; n < a.shape[0]; n++) {
                for(let m = 0; m < b.shape[1]; m++) {
                    let value_nm = 0;
                    for(let k = 0; k < a.shape[1]; k++) {
                        value_nm += a.get_cell([n, k]) * b.get_cell([k, m]);
                    }
                    res.set_cell([n, m], value_nm);
                }
            }
            return res;
        }
        else {
            throw "Not implemented.";
        }
    },

    unary_pointwise: function(unary_op) {
        let res = new Tensor(this.shape);
        for(let i = 0; i < res.array.length; i++) {
            res.array[i] = unary_op(this.array[i]);
        }
        return res;
    },

    binary_pointwise: function(b, binary_op) {
        let a = this;
        assert(a.ndim === b.ndim, "逐点运算两个tensor的形状不匹配");
        assert(a.shape.reduce(
            (pv, cv, ci) => (pv && (cv === b.shape[ci])), true),
            "逐点运算两个tensor的形状不匹配");
        let res = new Tensor(a.shape);
        for(let i = 0; i < res.array.length; i++) {
            res.array[i] = binary_op(a.array[i], b.array[i]);
        }
        return res;
    },

    T: function() { //转置
        assert(this.ndim === 2, "只支持矩阵（2维张量）的转置");
        let res = new Tensor([this.shape[1], this.shape[0]]);
        for(let m = 0; m < this.shape[0]; m++) {
            for(let n = 0; n < this.shape[1]; n++) {
                let v = this.get_cell([m, n]);
                res.set_cell([n, m], v);
            }
        }
        return res;
    },





    show: function() {
        let arr_count = 0;
        function build_tree(shape, arr) {
            if(shape.length === 1) {
                let leaf = [];
                for(let i = 0; i < shape[0]; i++) {
                    leaf.push(arr[arr_count]);
                    arr_count++;
                }
                return leaf;
            }
            else {
                let tree = [];
                for(let i = 0; i < shape[0]; i++) {
                    tree.push(build_tree(shape.slice(1), arr));
                }
                return tree;
            }
        }
        let tree = build_tree(this.shape, this.array);
        console.log(JSON.stringify(tree, null, 0));
    }

};

// Unit tests

const ReLU = (x) => ((x >= 0) ? x : 0);
const tanh = (x) => Math.tanh(x);

let x = new Tensor(); // (n=3, bs=2) bs=2个列向量，每个列向量n=3维，构成一个batch
let W = new Tensor(); // (m=5, n=3)  输入层n=3维，隐藏层m=5维
let b = new Tensor(); // (bs=2, m=5) 偏置，是bs=2个m=5维的行向量，转置成2个列向量

x.init([[1, 2],
        [2, 3],
        [3, 4]]); console.log("x = "); x.show();

W.init([[1, 1, 4],
        [5, 1, 4],
        [1, 1, 4],
        [5, 1, 4],
        [8, 1, 0]]); console.log("W = "); W.show();

b.init([[1, 1, 4, 5, 1],
        [1, 1, 4, 5, 1]]); console.log("b = "); b.show();

let z = W.dot(x).binary_pointwise(b.T(), (x,y)=>(x+y));
console.log("z = "); z.show();

let y = z.unary_pointwise(ReLU);
console.log("y = ");   y.show();
console.log("y.T = "); y.T().show();


/*
# Python 测试代码
import numpy as np
x = np.array([ [1, 2], [2, 3], [3, 4] ])
W = np.array([ [1, 1, 4], [5, 1, 4], [1, 1, 4], [5, 1, 4], [8, 1, 0] ])
b = np.array([ [1, 1, 4, 5, 1], [1, 1, 4, 5, 1] ])
z = W @ x + b.T
y = np.maximum(z, 0) # ReLU
print(y)
*/

</script>
</body>
</html>