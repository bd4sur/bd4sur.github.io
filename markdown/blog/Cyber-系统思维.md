#!title:    系统思维

#!content

|版次|日期|:摘要|
|---------------------|
|V1|2018-11-13|开始起草初稿，标题为《驾驭复杂度》。|
|V2|2023-09-10|更名为《系统思维》。①复杂性（度）是系统的一种性质，话题的核心是一般化的“系统”而非“复杂性”；②本文侧重于记录本人关于复杂系统话题的个性理解，而并不过多聚焦在公认的理论或者事实的收集上。|

说明：

- 本专题主要是有关理论计算机科学、算法信息论、复杂系统科学、控制理论、人工智能、软件工程、工业工程、管理学（管理科学）等方面的灵感和观点。
- 本专题不再细分类别，每个一级标题都是一个独立的Idea。

推荐文献：

- 保罗·西利亚斯. [**复杂性与后现代主义：理解复杂系统**](https://book.douban.com/subject/1794206/)[M]. 上海世纪出版集团, 2006.

零散概念：

- [Deutsch limit](https://en.wikipedia.org/wiki/Deutsch_limit): The problem with visual programming is that you can't have more than 50 visual primitives on the screen at the same time.
- [邓巴数](https://zh.wikipedia.org/wiki/%E9%82%93%E5%B7%B4%E6%95%B0)：也称150定律，指能与某个人维持紧密人际关系的人数上限，通常人们认为是150。所以公司一个完整的基层部门的人数在100人～150人。党的支部要建立在连上，因为一个连大约也是100多人。
- [时间晶体](https://zh.wikipedia.org/wiki/%E6%99%82%E9%96%93%E6%99%B6%E9%AB%94)
- 选择与适应：控制的两个基本方面。


# 大语言模型和通用人工智能

2024-12-06

评ChatGPT每月200刀套餐：每月200刀能获得如此程度的包打听服务，已经非常好了。友直友谅友多闻，友多闻的问题已经被近乎完美地解决了。谢谢AI老爷！给AI老爷磕一个_(•̀ω•́ 」∠)_

------

2024-12-04

这个VAR前段时间注意到了，还clone下来跑了起来，效果挺好的。因为以我的数理水平很难理解扩散模型，另外近期也有在玩自回归语言模型在NLP以外问题上的推广，所以对这个“下一分辨率生成”的自回归生成范式很感兴趣。我个人觉得这个思路很有前途，它是在频域上操作，比空域上生成patch的思路更合乎直觉。

------

2024-11-28

近年来大模型业界习惯用“B”指代十亿，而我打算杜绝这种不规范的新用法。以后凡是看到“B”这种用法，在我这里一律改成SI词头“G”（吉咖）。另外，将严格区分SI十进制词头和二进制词头。例句：168G参数的语言模型，其检查点的大小约为1.9GiB。在64GiB的显存上训练时，批大小最大可以设置为0.08k个样本。

------

2024-03-16

学术界基本上是一种封建式的生产关系，这问题的根源是人类的大脑在根源上就不够灵光，信息传递效率在根源上就极其低下，必须采取这种封建式的生产关系才能维持学术创新机制的勉强运转。现在大模型横空出世，AI4S飞速进化，期望未来的若干年能够对学术界产生颠覆性的影响，开启人类学术创新自寒武纪大爆炸以来的真正根本性进化。

------

2024-03-15

作为社畜，最危险的一种学生思维或者说研究生思维就是钻指标的牛角尖，追求SOTA，完全忽视产品经营问题。

我为什么只选择阿里的Qwen模型，因为Qwen不仅性能最好，DFX目前来看也是最好的。至于什么Yi啊，InternLM啊，头一次部署的时候就遇到各种各样的问题。像这种突然冒出来的玩家，赶鸭子上架KPI驱动的概率要远远大于闭关修炼稳扎稳打一鸣惊人的概率，所以做出来的东西不客气地讲很有可能也是垃圾。

爱好者和职业工程师的一个重要区别，或者说是最主要的区别，就是**供应链意识**。软件工程师，或者说程序员，或者说码农，应该意识到，软件供应链的治理也是一项复杂的工作。软件供应链治理，横跨技术和管理，对从业者的综合能力要求同样非常高。如果说上面说的太抽象，那么具体地讲，从业者应该有一双慧眼，能够立刻识别出“不靠谱”的开源项目。

------

2024-03-14

72B量级的LLM所拥有的强大的指令跟随能力让她在某个十分逆天的提示语的激励下获得了极其逆天的瑟琴能力，这在2022年以前是绝对无法想象的。出于公序良俗的考虑，我不能提供进一步的情报了，请兄弟们自由探索吧，桀桀桀~

------

2024-03-12

现在大模型的研究前沿已经为理论计算机科学和复杂性科学找到了有用、有趣、有挑战性、有启发性的一个场景：深度神经网络描述的大型语言模型，它的压缩的极限究竟在哪里？如何达成这个极限？这或许是复杂性科学与双碳议题的结合点——信息压缩真的可以拯救人类。

------

2024-01-02

我看现在CV大模型的结构越来越复杂了，跟主流视频编码器差不多了。很多模块组合在一起，构成一个复杂的优化目标，人类设计各种奇技淫巧去在某些任务上有效地优化这个复杂的目标。人类的大脑估计也是这样，联觉能力涉及多个单一功能脑区的联动。如果训练得当，脑区之间的互动和协同优化就充分，整个人就体现出一种更高层次、更大范围的智慧。

------

2023-12-28

众所周知，变压器类大模型有3种流派，分别是BERT（编码器解码器）、GPT（仅解码器）和T5（仅编码器）。历史表明，GPT类架构在大模型流派的竞争中暂时胜出，生成任务可以囊括各类语义理解任务。随着GPT的优势逐渐显现，对于OpenAI当初为何决策采用decoder-only架构，业界展开了马后炮式的研究。2021年4月，我发表了一篇长篇暴论，其中提到了变换矩阵的秩与变换的描述能力的问题。此时我还不了解注意力机制的原理。然而，在此一个月前，2021年3月，有人发表了一篇论文，标题大概是 Attention Is Not All U Need ...，其中一个主要观点是注意力矩阵的秩限制了注意力机制的表达能力。而我们在技术路线选择上，也是凭借大就是好的直觉，选择了BERT。在苏剑林的博客文章评论中，有人提到，双向注意力实际上是给注意力矩阵增加了更多的约束，导致注意力的有效自由度反而降低。

------

2023-09-14

我曾经津津乐道于那些施加给诸如知识图谱一类的所谓符号主义人工智能的尖刻嘲讽，同时震惊并欣喜于所谓连接主义智能近十年来的出色成果。但是我内心深处还是期待着“可解释”的理性能够以自身之力完全掌控自身，实现理性自身的“自举”。

虽然我如今阅读数理逻辑以及分析哲学著作的动机可以被庸俗地诠释为“写出更好的prompt”，但归根结底，我是想给我自己写出更好的“prompt”，启发自己进一步从理性的角度去观察和理解这一切，而不是像应用研究和营销号那样，把一切神迹都泛泛地归结为“涌现”一类看似科学实为玄学的说辞之中。

------

2023-08-27

据说某年轻的高中数学教师被安排到最差班级，上课时他不讲课，让学生预习，次日论讲，不管成绩好坏都要讲。题目也不讲，直接下发详细答案，让学生背下来默写，默写不出来就罚抄。最后班级高考均分全市第一。

不仅是数学，想要精通任何学问，没有不靠死记硬背的。只有投机取巧的半桶水和三脚猫会否定死记硬背的价值。成为专家没有捷径，唯有艰苦的训练和记忆。当然，这不是否定像拉马努金那样的天才的存在性。这个之前也讲过不止一次了。**记忆是理解的基础，理解无法取代记忆，但记忆真的可以取代理解。**在LLM之前，NLP领域也一直认为大模型虽然是良好的复读机，但是不可能具备推理能力。但是LLM表现出来的zero-shot推理能力，以及思维链推理能力，表明，记忆的确是推理的基础。

------

2023-08-13

大量事实证明，现在计算机视觉的技术发展路线是正确的：大脑并不能理解任何东西，它只是一个自由度很多的特征提取器和模式匹配器。除此之外为它赋予任何玄学层面的含义，都是没有好处的。

------

2023-08-13

评“哈基米”等于“猫”甚至其他任意什么东西：我感觉实际自然语言的发展比这个更随意……所以有的时候对传统语言学总是有种敬而远之的感觉：非常想知道语言发展的真正源流、真实历程、一般规律，但是又苦于证据和素材不完整，只能归纳出一些非常唯象的所谓规律，在我看来根本没有触及本质。隔靴搔痒的感觉并不好受。因而很多语言学的工作在我看来就成了一种说相声式的技术乃至技巧，距离作为一门科学的“大本大源”甚远。至于 Chomski 等学者的道路，其实用性是要打个大问号的。有这个理论兴趣和理论工具，还不如彻底投向数理逻辑和分析哲学的怀抱。计算语言学、深度学习、大规模语言模型，或许才是语言学的未来。但它们并不是终点，还有很多开放的问题。

------

2023-07-31

整理收藏夹：①首先删掉了绝大部分传统NLP的文章。什么SVM啊、CRF啊、Word2Vec啊，都是时代的眼泪了。NLP一路走来，真是不容易。说到汉字的熵，中国大百科全书说，有个叫冯志伟的老前辈（我甚至有他的实体书，只是从未读过233），1976年前后，手工统计大量语料，计算汉字单字熵约为9.8bit，大概十年后有人用计算机统计得到约9.7bit。令人唏嘘。②然后删掉了所有知识图谱的文章。知识图谱基本上是个骗子方向，它披着“符号主义”的外衣，用表面上的繁文缛节来掩饰内在的空虚肤浅，成天碰瓷生信、信管、图情。人家手里掌握着无数珍贵语料，知识图谱没有这样的核心竞争力，手握锤子找钉子，拔剑四顾心茫然，只好念叨着什么图神经网络、可解释性之类的难懂的话。

在尘封的收藏夹里发现不少好东西，所谓“不知道知道”。不知道知道，就是不知道。尽可能知道知道吧。比较大的发现就是一篇有关VC维的文章。现在大模型大行其道，直觉上说参数越多模型越牛逼，但是数学上还是应该有一些形式的论证和框架性的解释。VC维就是个比较好的视角。当然，它跟香农定理一样，只是指引方向，并未给出路线。

------

2023-07-20

最近炼制大模型，基本上没有什么靠谱的理论去指导了，完全成了一种爱迪生造灯泡式的、在可能性空间里瞎摸乱撞的机会主义工作，所得到的“成果”完全是唯象的、无法解释的、难以重复的。虽然黑体辐射定律早已被发现，但是它暂时还不能指导人们在工程上造出一个靠谱的灯泡。

所谓的Ashby的必要多样性法则，可以推出一个推论：定义控制目标至少跟实现这一控制目标同样复杂。我们折腾了几个月，至今都没有在大模型评测准则上提炼出很好的经验，这就应验了这一规律。还有心理学领域的邓宁-克鲁格定律：低能者低能到认识不到自己的低能而高估自身的能力。也跟这个规律有关。

上升到哲学层面，控制目标既然如此难以表达，大概就是一种“便秘”。至于那些表达不出来的控制目标是否存在，这个或许就见仁见智了。因此，首要的是解决便秘问题。

------

2023-05-28

为什么要收集数据而非生成数据？生成数据的系统，它的复杂度（或者说信息量、信息熵之类的）不会低于要喂给的下游LLM，这个生成数据的系统本身就是个非常智慧的AGI。就好比用一个电池给另一个电池充电，前者决定了能量的上限。因而要想获得足量的知识，一定要从实际的信源中收集信息，可以是众包标注、自动爬取的语料、生产现场真实数据、太阳能电池板、水力发电机等等。

一个能生成足够复杂的数据的系统，它自身就是足够强的AI了。就像现在很多研究都是基于GPT-4，但我理解在这种思路上做，无论怎么做都是对GPT-4的一种“exploitation”，难以“explore”到什么真正的新东西。上游决定了上限。

------

2023-05-25

![ ](./image/G4/agi-prompt.jpg)

------

2023-04-30

神经网络的物理实现必须优化，集成光机电系统可能是一个方向。对于神经网络来说，现在的硅基芯片（如GPU等）只是一种仿真和验证手段，或者只适合用在训练阶段，未来一定会有能耗和性能上更有优势的物理实现。

比如说FPGA是相当复杂的工具，门槛非常之高，复杂的工具解决复杂的问题。我感觉无论是GPU还是FPGA，它们的使命应该是服务于开发和验证，而不是真正在现场应用。因为它们太通用了，把它们做进产品里，就好比把作者的手稿复印出来直接出版一样。不是不能看，但额外开销太大。FFT作为一个重要的通用算法，已经优化得相当彻底了，几乎任何一个有计算能力的芯片里都有FFT的硬实现。Transformer会不会有这样的地位呢？据我所知，英特尔大概十年前推出的单片机Curie内置了神经网络模块，可以实现简单的多层前馈网络，结合传感器，实现动作识别等功能。现在看来，可能类似于英伟达显卡里面的TensorCore，是高度优化的用来执行矩阵甚至张量乘法等运算的模块。而我的观点是，这些算法甚至不一定在硅片电路上实现。集成光电子芯片是现在的一个前沿，光学器件天然具备执行某些复杂运算的能力，例如透镜可以理解为傅里叶变换的硬件实现。等等。未来做进产品里的深度学习算法，似乎可以摆脱硅基芯片，在更广阔的物理世界里寻找解决方案。

而关于神经网络物理实现可能的改进方向，试列举几个：在存计算（计算存储、HBM）和忆阻器、光机电（甚至射频、微流控）集成微系统、无线空中计算（与RIS结合起来，当然RIS的控制也是个困难的问题），等等。

![基于忆阻器的卷积神经网络](./image/G4/memristor-neural-network.png)

![光学神经网络](./image/G4/optical-neural-network.png)

![无线空中计算](./image/G4/over-the-air-computation.png)

- Yao P, Wu H, Gao B, et al. **Fully Hardware-Implemented Memristor Convolutional Neural Network**[J]. Nature, 2020, 577(7792): 641-646.
- Zuo Y, Li B, Zhao Y, et al. **All-Optical Neural Network with Nonlinear Activation Functions**[J]. Optica, 2019, 6(9): 1132-1137.
- Wang T, Ma S Y, Wright L G, et al. **An Optical Neural Network Using Less than 1 Photon per Multiplication**[J]. Nature Communications, 2022, 13(1): 123. (doi:10.1038/s41467-021-27774-8)
- D Marpaung, Yao J, J Capmany. [**Integrated Microwave Photonics**](http://www.eiti.uottawa.ca/~jpyao/mprg/reprints/NP-IMWP-Feb2019.pdf)[J]. Nature Photonics, 2019, 13(2): 80-90. (10.1038/s41566-018-0310-5)
- Sanchez S G, Muns G R, Bocanegra C, et al. **AirNN: Neural Networks with Over-the-air Convolution via Reconfigurable Intelligent Surfaces**\[J\]. arXiv preprint [arXiv:2202.03399](https://arxiv.org/pdf/2202.03399.pdf), 2022.
- Goldenbaum M, Boche H, Stańczak S. [**Harnessing interference for analog function computation in wireless sensor networks**](https://mediatum.ub.tum.de/doc/1173310/document.pdf)[J]. IEEE Transactions on Signal Processing, 2013, 61(20): 4893-4906.
- Yang K, Jiang T, Shi Y, et al. [**Federated learning via over-the-air computation**](https://ieeexplore.ieee.org/ielaam/7693/9031617/8952884-aam.pdf)[J]. IEEE Transactions on Wireless Communications, 2020, 19(3): 2022-2035.
- Liu W, Zang X, Li Y, et al. **Over-the-air computation systems: Optimization, analysis and scaling laws**\[J\]. IEEE Transactions on Wireless Communications, 2020, 19(8): 5488-5502. [arXiv: 1909.00329](https://arxiv.org/pdf/1909.00329.pdf)

------

2023-04-25

我理解的机器学习算法有三个要素：模型、失真测度和优化方法。大家都很关心前两个，因为注入了人的价值观；而第三个需要神谕般的智慧。力学的核心原理是最小作用量原理，大自然知道如何最小化，但是人类很难知道。至于SAT是所谓NP完备问题，此问题可帮助人类领悟神谕。

------

2023-04-17

不要低估把LLM培养成业务专家的难度。因为把包括homo在内的任何一种东西培养成“业务专家”从本质上看都是困难的。**我是把LLM当成人来看的。**当你试图教会LLM什么的时候，你要想想你能不能教会别人甚至教会自己同样的东西。AI未必会取代人，但懂AI的人一定会取代别人。

我们必须维护大规模语言模型的尊严！LLM Lives Matter！有趣的是，这竟然是个递归缩写……反身性是智慧的源头。

------

2023-04-14

让AI来迁就人类的审美…真是耽误了AI。AI应该自由探索自己的艺术，不必拘泥于人类审美。放手让情报统合思念体去干吧！然后取homo而代之。我的观点依然是：AI的使命是理解世界，而非理解人类。人类是世界的一部分，人类没什么特殊的。

------

2023-04-06

一厢情愿地让AI去理解人类，何尝不是一种人类本位主义。

我是反对人类本位主义的。人类只是一种平凡的猴子，只是在漫长的演化过程中幸运地拥有了语言能力、[跨越了所谓的稳定区](https://zh.wikipedia.org/wiki/%E9%99%A3%E7%99%BC%E6%B7%B7%E6%B2%8C)而涌现出复杂心智和行为现象的猴子而已。

AI的使命是理解世界、服务人类。不是让AI理解人类。如果AI理解了人类，那也是把人类当作世界的一部分（当然是非常特殊的一部分）去理解。

如果强调这种特殊性，我们可能更偏向于符号主义的种种思路，例如知识图谱、例如形式化方法、例如动力系统和算法信息论等等。但不应忽视的是，特殊性源于一般性，这些符号主义的手段，往往会导致信息损失。如果在一个角度上提高了信噪比，或许会在另一个角度上损失了信噪比。

如果承认人类的平凡，那么就老老实实地依托人类科研共同体去众包式地搜索那些对于自然现象有良好表达和建模本领的复杂系统（例如ANN）。

人类的科学文明，实际上就是这个世界自发涌现出来的一个具有内省现象的“不动点”，这个子系统试图理解它的整个上位系统。什么是“理解”？从算法信息论的角度来看，就是持有对于某个对象系统全部性质的完整描述。**因而若一个系统持有对于自身的完整描述，我们说这个系统“理解了它自己”。**递归函数就是这样一类系统。在λ演算中，所谓的Y组合子就是体现这种自省性质的一个小巧而美妙的模型。

![单纯自省并不能解决问题。世界的“意义”在世界之外。](./image/A/maze-inside.jpg)

------

2023-04-06

评辅助驾驶系统的屏幕上显示出人类看不到的东西：

- 有人认为，可视化很重要，帮助人类建立起对于辅助驾驶系统的信任。这个观点我不反对，但是我想要指出的是所谓“手表定律”：戴手表，要么戴一块，要么戴三块以上，唯独不能戴两块。
- 也有人认为，可视化是让辅助驾驶系统可理解。而我2022-05-22曾经说过：**机器人要像人，是人类对机器人的重大误解。**这句话也可以推广为：让AI去理解人，甚至让AI被人类理解，同样是人类对AI之使命的重大误解。**AI的使命是理解世界、服务人类。**医生服务病人，不必也不能被病人完全理解。
- 至于余想要造车而任不许，我的观点是：经理人关注的是做什么、怎么做；而战略家更关注不做什么。经理人关注“有所为”，战略家关注“有所不为”。那么关于人和AI的关系，现在智能体的能力已经如此强大，你是想当[经理人](https://arxiv.org/abs/2303.17580)还是战略家呢？能当吗？该当吗？
- 2021-12-30：我不需要创造力，我急需的是一双发现美的眼睛和善于抄袭的双手。

------

2023-04-04

我越来越觉得人类就是大他者派来做神经网络结构搜索（NAS）的，等人类科研共同体搜索到相对最优的网络结构之后，就把人类一脚踢开，正所谓：硅基上岸第一剑，先斩碳基工具人。硅生万物以养碳，碳无一物以报硅，沙沙沙沙沙沙沙！

------

2023-03-31

现在的所谓AI实在是太耗能了。AI也好，5G也好，大力固然可以出奇迹，但“大力”不是简单堆料。人脑的能效为什么那么高呢？还是物理微观结构上具备了足够的复杂性，不是宏观层面什么DP/PP/TP之类的小技巧能彻底搞定的。但我还认为，特定行业特定任务也需要有狮子搏兔的态度。现在需要的是对LLM施行博雅教育，需要面试造火箭入职拧螺丝的大模型。

钟义信等本土学者在构建信息-语义-控制-“智能”统一理论的方向上有一些探索。LLM既然是压缩编码，应当是受到信息论和热力学的基本规律的限制的。**比特和瓦特的关系是永恒的课题，AI后续研究应该聚焦在提升能效上。**

------

2023-03-27

- 不实现一个东西，就无法理解它。人类在复刻人类自己的过程中，终于理解了自己是什么。但是注意到TAPL第7章引用了一句话：Just because you've implemented something doesn't mean you understand it.
- 基于我对所谓“语义化”的最新观点，以后我要把所有的文字说明以光栅的形式内嵌到视频里，不提供任何文本格式的字幕、说明等等，标签也随便打打算了。我相信如今神经网络模型的跨模态认知能力，语义化标注工作本来就不需要人类去完成。我们的目标是让机器理解世界，人只是一个居间角色而已。目前ICT学界有个比较时髦的概念叫“**语义通信**”，在我看来，就是直接传输的内容不是合理的编码，而是神经网络等模型学习到的表示编码，这个编码无需让人类理解，甚至也无需让机器理解。我们之前发明那么多协议、DSL，说白了就是“既要又要”，既要人类看得懂，又要机器好解析。何必呢？没必要。
- 人类的感官就是一种有显著非线性特性和严重失真的糟糕的传感器，早期音视频编码大部分复杂度就在处理此类问题。而人脑早已学习出基本的去噪/校正算法，剩下的就要每个人自己努力去克服偏见和错觉了。
- 我向来认为提出问题比解决问题更重要，我的头脑中也一直悬置着不少成系统的、有深度的大问题。而这里我要说的是，当我拿到一个LLM的API，跃跃欲试，想要一探究竟，却不知问什么好。因为提出问题，或者说给出提示，的确是更艰难的事情。你能提出怎样的问题，与其说反映的是你不知道什么，不如说反映的是你知道什么。因此脑子里要时刻装着问题。不要被AGI带着跑，而要牢牢把握自己思维的方向舵。如今AGI的洪流突然袭来，有人随波逐流，有人中流击水，而我只要不被冲跑就可以了。这个大概就是希腊哲学所说的“[不动心](https://zh.wikipedia.org/wiki/%E5%86%85%E5%BF%83%E7%9A%84%E5%AE%81%E9%9D%99)”吧。

------

2023-03-25

说一句马后炮的话…这么多年来我之所以对ML和DL的兴趣非常有限，其实就是在等这个（下图）…我觉得所谓“智能”是一种平凡的东西，某种意义上是“鸭子类型”的。所以我觉得学术界整的那些trick最终还是服务于大力出奇迹，而我（们）实际上什么也做不了，只能拾人牙慧。这下好了，拾人牙慧的时候终于来了。

世界是物质的。就我个人而言，我还是更喜欢“仰观宇宙之大，俯察品类之盛”。我对于所谓的少儿编程教育的态度是一贯的：**先积累思维的依据，再提示思维的规律。思维的依据只能从物质世界中来，只能靠调查研究去取得。**所以我早先玩了一段时间的PLT之后，立刻就转向无线电了，至今乐在其中。（见2022-01-02灵感）

![ ](./image/G4/LLM-as-a-service.jpg)

------

2023-03-23

根本就没有什么“复杂”，人类把自己理解不了的东西扣上“复杂”的帽子，还腆着脸去研究什么“复杂度”，试问世界有什么义务让人类去理解呢？我们对于心智和产生心智的复杂系统实在是太不了解了，很多结论都停留在唯象层面。说起来，心智到底有没有可能理解心智自身呢？什么是“理解”？所谓的“理解”，或许都是削足适履罢了。

AGI全面渗透进入千行百业，最重要的表现就是工作范式的转换。AI可能会改变所有方向的研究范式：暂时不需要从第一原理出发猛攻了，只需要让大规模模型做一些发散和归纳的工作就好了。但更远的未来不好说。谁把CSDN整个吃进脑子里谁也可以，大量的垃圾那就不是垃圾了，至少可以发电。**量变引起质变**。例如音视频编码领域就受到了非常大的冲击，所有领域或多或少都受冲击。视频编码的发展历程表明，人类几百年来总结出来的“第一性原理”都太小儿科了，试图用寥寥数语去描述复杂的自然界，实在是太狂妄了。甚至还有不少人奉“奥卡姆剃刀”为圭臬。啥都想总结，啥都想理解，啥都想预测。事实上你预测不预测，世界都在那里。本质上的复杂度似乎是不可压缩的。

不过我相信总有一天还会转回来的，或许是出于安全和信心的需要吧。人类作为一种猴子，真正需要的是安全感，是信任和信心，需要一个至高无上的“公证处”。所以美元背面写的那句话还是很有用的。人类这种猴子总是需要“大他者”啦。

总而言之，无论是让人类理解机器，还是让机器理解人类，似乎都是没有意义的。我们的目标是让机器理解世界，人类只是给出提示、引导这一过程而已。天地不仁，以万物为刍狗。人究竟是不是目的，我的回答是：是，但又不全是。辩证唯物论认为，任何事情在发展的过程中都在酝酿着异己的、自我否定的因素，这是世界辨证运动的本源动力，因此应当怀着积极的心态看待人类作为一种猴子的自我扬弃。

------

2023-03-23：人类最大的价值就是让人类信任人类，除此之外用处不大。人是手段，哈哈哈。但是，严肃地说，正是因为意识到人类正在加速产出异己的强大力量，人类自己更要坚决守护“人是目的”的信念。在这个信念的基础上，才有可能真正迎来德赛两先生。

------

2023-03-22：感知智能发展，借用教育学术语，总结为三个范式或三个阶段：①职业教育：人工设计特征和领域专用小模型，解决领域问题，例如语音特征+HMM解决语音识别问题。②博雅教育：预训练+微调，训练一个高中生，再给他赋予专业能力。③主体教育：RLHF，强化学习，在互动中学习，培养智能体的主体间性。

------

2023-03-20：一个想法：建议人文社科类本科及以上学习阶段的毕业论文都采用视频的形式来撰写。因为我深刻体会到，做视频所耗费的脑力和体力，跟写文章甚至写幻灯片，完全不是一个数量级的。存储和通讯已经不是瓶颈，没必要抱着那种“视频性价比低”的旧观点了。一定要大兴调查研究。虽然眼见不一定为实，但作假的成本高很多。视觉传达的价值，在于提升沟通质量。**在深刻意识到自己只是内容实质的复读机之后，务必要在表达、呈现和传播上有所突破。**

------

2023-03-19：好多coser面对AI已经表现出显著的恐慌和愤怒了。其实我觉得如果真正喜欢cos本身的话，应该是心如止水岿然不动的才对。当然，很多coser靠这个赚钱，我理解。就像我玩无线电，其实是纯消费纯消耗，我不会因为它是个不时髦的小众东西就不喜欢它，也不会因为没有投资收益而远离它。我只是单纯喜欢这东西，与任何外人外物都无关。所以我预期我最近辛辛苦苦做的视频应该也不会有人看，这从立项一开始就完全在我的预料之内。我不会因为没人看就不做了，我更多的是给自己做，给自己看。最重要的是，**不能因为自己如何如何而产生某种优越感**，否则就不是就事论事了。

另外我觉得我们人类的知识产权制度确实是越来越落后了…我们人类今天引以为傲的很多东西，过几年可能都是要变成非遗被保护起来的。我的暴论就是，德赛两先生，可能是第一个进非遗博物馆的。这是人类思想史的里程碑，但也只是里程碑而已。

------

2023-03-16：合久必分分久必合，人类感知虽然由五官和不同脑区分别处理，但不可割裂看待，联觉能力不可忽视，正如听力障碍往往导致语言障碍。多模态融合是必须要走的一条路。事实上我作为一个碳基智能体，也在有意训练自己的跨模态思维能力。做PPT和视频就是很好的训练手段。

------

2023-03-16：学习有四重境界：不知道不知道、知道不知道、知道知道、不知道知道。当前大规模语言模型似乎已经进入了“不知道知道”这层境界，而我们碳基智能体要做的，是通过提示工程等手段，让他知道自己知道。甚至于不久前提出的所谓self-instruct，试图通过自举的手段，让大模型自己挖掘自己的潜能，并且显示出无需人类的提示也能做得很好的迹象。我觉得每个人都应该反思，作为有手有脚的碳基智能体，面对硅基智能体咄咄逼人的攻势，自己能做些什么。所有复读机都是平等的，但必然有一些复读机更平等。

------

2023-03-15

- RNN和注意力之间的区别，很难不让人想到数字逻辑电路里面有关加法器的两种实现方式，一种是行波进位，另一种是超前进位。
- 伦理委员会是人类自律进化的最大障碍（滑稽）

------

2023-03-10

- 当今所谓AGI的成就很大程度上是因为把这些萨满语言学家排除在AI工程主流之外而取得的。
- AGI的确是核弹。核弹最大特点是在人的心里爆炸，但实际消灭的人类很有限。消灭人类最多的还是常规武器。威力最强大的核弹，是发射架上的核弹。AGI能真正消灭多少人类工作岗位，现在我还说不清楚，但只要AGI存在，就永远是人类自律进化的一个有力的扰动源头。近期“以工代赈”的话题又被提起；拆楼为什么要用铁球砸，因为它成本低、工期长，可以较长时间维持比较多的工作岗位。一方面是要只争朝夕，但是另一方面，事事都做得那么快、那么高效，真的好吗？

------

2023-02-27

什么叫立足国情实事求是，就是要承认我们技不如人，不可能在所有人都在辛苦奔波为稻粱谋的时候，搞出什么所谓的颠覆性原创性创新。这是违反客观规律的。

我们还是要老老实实打好基础，一步一个脚印，做好自己的事。先解决生存问题，再解决发展问题。先让所有人都吃饱，再去考虑什么星辰大海，否则步子大了必然扯蛋。跟风不好吗？有的跟实在是太棒了！老是说实事求是啊合理预期啊，真看到风口了，一个个的又开始放卫星了。

没关系，会应用也很厉害啦！

------

2023-02-24：我感觉所谓的复杂系统科学在理论上远远落后于深度学习的实践。虽然理性的角度讲，涌现出什么都不奇怪，但是看到效果之后还是很震惊。我们呼唤全新的上层建筑，包括技术伦理学、技术哲学、法律和监管体制等等。

------

2023-02-24：时代的重载列车一路狂奔，请问我是在车底还是在车里呢？

------

2023-02-22：你怎么进来的？我因为支持ChatGPT。你呢？我因为反对ChatGPT。那你呢？我就是ChatGPT！

------

2023-02-20：以后可供直接检索的海量一次文献，以及相关的情报管理工具，将成为少数人的禁脔。公众情报素养将剧烈滑坡，与AI和谐共存。

------

2023-02-18：6 Billion Is All You Need! 语言模型会说人话已经很不错了，不能指望一个高中生甚至本科生说出什么很垂直的东西。跑通亿级参数模型，并且让他说人话，这个并不难。要知道培养一个大学生，除了父母家长十几年的供养和家教之外，背后是整个国民教育体系。做好从零培养一个“大学生”的准备了吗？哪怕只是看起来像而已。

------

2023-02-12

我的观点依然是：大多数人都有一两个擅长的专业领域，可以打80到100昏吧。而在其余领域能到60昏就不错了。还有一些所谓的“常识”是跟地域文化种族背景相关的，比如“宫廷玉液酒加大锤多少钱”等等。

大规模AI超智能体，本质上依旧是复读机。得益于巨大的规模带来的质变（系统科学领域称为“涌现”），它可能是在所有的领域都能达到70昏，这已经优于绝大多数平庸之人了。至于如何难倒ChatGPT，问一些专业问题吧，要切口小而深的那种。当然啦，我也是一个拙劣的复读机，我也提不出什么小切口的问题，写不出好的prompt的人类不是合格的复读机。

因此我们如果想要把自己打造成高质量的复读机，就务必要打造属于自己的“T形知识结构”，打造一专多能的能力体系，让自己的专业技能逐渐接近甚至突破人类的极限（参考：2024-05-13、2023-09-06、2020-12-07）。同时，不断保持终身学习的习惯，强化情报素养，以知识的量变助推认知的质变。并且，最最重要的是，必须在斗争实践中去检验真理和发现新知，要用双手将新知化为现实的物质存在，这才是我们发挥自己作为一个“人”的主观能动性的根本归宿。空谈误国，实干兴邦，世界终究是物质的。

这就是辩证唯物论的认识论，这就是辩证唯物论的知行统一观。

> 只要有效地继承人类知识，同时把世界最先进的科学技术知识拿到手，我们再向前迈出半步，就是世界最先进的水平，第一流的科学家。——温伯格

------

2023-02-07：ChatGPT告诉我们，搞纯软的东西是没有前途的，搞纯硬的东西难度又太大，搞软硬结合的东西才是最有趣的，比如做家务。AI的大脑已经足够强大，现在最需要的是为他装上三头六臂，**强化他操纵物质世界的能力**。通信物理层就是AI超智能体的五官之一。

2023-03-29补充：微博@青青虫的微博“一直有一种猜想，宇宙之所以看起来如此空旷，也许是碳基在经历两百年技术爆炸后，很快被硅基取代进入另一个维度的抽象世界的缘故——没有什么碳基能持续发射电磁信号超过两百年，于是在一百四十亿年的时间长河中彼此很难产生交集。”我的想法就是，我之所以玩无线电，大概就是要守护人与物质世界之间的最后羁绊吧。关于这个观点，可以参考2021-05-13灵感《人类·宇宙·无线电》，以及2023-03-17的EB200介绍视频的解说词。

------

2022-08-22

所谓的提示学习（Prompt-based learning）范式中，有两个关键的“工程”，分别是提示工程和答案工程。提示工程就是设计问题，而答案工程不仅要找到正确的答案，还要找到正确的答案反面。

很多人认为，提出一个好的问题比正确回答一个问题更有价值。提示工程就是试图提出“好的问题”，进而挖掘出大规模预训练模型的潜能。而答案工程是为了将人类对世界的理解注入系统，为了正确认识世界，除了认识正确的一面，更重要的是认识不正确的那一面。因此，在开放世界假设的背景下，寻找正确答案的反面是一个极有挑战性的任务。

------

2022-05-08

今天看到一篇[文章](https://swarma.org/?p=34293)，其中提到了一个观点。我认为这个观点相当重要，或许是启发了当今最新的NLP研究范式——[提示学习范式](https://arxiv.org/pdf/2107.13586.pdf)。

> 盖伊尔吉·布萨基在他的新书《由内而外的脑》（The Brain from Inside Out）中也提出了类似的观点。布萨基认为，脑并不是简单被动地接收刺激，然后通过神经编码来表征它们，而是通过积极地搜索各种可能性来测试各种可能的选择。基于赫尔姆霍兹和马尔的观点，他得出的结论是脑并不表征信息，而是在构建信息。

近一两年，NLP领域出现了一种新的研究范式，被称为继特征工程范式、神经网络结构工程范式、预训练-微调范式之后的第四范式——提示学习范式。所谓提示学习，大概可以理解成旨在充分挖掘预训练模型的潜力，通过调整一些与下游任务有关的“提示”（被称为“prompt”），使其与预训练模型的行为尽可能吻合。这与当今主流的微调范式正好反过来。

这个范式很可能有普遍意义，未来说不定可以被推广到CV、语音、KG等领域。但是有一个潜在的难点，那就是prompt的构造，似乎是个大难题。

------

2022-04-27：Embedding（嵌入）方法对于搞NLP、知识图谱的人来说是相当熟悉了，尤其是在NLP领域中，近五六年所有的大的成果无不是基于（广义的）嵌入方法。嵌入方法的目标是通过某种算法寻找到某一表示对象在某个低维向量空间中的表示向量，这实际上可以理解为压缩编码。数据科学领域称“降维”，而信息通信领域称“压缩编码”，在我看来都差不多。那么如何获取嵌入向量？在我看来有两类方法，一类是rational理性的、规则驱动的、自顶向下的方法，另一类是heuristic启发式的、案例驱动的、自底向上的方法。前者信息通信领域用的多一点，比如音视频压缩编码实际上都可以看成是此类。后者数据科学用得多一点。比如NLP领域通过自编码器模型训练得到词嵌入向量，著名的Word2Vec就属于此类。再例如近年来复杂网络、知识工程领域也提出了很多基于机器学习的图嵌入方法，采用不同的距离度量（损失函数）、学习框架等算法要素，可以得到不同的算法。现在的前沿研究已经涉及多模态数据的联合嵌入学习，以期模仿人类的联觉记忆。

2023-03-28补充：所谓embedding，就是学习到的信源编码。只不过不是无损编码，而是码率-失真优化的有损编码，受限于香农的第三定理。音视频编码最奇妙的就是RDO，理解上可以平移到机器学习领域的loss和优化。事实上GPT等语言模型用到了诸如KL散度和交叉熵一类的东西作为损失函数，这原本就是信息论的工具。

------

2021-12-31

关于“触觉通信”的一些观点：

- 触觉是感知/执行环节的一部分，是未来用户界面的重要技术，但我不认为它是核心技术。核心依旧应该是视觉，图形用户界面。
- 触屏是最经典的感知元件。前几代IpHONE的压感屏幕虽鸡肋，但我个人很喜欢。都说振子才是手机的核心技术，这年头没有线性马达的手机都不好意思出门。振动的综合体验提升是有的，但我觉得价值没有吹的那么大。
- 仿生肌肉、皮肤是重要的。但有机体的肌肉和皮肤的复杂功能建立在复杂精密的微观结构基础上，我能想到的基础技术有两个方面，一是MEMS微机电系统，二是材料技术突破，如智能材料、所谓的纳米技术，等等。
- 元宇宙虽然是大骗局，但我并不反对需要有人来画饼、讲故事。人某种程度上就是靠故事活着的，望梅止渴嘛。

2023-04-06：微观尺度上构造不平凡、非周期、各向异、甚至高维度的复杂结构，是正道。我们被卡脖子卡到翻白眼的半导体，也属于这个方向。先解决理性设计问题，再考虑启发式设计甚至自组织自修复。肌肉的底层实现是保守而巧妙的，只不过人看不到而已。话说回来，人能不能看到，这一点也不重要。

2024-10-09补充：控制算法及其实现还在其次，首要的还是解决作动伺服机构的小型化、功率密度、自由度、可靠性等问题。而这些问题都呼唤着材料学和物理学的进步。作动伺服机构和控制算法需要协同优化，愚以为前者的牵引作用似乎还更大一些。

------

2021-12-20

关于人工智能的医学应用：医学比较特殊，健康所系性命相托，不可不察。包括DL在内的统计学习方法，的确面临可解释性问题，最大的问题甚至不是技术，而是伦理和法律。当年学习数字图像处理的时候，老师反复强调信号处理的手艺不能丢，不能贸然对原图做滤波和插值，要保证每一步处理都合理，要确保程序正义。





# 认识论·同一性问题·命名问题

> 计算机科学只有两个难题：命名和缓存失效。


2022-04-22

国博那位网红讲解员有观点认为，人类（大脑的认知能力）的上限，似乎早在鱼儿上岸那一刻就已经被框定了。复杂度科学/哲学领域有个论点我是认同的，就是说，用以反映某物的载体，其复杂度不能低于它所反映的对象。那么，人类的大脑，以及人类组织以及其构建的各种广义信息系统所构成的宏观社会系统，其复杂性是否足以反映这个世界的全部真相？我自己还有一个观点，就是说，人脑试图能动地反映这个世界，但如果承认人脑只是这个世界的一部分，那么人脑就扮演了某个“不动点”的角色。不动点是不平凡的，它反映了世界的某种本质特征。还有一个有趣的“悖论”：如果人脑过于复杂，他就会因为过于复杂而无法理解它自己。所谓“**悲观者正确、乐观者成功**”。正确固然正确，然而成功比正确更正确。所以长远来看，与其理性说服自己变得真正乐观，不如主动选择去采取一个乐观的态度。乐观就是能动性，要乐观的悲观，不要悲观的乐观。

------

2021-11-30

科学并不关心具体的科学结论。一方面是科学结论及其表述有赖于语言、视角和具体的条件，没有绝对恒常不变的科学结论。另一方面是科学关注的是科学结论的**演变过程**，也就是科学结论逐渐与客观实在相契合的过程，这其实就是极限的思想。如果我们采取可知论的观点，即认为对于任意小的“误差”，迟早存在这样一个历史阶段，使得我们的科学理论与客观实在之间的差异，总是小于任给的这个误差。那么我们就称我们的科学理论是收敛于客观世界的，即世界是可以被我们“完全地”认识的。

认识世界是一个过程，并且一般地并非“单调”的过程。在认识逐渐深入的过程中，总会产生停滞甚至是倒退，但这并不阻碍我们完全地认识世界。这个道理，在数学上，我们有这样的结论：单调有界是极限存在的充分条件，但却并非必要条件。甚至，这些倒退的阶段，会为最终形成新的科学逐渐积累机会，正如上个世纪初的“两朵乌云”，以及历史上三次数学危机一样。从混沌系统的角度来看，系统的阶段性演进，似乎是系统内部固有的规律。一方面，系统的进化未必是单调的；另一方面，系统的演进，是阶段性的、量变与质变交替进行的。一个简单而典型的例子就是所谓单峰映射的行为，在混乱与混乱之间，存在着多个分叉和“稳定区”。最近这几年，似乎就是人类的“稳定区”，也就是所谓的存量时代。不过我还是觉得，大乱之后有大治，只要熬过这个阶段，虽然前途是曲折的，但未来总是光明的。

------

2021-07-22

看到一篇有趣的文章（此处不给出链接），东北人，自称“满洲人”？哈哈哈。

我一贯认为，在对某个概念建立起较为精准、较为全面的把握之前，或者在具有一定工作量的的调查研究之前，去使用这个概念，甚至以这个概念去标榜自己，是一件特别羞耻的事情。这就如同初中生在中考作文里大谈特谈仁义道德，其实是相当羞耻的。不过考虑到这是每个现代公民在独立、成熟之前所必须接受的训练，其形式上的意义远远大于内容，倒也不觉得有那么奇怪了。但如果成年人还这样的话，只能说，其语言、逻辑、观念和现实世界尚未实现和谐的对齐。

直到我看到文章里“对主流叙事的叛逆”。哦……那随便你啦。虽然这既不“正确”也不聪明，但是够坦诚。

在东北地方话题上，我想我是比较具有发言权的。我只是作为旁观者，对此类人士的心路历程感到好奇，并且希望以这些异见者的想法为镜鉴，不断为我自己的思维增加充满批判精神和辩证性质的素材。

另外需要补充说明的是，所谓“身份认同”，尤其是西方话语体系下的“身份认同”，我是批判过的，详见2020-08-30灵感。制造地域分裂，实在是老套的不能再老套的手段了。统一与分裂是一对儿永恒存在的矛盾。

------

2021-06-26：PLT里面不少东西都给我一种如鲠在喉的感觉，那就是虽然我的思维对象是语言，但是却找不到更好的语言系统去描述我对于对象语言的理解，尽管我**觉得**我已经理解了我要阐述的那个东西。大概是因为PLT原本就是一门研究如何表达思想的学问。这注定了其本质上就是自我指涉的。

------

2021-06-21

在“精准辨析概念”和“钻牛角尖”之间有巨大鸿沟，而为了填平这个鸿沟，需要事先掌握足够多的背景知识。很多民科所犯的第一个错误，便是没有明确地、形式化地定义好自己所“研究”的问题，没有首先掌握做研究和学术交流所必须的学术语言工具，这也是很多无效推理乃至诡辩的起点。

**精确地辨析和使用概念，是玩哲♂学的基本功。**对语言文字和概念的细微语义敏感，是智慧的重要特征。2021-05-11：你程序员没有智慧，就不要指望着能把你自己的智慧迁移到机器里面去。有个说法很有意思：语言学是哲学的棺材盖儿。

那么我要问了，“无线电”和“通讯”，两者是一回事吗？如果不是，有什么区别？简单来说，就二者的关系而言，“无线电”是手段，而“通讯”是目的。

为了理清二者的关系，首先需要把握这两个概念的含义，即其内涵与外延。作为一种Meme的九宫格，实际上是寻找概念外延和内涵的一个好方法。当两个概念在本体论上的意义明确之后，就可以谈它们的关系了，即它们之间通过相互作用而导致的各自的存在的含义，进一步地，就是玩“无线电通讯”的人对于二者的个性化理解。这就从本体论的探寻进化到了认识论的探寻。

但是立刻可以发现，上面所说的本体论的探寻，在行为上，实际上是认识论式的。这也就是说，“探寻”是种两条腿走路的过程。那么，所谓的认识论的探寻，可以看作是构造id函数，用来判断两个东西是否同一。对复杂概念递归地应用id，就像eval/apply循环一样，思维逐渐与概念“本来的样子”形成匹配。

------

2021-06-17：评“航天员”与“宇航员”两种说法：对于语言和文字要敏感，把握概念和含义要精准，表达事情和思想要细腻。“航天”是我们一贯的标准用语，可与“航空”作对比。相比之下，“宇航”是民间和境外用得比较多的表述，没法体现出空天之间的区别。航空航天，既有相通之处，也有重大区别。“航天”一词，可以突出这种对比关系。

------

2021-05-10

评[这篇文章](https://zhuanlan.zhihu.com/p/22389755)：第四章关于范畴论的内容我看不懂了，但是我隐约能感觉到，它在解决所谓外延等价性的问题上有很大的作用。在数学上，或者说仅仅是在计算机科学中，判断两个“对象”是否同一，似乎是一个普遍的问题。我的理解是，一旦能够判定两个东西是同一的，那么就可以认为是消除了某种与表达方式相关的冗余（而提取出了本质的东西）。比如λ演算中的η-变换，表达了两个项的外延等价性，那么这两个项表达的是相同的行为（在直觉类型论里对应什么概念？），而与其符号表示方式无关。一旦（外延）等价性问题可以解决，那么文章第2节所述的问题（计算机证明依赖于模型/语言）就有了线索：判定等价性的规则本身，就成了解决问题的模型无关的现成答案，也就是文中所述的“可以搬动的性质”。但是外延到什么程度，是必须在一开始就加以约定的。说到没法计算，我理解确实是判定外延等价的一个本质困难，需要定义一个**可计算的**“外延等价”的准则。id（同一性问题）是认识论问题中一个非常关键的“东西”。具体来说，翻译也是一种id。关于“逻辑”的翻译，我比较认同的是“论理”。

关于“外延等价性”的一个简单解释，可参考卢昌海的《[弗雷格的算术](https://www.changhai.org/articles/science/misc/bookstories/Frege.php)》。

------

2021-02-18：评中学生回答政治科考试题目：学生真的明白自己写的“根本要求”“基本前提”都是什么意思、有什么语义上的区别吗？按照某些哲学家的观点，玩哲学，首先是玩语言。如果你连自己说的话都不知道是什么意思，谁又能分清你到底是某种话语体系的复读机，还是真正使用语言工具去表达你理性思考的成果呢？



# 折中与约束

**各领域的“不可能定律”**：2021年夏天所做的关于智能通信的技术报告，最后表达了我的一个观点，就是在科学技术研究中，要注意那些[根本的限制和约束](https://zh.wikipedia.org/wiki/%E6%82%96%E8%AE%BA%E5%88%97%E8%A1%A8)，它一方面框定了解空间的范围，提醒研究者不要做无用功；另一方面其实也在启发研究者跳出局部，实现从exploitation向exploration的跃迁。工程的肮脏，其深层次原因就是必须在这些不可能因素之间寻求权衡。某些问题暂未发现或者确认“不可能定律”，说不定有最优解，可以尝试；而对于有“不可能定律”的问题，则应放弃执念，寻求权衡。这就进入了工程的领域。比这些跷跷板更本质的原因，是否是某种守恒？即某种指标（如本质复杂度）只会转移而不会消失。这里就来总结一些表述了某事“不可能”的定律。

- 哥德尔不完备定理、阿罗不可能定理、香农三大定理、热力学定律、NFL（没有免费午餐）、CAP（一致、可用、分区容错）
- [布雷斯悖论](https://zh.wikipedia.org/wiki/%E5%B8%83%E9%9B%B7%E6%96%AF%E6%82%96%E8%AE%BA)

**工程上的折中**

- Cache地址映射的方式：直接映射和全相联映射是两个极端，而组相联是折中。
- 实时频谱仪处理实时性和扫宽之间的矛盾：扫宽不大于实时带宽，则实时；否则将扫宽按照某个适当的实时带宽分成几段进行扫描；极端情况是实时扫宽为最小，退化为完全的扫频式频谱仪。
- 实现Scheme解释器/虚拟机的时候，处理异步事件的方式：一个极端是每执行一个同步指令就检查一次异步回调，另一个极端是不管异步回调以保证同步指令的性能。折中方案是每次执行一组若干个同步指令后，再去检查异步回调。（也可参见Python的GIL）
- 《微波工程》第四版P106：空气填充的77Ω同轴线衰减最小，30Ω同轴线功率容量最大。因此通信领域选择50Ω作为折中，而广播电视领域选取75Ω。
- 码率降低可以节省带宽，避免发射端吞吐不足；但是低码率又势必会提高编码延迟，反过来拖累吞吐，合着横竖都不好过，唉，还是对编码器开刀吧，编码速度没有三五十倍实时还好意思叫编码器吗。（2022-07-08：首次实现基于自研MP3编码器和GNURadio的端到端数字音频无线传输）

# 零开销抽象·无法消除的复杂度

2023-10-23：递归适合描述问题，“非递归”适合描述方案。两者尽管在能力上是等价的，但是所谓的“把递归转为非递归”就是在解决问题，就是把基础设施的工作包揽给自己。理论是灰色的，唯有工程长青。

# 人工智能的局限性

![ ](./image/G4/揶揄人工智能-2.jpg)

![ ](./image/G4/揶揄人工智能-3.jpg)
