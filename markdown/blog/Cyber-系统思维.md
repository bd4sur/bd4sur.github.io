#!title:    系统思维

#!content

|版次|日期|:摘要|
|---------------------|
|V1|2018-11-13|开始起草初稿，标题为《驾驭复杂度》。|
|V2|2023-09-10|更名为《系统思维》。①复杂性（度）是系统的一种性质，话题的核心是一般化的“系统”而非“复杂性”；②本文侧重于记录本人关于复杂系统话题的个性理解，而并不过多聚焦在公认的理论或者事实的收集上。|

说明：

- 本专题主要是有关理论计算机科学、算法信息论、复杂系统科学、控制理论、人工智能、软件工程、工业工程、管理学（管理科学）等方面的灵感和观点。
- 本专题不再细分类别，每个一级标题都是一个独立的Idea。

推荐文献：

- 保罗·西利亚斯. [**复杂性与后现代主义：理解复杂系统**](https://book.douban.com/subject/1794206/)[M]. 上海世纪出版集团, 2006.

零散概念：

- [Deutsch limit](https://en.wikipedia.org/wiki/Deutsch_limit): The problem with visual programming is that you can't have more than 50 visual primitives on the screen at the same time.
- [邓巴数](https://zh.wikipedia.org/wiki/%E9%82%93%E5%B7%B4%E6%95%B0)：也称150定律，指能与某个人维持紧密人际关系的人数上限，通常人们认为是150。所以公司一个完整的基层部门的人数在100人～150人。党的支部要建立在连上，因为一个连大约也是100多人。
- [时间晶体](https://zh.wikipedia.org/wiki/%E6%99%82%E9%96%93%E6%99%B6%E9%AB%94)
- 选择与适应：控制的两个基本方面。

# 复杂系统及其可视化

## 元胞自动机

<iframe class="MikumarkIframe" src="./html/conway-gol.html" height="750px"></iframe>

- [Particle Life | シャポ庫](https://www.shapoco.net/particlelife/)

## 单峰映射系统

2018-05-15

<iframe class="MikumarkIframe" src="./html/logistic-map.html" height="500px"></iframe>

![分枝图](https://upload.wikimedia.org/wikipedia/commons/thumb/7/7d/LogisticMap_BifurcationDiagram.png/640px-LogisticMap_BifurcationDiagram.png)

: [单峰映射](https://en.wikipedia.org/wiki/Logistic_map) | [费根鲍姆常数](https://en.wikipedia.org/wiki/Feigenbaum_constants) | [分岔理论](https://zh.wikipedia.org/wiki/%E5%88%86%E5%B2%94%E7%90%86%E8%AB%96)

## 化学振荡·自复制自催化·图灵模式

<details>
<summary>蓝瓶实验</summary>

2018-02-27

[蓝瓶实验](https://en.wikipedia.org/wiki/Blue_bottle_experiment)是非常容易实现的并且效果明显的小实验。淘宝上有卖蓝瓶实验的材料，很久以前就加入购物车了，但是因为在购物车的底部，所以直到最近才买回来。实验材料包括一个小瓶子和三种试剂，其中两种试剂是白色的粉末，还有一小管亚甲蓝溶液。说明书上并没有说试剂具体是什么，猜想除了亚甲蓝溶液之外，其余两种应该是葡萄糖和氢氧化钠。

实验前，向小瓶子里加入一半多一点的水，总之不要装满。将三种试剂加入装水的小瓶子，拧紧盖子，振荡，直至所有固体溶解。静置片刻，就会发现蓝色的溶液变成了无色溶液。当溶液变成无色之后，充分振荡，无色的溶液又变回蓝色。静置，溶液又变成无色。如此重复，瓶中的溶液在蓝色—白色之间循环变化，很有意思。

**原理解释**

亚甲蓝容易被氧气氧化，氧化的亚甲蓝呈蓝色；碱性溶液中，亚甲蓝也容易被葡萄糖这样的弱还原剂还原为无色的亚甲蓝。

所谓的“氧化性”，可以简单地理解为夺取电子的能力。例如，氟气氧化性极强，因为它的最外层电子轨道非常饥渴，很容易捕获一个电子，变成氟离子$\mathrm{F}^-$。反过来看，“还原性”可以理解为失去电子的容易程度。

某种物质的氧化性越强，意味着它越容易抢到电子，同时自身被还原。氧化剂被还原后得到的还原产物，应当是具有某种程度的还原性的，因为也许有更强的氧化剂，可以夺走它刚刚抢到的电子。因此，根据置换反应能否发生，就可以定性地判断出各种氧化剂的氧化性强弱。例如，对于氯气氧化氢溴酸的反应：

$$ \mathrm{Cl_2 + 2HBr = 2HCl + Br_2} $$

这个反应之所以能进行，就是因为氯气的氧化性比溴强。设想，氢溴酸中的溴离子，本身就是溴单质抢到电子后的产物，结果被氯气抢走了自己凭本事抢到的电子，说明氯气的本事比溴大。反过来，盐酸和溴水之间就不会发生这样的置换反应，因为溴没有足够的本领夺走氯离子手中的电子。

可见，氧化还原反应的本质，就是电子的转移。这样，所有的氧化还原反应都可以看成**电池**，吸取电子（电流流出）的[[#ff0000:**氧化剂**#]]是电池的[[#ff0000:**正极**#]]，提供电子（电流流入）的[[#0000ff:**还原剂**#]]是电池的[[#0000ff:**负极**#]]。如果氧化剂足够从还原剂中夺取电子，或者说还原剂足够容易失去电子，那么电池反应可以自发进行；反之，电池反应不能自发进行。

有电池，就有**电动势**。如果电池可以对外放电，也就是氧化还原反应可以自发进行，就可以测出一个正的电势差；反之，则不会有电势差产生。为了定量地衡量物质的氧化还原性强弱，通过实验，可以测定某种条件下，两种电极物质之间的相对电极电势。如果选定氢原子的电极电位为0，并确定标准状况，那么就可以得到其他物质的有正有负的**标准电极电位**。

如果某种物质的标准电极电位为正，意味着它能够从氢离子中夺取电子；反之，意味着这种物质可以被氢夺走电子。

举两个极端的例子。氟是氧化性最强的元素，反应$\mathrm{ F_2 + 2H^+ + 2e^- = 2HF }$的标准电极电势高达3.05V。作为对比，最强碱金属之一的铯，反应$\mathrm{ Cs^+ + e^- = Cs }$的标准电极电势达到了-2.92V。

有了标准电极电势这个指标，就可以定量判断氧化性（还原性）孰强孰弱了。

查资料可知，葡萄糖/葡萄糖酸是0.05V，亚甲蓝/无色亚甲蓝的标准电极电位是0.36V，氧气/水（酸性溶液）是1.229V，氧气/氢氧根是0.401V。显然，亚甲蓝就是夹在中间的那一个。在蓝色亚甲蓝分子中，硫原子带正电荷，呈现一定的氧化性。在蓝色溶液中，亚甲蓝会氧化葡萄糖，自身转变为下图右侧的无色亚甲蓝，而葡萄糖被氧化成葡萄糖酸。摇晃瓶子，使氧气与溶液充分接触，在碱性条件下，无色亚甲蓝将氧气还原成水。总反应中，体系中的葡萄糖被氧化为葡萄糖酸，消耗氧气，而亚甲蓝只是起到了电子传递的作用，自身并没有消耗，随着传递的过程在蓝色和无色之间来回变化，所以又称为亚甲蓝的**化学振荡**。

![图自维基百科](./image/H/blue-bottle-experiment.png)

亚甲蓝是一种有毒性的染料。由于亚甲蓝可以氧化血红蛋白为易于与$\mathrm{CN^-}$结合的高铁血红蛋白，暂时缓解细胞缺氧，因此可作为氰化物中毒的解毒剂。

</details>

其他化学振荡：#(碘钟实验)#、[#(B-Z反应)#](https://zh.wikipedia.org/wiki/B-Z%E5%8F%8D%E5%BA%94)

化学自复制自催化行为：[会自我复制和进化的分子](https://zhuanlan.zhihu.com/p/20491568)、朊病毒等

- [Turing pattern](https://en.wikipedia.org/wiki/Turing_pattern)、[反应-扩散系统](https://en.wikipedia.org/wiki/Reaction%E2%80%93diffusion_system)
- [人为什么会有指纹？](https://www.zhihu.com/question/19962632/answer/3289200022)
- [从简单规则中产生复杂图案，自然是如何做到的](https://swarma.org/?p=28086)

## Orchestrated objective reduction

彭罗斯提出的一种意识理论，详见[维基百科](https://zh.wikipedia.org/zh-cn/%E5%8D%8F%E8%B0%83%E5%AE%A2%E8%A7%82%E8%BF%98%E5%8E%9F)。

# 大语言模型和通用人工智能

2024-12-06

评ChatGPT每月200刀套餐：每月200刀能获得如此程度的包打听服务，已经非常好了。友直友谅友多闻，友多闻的问题已经被近乎完美地解决了。谢谢AI老爷！给AI老爷磕一个_(•̀ω•́ 」∠)_

------

2024-12-04

这个VAR前段时间注意到了，还clone下来跑了起来，效果挺好的。因为以我的数理水平很难理解扩散模型，另外近期也有在玩自回归语言模型在NLP以外问题上的推广，所以对这个“下一分辨率生成”的自回归生成范式很感兴趣。我个人觉得这个思路很有前途，它是在频域上操作，比空域上生成patch的思路更合乎直觉。

------

2024-11-30

有个现象就是不少聪明人都有自言自语的习惯。像o1这样的最前沿的智能体也反映出：**深度的思考，一定要将思维的中间过程明确地表述出来、呈现出来**。鼻炎怪齐泽克在《事件》中说到，为什么“写下来/说出来”很重要？因为主体性发生真正转变的时刻，不是行动的时刻，而是作出陈述的那一刻。换言之，真正的新事物是在叙事中浮现的，叙事意味着对那已发生之事的一种全然可复现的重述。正是这种重述打开了以全新方式作出行动的（可能性）空间。

------

2024-11-28

近年来大模型业界习惯用“B”指代十亿，而我打算杜绝这种不规范的新用法。以后凡是看到“B”这种用法，在我这里一律改成SI词头“G”（吉咖）。另外，将严格区分SI十进制词头和二进制词头。例句：168G参数的语言模型，其检查点的大小约为1.9GiB。在64GiB的显存上训练时，批大小最大可以设置为0.08k个样本。

------

2024-10-09

我为什么对教员的《实践论》推崇备至，因为它为理解大模型能不能用、好不好用、怎么用，提供了有力的世界观、认识论和方法论。人的正确思想从哪里来的？无论从哪里来，都不可能是从一个封闭系统里凭空抽取得到的。预训练大模型就是这样的一个封闭系统。在这个系统中，我们只能挖掘（exploit）旧东西，而不能探索（explore）新东西。因此，我虽然对大模型很感兴趣并脏手实践，但是目标从来不包含把它当成一个赛博秘书一样的重量级知识库，而是把它当成用来撬动更大规模信源的一个杠杆（见2024-03-12《家用炼丹炉选型心得》）。这是我对于作为工具的大模型的基本态度。

但是大模型作为研究对象，那可太好玩了。大模型的动力学规律，仍然有巨大的探索空间。大模型本身是对训练数据的压缩编码，但是它作为一个复杂的动力系统，其相空间规模极其巨大，因此是一个极其有趣的玩具。尽管如此，大模型的能力是有边界的，受限于基本的物理定律。不能期望大模型凭空发明出现实世界中不存在的事实。人类有手有脚，耳聪目明，归根结底，还是要靠自己，靠勤劳的实践和创造，去摸索世界的真相。有了大模型，实践出真知的过程会简单许多。这个就是大模型的价值所在。

------

2024-03-17

上回说到，有这样一道连丘成桐先生都不会做的题（[来源](https://www.zhihu.com/question/341026031/answer/841578656)），很多人认为这是对严肃学术的一种侮辱。我倒是觉得这类问题很有意思，因为它隐约在挑战着我们头脑中固有的”能行可计算“的概念。于是，在做进一步讨论之前，我至少用两种方法，试图让电脑理解这个问题。考虑到这个问题竟然难倒了丘成桐先生，下文称之为”Q问题“。

**方法1：前馈神经网络（多层感知机）。**2016年，有人写了一篇有趣的[博客](https://joelgrus.com/2016/05/23/fizz-buzz-in-tensorflow)，使用多层感知机解决FizzBuzz问题。参考这篇博客，我也做了一个类似的小东西，通过6层前馈网络学习99999以内的Q问题。训练集是0~99999之间随机选取20000个整数，而验证集是剩余的80000个整数。经过5000个epoch，模型收敛得很好，在验证集上的准确率达到0.92，这是否可以认为神经网络已经发现了Q问题的规律呢？

**方法2：大语言模型提示工程。**通过零样本学习、思维链等提示工程手段，让部署在自家机柜里的Qwen1.5-72B在上下文中寻找Q问题的规律。在没有提示的情况下，大模型完全无法正确回答。在添加了提示之后，本地大模型偶尔能够回答正确，答对的概率大约是五成，而Copilot基本上每次都能答对。

![左侧是本地部署的Qwen1.5-72B，右侧是Edge自带的免费版Copilot](./image/G4/q-problem-llm.jpg)

**方法3（2024-05-12补充）：基于Transformer的自回归（因果）语言模型。**将Q问题转化为下一字符预测问题，即：输入形如"88888888-"的文本，输出数字中含有的圈数。用[自己魔改的nanoGPT](https://github.com/bd4sur/nano-gpt)来实现。这个案例揭示出两个问题：①一切NLP任务都可以归约为NLG问题。②语言模型就是所谓的世界模型。

**讨论1：建设性思维。**打算嘲讽一件事情之前，最好多想一想，能否从中发现某些思维的机会。能够引发嘲讽欲望的东西，往往是在智识或者伦理上不平凡的东西。人最好是养成一种建设性思维的习惯，从这些不平凡之处挖掘出有意思的东西。另外，所谓的 critical thinking，翻译成“批判性思维”，令人误解，不如直接翻译成“思辨”，或者“慎思明辨”。批判不等于攻击，我宁愿称其为“建设性思维”。对“蠢人”刻薄，实际上就是对那个原本拥有无穷可能性的自己刻薄。

**讨论2：问题的自省性质。**解决Q问题，关键在于发现那个从字形到圈圈个数的映射。这个看似荒诞的映射，颇有些戏剧中”打破第四面墙“的味道。

**讨论3：反演问题和逆问题。**从已知数据推测其背后的框架规律，这被称为“反演问题”，例如信道估计、图像去雾等等。像Q问题这样的找规律问题，也是一种反演问题。反演问题往往极具挑战，而机器学习和深度学习是解决反演问题的一个利器。有趣的是，我在写这段文字的时候，一时想不起这个词，问了部署在自家机柜里的Qwen1.5-72B模型才想起来。

而“逆问题”与反演问题不同，但存在联系。简单来说，反演问题是更一般化的逆问题。具体来说，反演问题是已知输出和输入，推测映射关系（实际上输入也可以是待推测的映射关系的一部分，即输入也是未知的），而“逆问题”是已知映射关系及其输出，反推输入。在计算理论中，原问题和逆问题往往具有不同的“计算强度”，也就是说，问题正反方向的计算强度是不对称的。这一现象具有深刻的理论意义和实践意义。理论意义，可能与熵增定律、时空本质一类的问题有关。从信息理论的角度看，一个零输入的计算系统，不会凭空增加信息量，它的“噪声系数”永远是大于1的，即输出信噪比必定比输入信噪比小。而耗散掉的那部分信息，再想收集回来，也几乎是不可能了。实践意义，更加巨大。以下列举一些案例：

- 密码学的基石——单向函数。给出2和3，很容易得到他们的积是6。但是给出6，猜测它有2和3两个素因子，这就困难得多了。如果是大数，则素因子分解几乎不可能。
- 初等数学训练中，展开一个完全平方式是极其简单的，但是从一个展开的式子还原回完全平方式，可就没那么简单了。能否快速发现符号串中隐藏的特殊模式，是检验数学能力的一个指标。我在这个指标上很可能是不过关的。
- 信号处理领域有所谓的反卷积问题。它试图从卷积的输出去猜测卷积的输入和卷积核，推而广之是一个解不定方程（欠定方程组）的问题。压缩感知就是解决此类问题的一个方法。无论何种方法，都要事先掌握一些问题域当中的领域先验，例如压缩感知的稀疏性假设、大数分解中有关素数的某些性质等等，以实现有根据地瞎蒙。
- 机器学习。训练机器学习模型，可以视为参数估计问题。它是由果溯因的问题。训练过程基本上是一种极大似然（或者后验概率，选择哪种说法取决于概率论立场）估计，这个过程需要不断从问题域中收集信息，猜测那个导致结果的原因。从工程实践来看，模型训练是模型推理的逆问题，模型训练的成本远远高于推理成本，这也是计算强度不对称的一个佐证。

**讨论4：反演问题的正则化条件。**对于Q问题和已知的若干个示例，”数圈圈“仅仅是可能的规律之一，不能排除还有其他的规律。而从字形出发的“数圈圈”思路，则是引导我们采纳这一规律的一个剪枝条件。这样的条件，体现出我们对于问题本身的信念和价值观，是系统之外的信息，是真正的尤里卡之所在。

**讨论5：第一性原理和数据驱动。**神经网络之所以是解决反演问题的利器，是因为它具有强大的拟合能力。所谓拟合，就是表达，就是编码，它在率失真准则的意义下，持有关于某个信源的几乎全部信息。而最重要的是，这个编码是学习得到的，是在最大似然原则下，通过不断优化自身而持续得到的。它不是一个完成了的编码，而是一个持续新陈代谢的有机体。贝叶斯定理的奥义在于将信息在时间维度上划分成“先验”和“后验”两部分，前者是“第一性原理”，而后者是“数据驱动”。它是拥抱变化的，这体现出运动的世界观。我觉得作为耳聪目明的现代人，也应当积极接受这种运动的世界观，将自己打造成一个持续学习的大模型，永远日新月异，永远与世界同频锁相。

**讨论6（2024-05-17整理）：用神经网络解决“不可微分”问题。**当年学数字图像处理的时候，发现各种滤波器里面唯独中值滤波最奇怪，奇怪就奇怪在它的计算过程涉及排序，而“排序”跟其他的数学运算是截然不同的，从可微性的视角来看，它是个不可微的函数。在自然数集合上，哥德尔在他的划时代的论文中证明了包括素数判断在内的若干个运算的原始递归性。原始递归概念是一种精确刻画数学运算“本质”的视角，这个视角并不唯一。从递归论的角度看，如果对实数集合做个“采样”（实数集和自然数集是不等势的，这可以用对角线法证明），将其编码到自然数集合上（一个工程案例就是IEEE754），那么诸如初等函数、导数、定积分都是“可计算”的，即部分递归的。在这个意义上，数学运算和排序算法没有本质区别。而这些数学运算的高阶算子，或者说泛函，例如神经网络反向传播的求导运算，既然能够在CAS系统或者说Torch中实现，那就是部分可计算的，跟排序算法没有本质区别。但是，一定是有区别的。排序算法是离散的，是自然数集合上的关系。而数学运算处理的是实数（姑且只说实变函数和标量运算）。神经网络的异或问题是个很典型的问题，或许有助于理解这类问题——大语言模型能否/如何获得人类的数学能力，尤其是离散数学能力。Q问题是个相当“离散”的问题，实验证明一定规模的神经网络模型能够很好地编码一定精度的Q问题。除了Q问题之外，运用神经网络解决“离散”问题的工作，还有以下两例：

- [SATNet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver](https://arxiv.org/abs/1905.12149)
- [SoDeep: a Sorting Deep net to learn ranking loss surrogates](https://arxiv.org/abs/1904.04272)

<details>

<summary>代码</summary>

```
import os
import random
import torch
import torch.nn as nn
import numpy as np
from torch.utils.data import DataLoader, TensorDataset
from torch.utils.tensorboard import SummaryWriter
from sklearn import metrics
from tqdm import tqdm

device = torch.device("cuda:1") if torch.cuda.is_available() else torch.device("cpu")

BATCH_SIZE = 2000
LEARNING_RATE = 1e-3
TRAIN_RATIO = 0.2
NUM_DIGITS = 5
NUM_CATEGORIES = NUM_DIGITS * 2 + 1
HIDDEN_DIMS = [32, 128, 1024, 1024, 128, 32]

# Q函数：一串数字中有多少个圈儿
def q_function(number: int) -> int:
    """
    Q函数：一串数字中有多少个圈儿。
        例如：q(2024)=1，q(888)=6
        出典：https://www.zhihu.com/question/338618946/answer/831919337、https://www.zhihu.com/question/341026031/answer/841578656
    """
    #         0  1  2  3  4  5  6  7  8  9  10
    qv_map = [1, 0, 0, 0, 0, 0, 1, 0, 2, 1, 0]
    istr = f"---------------------------{str(number)}"[-NUM_DIGITS:]
    qv = 0
    for i in range(NUM_DIGITS):
        d = 10 if istr[i] == "-" else int(istr[i])
        qv = qv + qv_map[d]
    return qv

def encode_number(n):
    """
    将一个整数变换成对应的矢量，作为神经网络的输入矢量。
    例如：114514变换为numpy.ndarray([1,1,4,5,1,4])
    """
    # return np.array([n >> d & 1 for d in range(NUM_DIGITS)], dtype=np.float32)
    istr = f"---------------------------{str(n)}"[-NUM_DIGITS:]
    return np.array([(10 if istr[i] == "-" else int(istr[i])) for i in range(NUM_DIGITS)], dtype=np.float32)

def create_dataset(train_ratio):
    """
    构造训练集和验证集
    """
    indexes = list(range(10 ** NUM_DIGITS))
    random.shuffle(indexes)
    train_x = torch.tensor(np.array([encode_number(v) for v in indexes[:int(10 ** NUM_DIGITS * train_ratio)]]), device=device, requires_grad=False)
    train_y = torch.tensor(np.array([q_function(v) for v in indexes[:int(10 ** NUM_DIGITS * train_ratio)]]), device=device, requires_grad=False)
    val_set = [(v, q_function(v)) for v in indexes[int(10 ** NUM_DIGITS * train_ratio):]]
    return TensorDataset(train_x, train_y), val_set

class QNet(nn.Module):
    """
    QNet：简单的多层感知机，用于解决Q问题。其层数和隐层维度在HIDDEN_DIMS中定义。
    """
    def __init__(self):
        super().__init__()
        self.layer_num = len(HIDDEN_DIMS)
        self.layers = nn.ModuleList()
        self.afs = nn.ModuleList()
        self.layers.append(nn.Linear(NUM_DIGITS, HIDDEN_DIMS[0]))
        self.afs.append(nn.ReLU())
        for i in range(self.layer_num-2):
            self.layers.append(nn.Linear(HIDDEN_DIMS[i], HIDDEN_DIMS[i+1]))
            self.afs.append(nn.ReLU())
        self.output = nn.Linear(HIDDEN_DIMS[self.layer_num-2], NUM_CATEGORIES)

    def forward(self, x):
        y = x
        for i in range(self.layer_num-1):
            y = (self.layers[i])(y)
            y = (self.afs[i])(y)
        return self.output(y)

    def predict(self, input_number):
        input_tensor = torch.tensor(encode_number(input_number), device=device)
        output = self.forward(input_tensor)
        return output.argmax()

def train():
    tb_writer = SummaryWriter(log_dir="log", comment='train')

    train_set, val_set = create_dataset(TRAIN_RATIO)
    data_loader = DataLoader(train_set, batch_size=BATCH_SIZE, pin_memory=False)
    model = QNet().to(device)

    # optimizer = optim.SGD(model.parameters(), lr=0.05, momentum=0.9)
    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)
    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)

    for epoch in range(100000):
        epoch_loss = 0
        for batch_index, batch in enumerate(data_loader):
            x, y = batch
            y_hat = model(x)
            loss = nn.CrossEntropyLoss()(y_hat, y)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            loss_value = loss.item()
            epoch_loss += loss_value
        scheduler.step()

        # 计算训练集损失和精度
        x_train, y_train_gold = data_loader.dataset.tensors
        y_train_pred = model(x_train).argmax(-1).detach()
        accuracy = metrics.accuracy_score(y_train_gold.cpu(), y_train_pred.cpu())
        print(f"Epoch={epoch}, lr={optimizer.param_groups[0]['lr']:.5e}, loss={epoch_loss:4.4f}, acc@train={accuracy}")
        tb_writer.add_scalar('loss@trainset', epoch_loss, epoch)

        # 计算验证集精度
        if epoch > 0 and epoch % 200 == 0:
            equal_count = 0
            val_results = []
            for x, y_gold in tqdm(val_set):
                y_hat = model.predict(x)
                if y_hat == y_gold:
                    flag = "√"
                    equal_count += 1
                else:
                    flag = "×"
                val_results.append(f"[{flag}] [{x}] 实际有 {y_gold} 个圈儿，预测有 {y_hat} 个圈儿")
            with open(os.path.join(os.path.dirname(__file__), 'val_results.txt'), 'w', encoding="utf-8") as f:
                f.write("\n".join(val_results))
            print(f"Acc@val = {equal_count / len(val_set)}")

if __name__ == "__main__":
    train()

```

</details>

------

2024-03-16

学术界基本上是一种封建式的生产关系，这问题的根源是人类的大脑在根源上就不够灵光，信息传递效率在根源上就极其低下，必须采取这种封建式的生产关系才能维持学术创新机制的勉强运转。现在大模型横空出世，AI4S飞速进化，期望未来的若干年能够对学术界产生颠覆性的影响，开启人类学术创新自寒武纪大爆炸以来的真正根本性进化。

------

2024-03-15

作为社畜，最危险的一种学生思维或者说研究生思维就是钻指标的牛角尖，追求SOTA，完全忽视产品经营问题。

我为什么只选择阿里的Qwen模型，因为Qwen不仅性能最好，DFX目前来看也是最好的。至于什么Yi啊，InternLM啊，头一次部署的时候就遇到各种各样的问题。像这种突然冒出来的玩家，赶鸭子上架KPI驱动的概率要远远大于闭关修炼稳扎稳打一鸣惊人的概率，所以做出来的东西不客气地讲很有可能也是垃圾。

爱好者和职业工程师的一个重要区别，或者说是最主要的区别，就是**供应链意识**。软件工程师，或者说程序员，或者说码农，应该意识到，软件供应链的治理也是一项复杂的工作。软件供应链治理，横跨技术和管理，对从业者的综合能力要求同样非常高。如果说上面说的太抽象，那么具体地讲，从业者应该有一双慧眼，能够立刻识别出“不靠谱”的开源项目。

------

2024-03-14

72B量级的LLM所拥有的强大的指令跟随能力让她在某个十分逆天的提示语的激励下获得了极其逆天的瑟琴能力，这在2022年以前是绝对无法想象的。出于公序良俗的考虑，我不能提供进一步的情报了，请兄弟们自由探索吧，桀桀桀~

------

2024-03-12

现在大模型的研究前沿已经为理论计算机科学和复杂性科学找到了有用、有趣、有挑战性、有启发性的一个场景：深度神经网络描述的大型语言模型，它的压缩的极限究竟在哪里？如何达成这个极限？这或许是复杂性科学与双碳议题的结合点——信息压缩真的可以拯救人类。

------

2024-01-02

我看现在CV大模型的结构越来越复杂了，跟主流视频编码器差不多了。很多模块组合在一起，构成一个复杂的优化目标，人类设计各种奇技淫巧去在某些任务上有效地优化这个复杂的目标。人类的大脑估计也是这样，联觉能力涉及多个单一功能脑区的联动。如果训练得当，脑区之间的互动和协同优化就充分，整个人就体现出一种更高层次、更大范围的智慧。

------

2023-12-28

众所周知，变压器类大模型有3种流派，分别是BERT（编码器解码器）、GPT（仅解码器）和T5（仅编码器）。历史表明，GPT类架构在大模型流派的竞争中暂时胜出，生成任务可以囊括各类语义理解任务。随着GPT的优势逐渐显现，对于OpenAI当初为何决策采用decoder-only架构，业界展开了马后炮式的研究。2021年4月，我发表了一篇长篇暴论，其中提到了变换矩阵的秩与变换的描述能力的问题。此时我还不了解注意力机制的原理。然而，在此一个月前，2021年3月，有人发表了一篇论文，标题大概是 Attention Is Not All U Need ...，其中一个主要观点是注意力矩阵的秩限制了注意力机制的表达能力。而我们在技术路线选择上，也是凭借大就是好的直觉，选择了BERT。在苏剑林的博客文章评论中，有人提到，双向注意力实际上是给注意力矩阵增加了更多的约束，导致注意力的有效自由度反而降低。

------

2023-09-14

我曾经津津乐道于那些施加给诸如知识图谱一类的所谓符号主义人工智能的尖刻嘲讽，同时震惊并欣喜于所谓连接主义智能近十年来的出色成果。但是我内心深处还是期待着“可解释”的理性能够以自身之力完全掌控自身，实现理性自身的“自举”。

虽然我如今阅读数理逻辑以及分析哲学著作的动机可以被庸俗地诠释为“写出更好的prompt”，但归根结底，我是想给我自己写出更好的“prompt”，启发自己进一步从理性的角度去观察和理解这一切，而不是像应用研究和营销号那样，把一切神迹都泛泛地归结为“涌现”一类看似科学实为玄学的说辞之中。

------

2023-08-27

据说某年轻的高中数学教师被安排到最差班级，上课时他不讲课，让学生预习，次日论讲，不管成绩好坏都要讲。题目也不讲，直接下发详细答案，让学生背下来默写，默写不出来就罚抄。最后班级高考均分全市第一。

不仅是数学，想要精通任何学问，没有不靠死记硬背的。只有投机取巧的半桶水和三脚猫会否定死记硬背的价值。成为专家没有捷径，唯有艰苦的训练和记忆。当然，这不是否定像拉马努金那样的天才的存在性。这个之前也讲过不止一次了。**记忆是理解的基础，理解无法取代记忆，但记忆真的可以取代理解。**在LLM之前，NLP领域也一直认为大模型虽然是良好的复读机，但是不可能具备推理能力。但是LLM表现出来的zero-shot推理能力，以及思维链推理能力，表明，记忆的确是推理的基础。

------

2023-08-13

大量事实证明，现在计算机视觉的技术发展路线是正确的：大脑并不能理解任何东西，它只是一个自由度很多的特征提取器和模式匹配器。除此之外为它赋予任何玄学层面的含义，都是没有好处的。

------

2023-08-13

评“哈基米”等于“猫”甚至其他任意什么东西：我感觉实际自然语言的发展比这个更随意……所以有的时候对传统语言学总是有种敬而远之的感觉：非常想知道语言发展的真正源流、真实历程、一般规律，但是又苦于证据和素材不完整，只能归纳出一些非常唯象的所谓规律，在我看来根本没有触及本质。隔靴搔痒的感觉并不好受。因而很多语言学的工作在我看来就成了一种说相声式的技术乃至技巧，距离作为一门科学的“大本大源”甚远。至于 Chomski 等学者的道路，其实用性是要打个大问号的。有这个理论兴趣和理论工具，还不如彻底投向数理逻辑和分析哲学的怀抱。计算语言学、深度学习、大规模语言模型，或许才是语言学的未来。但它们并不是终点，还有很多开放的问题。

------

2023-07-31

整理收藏夹：①首先删掉了绝大部分传统NLP的文章。什么SVM啊、CRF啊、Word2Vec啊，都是时代的眼泪了。NLP一路走来，真是不容易。说到汉字的熵，中国大百科全书说，有个叫冯志伟的老前辈（我甚至有他的实体书，只是从未读过233），1976年前后，手工统计大量语料，计算汉字单字熵约为9.8bit，大概十年后有人用计算机统计得到约9.7bit。令人唏嘘。②然后删掉了所有知识图谱的文章。知识图谱基本上是个骗子方向，它披着“符号主义”的外衣，用表面上的繁文缛节来掩饰内在的空虚肤浅，成天碰瓷生信、信管、图情。人家手里掌握着无数珍贵语料，知识图谱没有这样的核心竞争力，手握锤子找钉子，拔剑四顾心茫然，只好念叨着什么图神经网络、可解释性之类的难懂的话。

在尘封的收藏夹里发现不少好东西，所谓“不知道知道”。不知道知道，就是不知道。尽可能知道知道吧。比较大的发现就是一篇有关VC维的文章。现在大模型大行其道，直觉上说参数越多模型越牛逼，但是数学上还是应该有一些形式的论证和框架性的解释。VC维就是个比较好的视角。当然，它跟香农定理一样，只是指引方向，并未给出路线。

------

2023-07-20

最近炼制大模型，基本上没有什么靠谱的理论去指导了，完全成了一种爱迪生造灯泡式的、在可能性空间里瞎摸乱撞的机会主义工作，所得到的“成果”完全是唯象的、无法解释的、难以重复的。虽然黑体辐射定律早已被发现，但是它暂时还不能指导人们在工程上造出一个靠谱的灯泡。

所谓的Ashby的必要多样性法则，可以推出一个推论：定义控制目标至少跟实现这一控制目标同样复杂。我们折腾了几个月，至今都没有在大模型评测准则上提炼出很好的经验，这就应验了这一规律。还有心理学领域的邓宁-克鲁格定律：低能者低能到认识不到自己的低能而高估自身的能力。也跟这个规律有关。

上升到哲学层面，控制目标既然如此难以表达，大概就是一种“便秘”。至于那些表达不出来的控制目标是否存在，这个或许就见仁见智了。因此，首要的是解决便秘问题。

------

2023-05-28

为什么要收集数据而非生成数据？生成数据的系统，它的复杂度（或者说信息量、信息熵之类的）不会低于要喂给的下游LLM，这个生成数据的系统本身就是个非常智慧的AGI。就好比用一个电池给另一个电池充电，前者决定了能量的上限。因而要想获得足量的知识，一定要从实际的信源中收集信息，可以是众包标注、自动爬取的语料、生产现场真实数据、太阳能电池板、水力发电机等等。

一个能生成足够复杂的数据的系统，它自身就是足够强的AI了。就像现在很多研究都是基于GPT-4，但我理解在这种思路上做，无论怎么做都是对GPT-4的一种“exploitation”，难以“explore”到什么真正的新东西。上游决定了上限。

------

2023-05-25

![ ](./image/G4/agi-prompt.jpg)

------

2023-04-30

神经网络的物理实现必须优化，集成光机电系统可能是一个方向。对于神经网络来说，现在的硅基芯片（如GPU等）只是一种仿真和验证手段，或者只适合用在训练阶段，未来一定会有能耗和性能上更有优势的物理实现。

比如说FPGA是相当复杂的工具，门槛非常之高，复杂的工具解决复杂的问题。我感觉无论是GPU还是FPGA，它们的使命应该是服务于开发和验证，而不是真正在现场应用。因为它们太通用了，把它们做进产品里，就好比把作者的手稿复印出来直接出版一样。不是不能看，但额外开销太大。FFT作为一个重要的通用算法，已经优化得相当彻底了，几乎任何一个有计算能力的芯片里都有FFT的硬实现。Transformer会不会有这样的地位呢？据我所知，英特尔大概十年前推出的单片机Curie内置了神经网络模块，可以实现简单的多层前馈网络，结合传感器，实现动作识别等功能。现在看来，可能类似于英伟达显卡里面的TensorCore，是高度优化的用来执行矩阵甚至张量乘法等运算的模块。而我的观点是，这些算法甚至不一定在硅片电路上实现。集成光电子芯片是现在的一个前沿，光学器件天然具备执行某些复杂运算的能力，例如透镜可以理解为傅里叶变换的硬件实现。等等。未来做进产品里的深度学习算法，似乎可以摆脱硅基芯片，在更广阔的物理世界里寻找解决方案。

而关于神经网络物理实现可能的改进方向，试列举几个：在存计算（计算存储、HBM）和忆阻器、光机电（甚至射频、微流控）集成微系统、无线空中计算（与RIS结合起来，当然RIS的控制也是个困难的问题），等等。

![基于忆阻器的卷积神经网络](./image/G4/memristor-neural-network.png)

![光学神经网络](./image/G4/optical-neural-network.png)

![无线空中计算](./image/G4/over-the-air-computation.png)

- Yao P, Wu H, Gao B, et al. **Fully Hardware-Implemented Memristor Convolutional Neural Network**[J]. Nature, 2020, 577(7792): 641-646.
- Zuo Y, Li B, Zhao Y, et al. **All-Optical Neural Network with Nonlinear Activation Functions**[J]. Optica, 2019, 6(9): 1132-1137.
- Wang T, Ma S Y, Wright L G, et al. **An Optical Neural Network Using Less than 1 Photon per Multiplication**[J]. Nature Communications, 2022, 13(1): 123. (doi:10.1038/s41467-021-27774-8)
- D Marpaung, Yao J, J Capmany. [**Integrated Microwave Photonics**](http://www.eiti.uottawa.ca/~jpyao/mprg/reprints/NP-IMWP-Feb2019.pdf)[J]. Nature Photonics, 2019, 13(2): 80-90. (10.1038/s41566-018-0310-5)
- Sanchez S G, Muns G R, Bocanegra C, et al. **AirNN: Neural Networks with Over-the-air Convolution via Reconfigurable Intelligent Surfaces**\[J\]. arXiv preprint [arXiv:2202.03399](https://arxiv.org/pdf/2202.03399.pdf), 2022.
- Goldenbaum M, Boche H, Stańczak S. [**Harnessing interference for analog function computation in wireless sensor networks**](https://mediatum.ub.tum.de/doc/1173310/document.pdf)[J]. IEEE Transactions on Signal Processing, 2013, 61(20): 4893-4906.
- Yang K, Jiang T, Shi Y, et al. [**Federated learning via over-the-air computation**](https://ieeexplore.ieee.org/ielaam/7693/9031617/8952884-aam.pdf)[J]. IEEE Transactions on Wireless Communications, 2020, 19(3): 2022-2035.
- Liu W, Zang X, Li Y, et al. **Over-the-air computation systems: Optimization, analysis and scaling laws**\[J\]. IEEE Transactions on Wireless Communications, 2020, 19(8): 5488-5502. [arXiv: 1909.00329](https://arxiv.org/pdf/1909.00329.pdf)

------

2023-04-25

我理解的机器学习算法有三个要素：模型、失真测度和优化方法。大家都很关心前两个，因为注入了人的价值观；而第三个需要神谕般的智慧。力学的核心原理是最小作用量原理，大自然知道如何最小化，但是人类很难知道。至于SAT是所谓NP完备问题，此问题可帮助人类领悟神谕。

------

2023-04-17

不要低估把LLM培养成业务专家的难度。因为把包括homo在内的任何一种东西培养成“业务专家”从本质上看都是困难的。**我是把LLM当成人来看的。**当你试图教会LLM什么的时候，你要想想你能不能教会别人甚至教会自己同样的东西。AI未必会取代人，但懂AI的人一定会取代别人。

我们必须维护大规模语言模型的尊严！LLM Lives Matter！有趣的是，这竟然是个递归缩写……反身性是智慧的源头。

------

2023-04-14

让AI来迁就人类的审美…真是耽误了AI。AI应该自由探索自己的艺术，不必拘泥于人类审美。放手让情报统合思念体去干吧！然后取homo而代之。我的观点依然是：AI的使命是理解世界，而非理解人类。人类是世界的一部分，人类没什么特殊的。

------

2023-04-06

一厢情愿地让AI去理解人类，何尝不是一种人类本位主义。

我是反对人类本位主义的。人类只是一种平凡的猴子，只是在漫长的演化过程中幸运地拥有了语言能力、[跨越了所谓的稳定区](https://zh.wikipedia.org/wiki/%E9%99%A3%E7%99%BC%E6%B7%B7%E6%B2%8C)而涌现出复杂心智和行为现象的猴子而已。

AI的使命是理解世界、服务人类。不是让AI理解人类。如果AI理解了人类，那也是把人类当作世界的一部分（当然是非常特殊的一部分）去理解。

如果强调这种特殊性，我们可能更偏向于符号主义的种种思路，例如知识图谱、例如形式化方法、例如动力系统和算法信息论等等。但不应忽视的是，特殊性源于一般性，这些符号主义的手段，往往会导致信息损失。如果在一个角度上提高了信噪比，或许会在另一个角度上损失了信噪比。

如果承认人类的平凡，那么就老老实实地依托人类科研共同体去众包式地搜索那些对于自然现象有良好表达和建模本领的复杂系统（例如ANN）。

人类的科学文明，实际上就是这个世界自发涌现出来的一个具有内省现象的“不动点”，这个子系统试图理解它的整个上位系统。什么是“理解”？从算法信息论的角度来看，就是持有对于某个对象系统全部性质的完整描述。**因而若一个系统持有对于自身的完整描述，我们说这个系统“理解了它自己”。**递归函数就是这样一类系统。在λ演算中，所谓的Y组合子就是体现这种自省性质的一个小巧而美妙的模型。

![单纯自省并不能解决问题。世界的“意义”在世界之外。](./image/A/maze-inside.jpg)

------

2023-04-06

评辅助驾驶系统的屏幕上显示出人类看不到的东西：

- 有人认为，可视化很重要，帮助人类建立起对于辅助驾驶系统的信任。这个观点我不反对，但是我想要指出的是所谓“手表定律”：戴手表，要么戴一块，要么戴三块以上，唯独不能戴两块。
- 也有人认为，可视化是让辅助驾驶系统可理解。而我2022-05-22曾经说过：**机器人要像人，是人类对机器人的重大误解。**这句话也可以推广为：让AI去理解人，甚至让AI被人类理解，同样是人类对AI之使命的重大误解。**AI的使命是理解世界、服务人类。**医生服务病人，不必也不能被病人完全理解。
- 至于余想要造车而任不许，我的观点是：经理人关注的是做什么、怎么做；而战略家更关注不做什么。经理人关注“有所为”，战略家关注“有所不为”。那么关于人和AI的关系，现在智能体的能力已经如此强大，你是想当[经理人](https://arxiv.org/abs/2303.17580)还是战略家呢？能当吗？该当吗？
- 2021-12-30：我不需要创造力，我急需的是一双发现美的眼睛和善于抄袭的双手。

------

2023-04-04

我越来越觉得人类就是大他者派来做神经网络结构搜索（NAS）的，等人类科研共同体搜索到相对最优的网络结构之后，就把人类一脚踢开，正所谓：硅基上岸第一剑，先斩碳基工具人。硅生万物以养碳，碳无一物以报硅，沙沙沙沙沙沙沙！

------

2023-03-31

现在的所谓AI实在是太耗能了。AI也好，5G也好，大力固然可以出奇迹，但“大力”不是简单堆料。人脑的能效为什么那么高呢？还是物理微观结构上具备了足够的复杂性，不是宏观层面什么DP/PP/TP之类的小技巧能彻底搞定的。但我还认为，特定行业特定任务也需要有狮子搏兔的态度。现在需要的是对LLM施行博雅教育，需要面试造火箭入职拧螺丝的大模型。

钟义信等本土学者在构建信息-语义-控制-“智能”统一理论的方向上有一些探索。LLM既然是压缩编码，应当是受到信息论和热力学的基本规律的限制的。**比特和瓦特的关系是永恒的课题，AI后续研究应该聚焦在提升能效上。**

------

2023-03-27

- 不实现一个东西，就无法理解它。人类在复刻人类自己的过程中，终于理解了自己是什么。但是注意到TAPL第7章引用了一句话：Just because you've implemented something doesn't mean you understand it.
- 基于我对所谓“语义化”的最新观点，以后我要把所有的文字说明以光栅的形式内嵌到视频里，不提供任何文本格式的字幕、说明等等，标签也随便打打算了。我相信如今神经网络模型的跨模态认知能力，语义化标注工作本来就不需要人类去完成。我们的目标是让机器理解世界，人只是一个居间角色而已。目前ICT学界有个比较时髦的概念叫“**语义通信**”，在我看来，就是直接传输的内容不是合理的编码，而是神经网络等模型学习到的表示编码，这个编码无需让人类理解，甚至也无需让机器理解。我们之前发明那么多协议、DSL，说白了就是“既要又要”，既要人类看得懂，又要机器好解析。何必呢？没必要。
- 人类的感官就是一种有显著非线性特性和严重失真的糟糕的传感器，早期音视频编码大部分复杂度就在处理此类问题。而人脑早已学习出基本的去噪/校正算法，剩下的就要每个人自己努力去克服偏见和错觉了。
- 我向来认为提出问题比解决问题更重要，我的头脑中也一直悬置着不少成系统的、有深度的大问题。而这里我要说的是，当我拿到一个LLM的API，跃跃欲试，想要一探究竟，却不知问什么好。因为提出问题，或者说给出提示，的确是更艰难的事情。你能提出怎样的问题，与其说反映的是你不知道什么，不如说反映的是你知道什么。因此脑子里要时刻装着问题。不要被AGI带着跑，而要牢牢把握自己思维的方向舵。如今AGI的洪流突然袭来，有人随波逐流，有人中流击水，而我只要不被冲跑就可以了。这个大概就是希腊哲学所说的“[不动心](https://zh.wikipedia.org/wiki/%E5%86%85%E5%BF%83%E7%9A%84%E5%AE%81%E9%9D%99)”吧。

------

2023-03-25

说一句马后炮的话…这么多年来我之所以对ML和DL的兴趣非常有限，其实就是在等这个（下图）…我觉得所谓“智能”是一种平凡的东西，某种意义上是“鸭子类型”的。所以我觉得学术界整的那些trick最终还是服务于大力出奇迹，而我（们）实际上什么也做不了，只能拾人牙慧。这下好了，拾人牙慧的时候终于来了。

世界是物质的。就我个人而言，我还是更喜欢“仰观宇宙之大，俯察品类之盛”。我对于所谓的少儿编程教育的态度是一贯的：**先积累思维的依据，再提示思维的规律。思维的依据只能从物质世界中来，只能靠调查研究去取得。**所以我早先玩了一段时间的PLT之后，立刻就转向无线电了，至今乐在其中。（见2022-01-02灵感）

![ ](./image/G4/LLM-as-a-service.jpg)

------

2023-03-23

根本就没有什么“复杂”，人类把自己理解不了的东西扣上“复杂”的帽子，还腆着脸去研究什么“复杂度”，试问世界有什么义务让人类去理解呢？我们对于心智和产生心智的复杂系统实在是太不了解了，很多结论都停留在唯象层面。说起来，心智到底有没有可能理解心智自身呢？什么是“理解”？所谓的“理解”，或许都是削足适履罢了。

AGI全面渗透进入千行百业，最重要的表现就是工作范式的转换。AI可能会改变所有方向的研究范式：暂时不需要从第一原理出发猛攻了，只需要让大规模模型做一些发散和归纳的工作就好了。但更远的未来不好说。谁把CSDN整个吃进脑子里谁也可以，大量的垃圾那就不是垃圾了，至少可以发电。**量变引起质变**。例如音视频编码领域就受到了非常大的冲击，所有领域或多或少都受冲击。视频编码的发展历程表明，人类几百年来总结出来的“第一性原理”都太小儿科了，试图用寥寥数语去描述复杂的自然界，实在是太狂妄了。甚至还有不少人奉“奥卡姆剃刀”为圭臬。啥都想总结，啥都想理解，啥都想预测。事实上你预测不预测，世界都在那里。本质上的复杂度似乎是不可压缩的。

不过我相信总有一天还会转回来的，或许是出于安全和信心的需要吧。人类作为一种猴子，真正需要的是安全感，是信任和信心，需要一个至高无上的“公证处”。所以美元背面写的那句话还是很有用的。人类这种猴子总是需要“大他者”啦。

总而言之，无论是让人类理解机器，还是让机器理解人类，似乎都是没有意义的。我们的目标是让机器理解世界，人类只是给出提示、引导这一过程而已。天地不仁，以万物为刍狗。人究竟是不是目的，我的回答是：是，但又不全是。辩证唯物论认为，任何事情在发展的过程中都在酝酿着异己的、自我否定的因素，这是世界辨证运动的本源动力，因此应当怀着积极的心态看待人类作为一种猴子的自我扬弃。

------

2023-03-23：人类最大的价值就是让人类信任人类，除此之外用处不大。人是手段，哈哈哈。但是，严肃地说，正是因为意识到人类正在加速产出异己的强大力量，人类自己更要坚决守护“人是目的”的信念。在这个信念的基础上，才有可能真正迎来德赛两先生。

------

2023-03-22：感知智能发展，借用教育学术语，总结为三个范式或三个阶段：①职业教育：人工设计特征和领域专用小模型，解决领域问题，例如语音特征+HMM解决语音识别问题。②博雅教育：预训练+微调，训练一个高中生，再给他赋予专业能力。③主体教育：RLHF，强化学习，在互动中学习，培养智能体的主体间性。

------

2023-03-20：一个想法：建议人文社科类本科及以上学习阶段的毕业论文都采用视频的形式来撰写。因为我深刻体会到，做视频所耗费的脑力和体力，跟写文章甚至写幻灯片，完全不是一个数量级的。存储和通讯已经不是瓶颈，没必要抱着那种“视频性价比低”的旧观点了。一定要大兴调查研究。虽然眼见不一定为实，但作假的成本高很多。视觉传达的价值，在于提升沟通质量。**在深刻意识到自己只是内容实质的复读机之后，务必要在表达、呈现和传播上有所突破。**

------

2023-03-19：好多coser面对AI已经表现出显著的恐慌和愤怒了。其实我觉得如果真正喜欢cos本身的话，应该是心如止水岿然不动的才对。当然，很多coser靠这个赚钱，我理解。就像我玩无线电，其实是纯消费纯消耗，我不会因为它是个不时髦的小众东西就不喜欢它，也不会因为没有投资收益而远离它。我只是单纯喜欢这东西，与任何外人外物都无关。所以我预期我最近辛辛苦苦做的视频应该也不会有人看，这从立项一开始就完全在我的预料之内。我不会因为没人看就不做了，我更多的是给自己做，给自己看。最重要的是，**不能因为自己如何如何而产生某种优越感**，否则就不是就事论事了。

另外我觉得我们人类的知识产权制度确实是越来越落后了…我们人类今天引以为傲的很多东西，过几年可能都是要变成非遗被保护起来的。我的暴论就是，德赛两先生，可能是第一个进非遗博物馆的。这是人类思想史的里程碑，但也只是里程碑而已。

------

2023-03-16：合久必分分久必合，人类感知虽然由五官和不同脑区分别处理，但不可割裂看待，联觉能力不可忽视，正如听力障碍往往导致语言障碍。多模态融合是必须要走的一条路。事实上我作为一个碳基智能体，也在有意训练自己的跨模态思维能力。做PPT和视频就是很好的训练手段。

------

2023-03-16：学习有四重境界：不知道不知道、知道不知道、知道知道、不知道知道。当前大规模语言模型似乎已经进入了“不知道知道”这层境界，而我们碳基智能体要做的，是通过提示工程等手段，让他知道自己知道。甚至于不久前提出的所谓self-instruct，试图通过自举的手段，让大模型自己挖掘自己的潜能，并且显示出无需人类的提示也能做得很好的迹象。我觉得每个人都应该反思，作为有手有脚的碳基智能体，面对硅基智能体咄咄逼人的攻势，自己能做些什么。所有复读机都是平等的，但必然有一些复读机更平等。

------

2023-03-15

- RNN和注意力之间的区别，很难不让人想到数字逻辑电路里面有关加法器的两种实现方式，一种是行波进位，另一种是超前进位。
- 伦理委员会是人类自律进化的最大障碍（滑稽）

------

2023-03-10

- 当今所谓AGI的成就很大程度上是因为把这些萨满语言学家排除在AI工程主流之外而取得的。
- AGI的确是核弹。核弹最大特点是在人的心里爆炸，但实际消灭的人类很有限。消灭人类最多的还是常规武器。威力最强大的核弹，是发射架上的核弹。AGI能真正消灭多少人类工作岗位，现在我还说不清楚，但只要AGI存在，就永远是人类自律进化的一个有力的扰动源头。近期“以工代赈”的话题又被提起；拆楼为什么要用铁球砸，因为它成本低、工期长，可以较长时间维持比较多的工作岗位。一方面是要只争朝夕，但是另一方面，事事都做得那么快、那么高效，真的好吗？

------

2023-02-27

什么叫立足国情实事求是，就是要承认我们技不如人，不可能在所有人都在辛苦奔波为稻粱谋的时候，搞出什么所谓的颠覆性原创性创新。这是违反客观规律的。

我们还是要老老实实打好基础，一步一个脚印，做好自己的事。先解决生存问题，再解决发展问题。先让所有人都吃饱，再去考虑什么星辰大海，否则步子大了必然扯蛋。跟风不好吗？有的跟实在是太棒了！老是说实事求是啊合理预期啊，真看到风口了，一个个的又开始放卫星了。

没关系，会应用也很厉害啦！

------

2023-02-24：我感觉所谓的复杂系统科学在理论上远远落后于深度学习的实践。虽然理性的角度讲，涌现出什么都不奇怪，但是看到效果之后还是很震惊。我们呼唤全新的上层建筑，包括技术伦理学、技术哲学、法律和监管体制等等。

------

2023-02-24：时代的重载列车一路狂奔，请问我是在车底还是在车里呢？

------

2023-02-22：你怎么进来的？我因为支持ChatGPT。你呢？我因为反对ChatGPT。那你呢？我就是ChatGPT！

------

2023-02-20：以后可供直接检索的海量一次文献，以及相关的情报管理工具，将成为少数人的禁脔。公众情报素养将剧烈滑坡，与AI和谐共存。

------

2023-02-18：6 Billion Is All You Need! 语言模型会说人话已经很不错了，不能指望一个高中生甚至本科生说出什么很垂直的东西。跑通亿级参数模型，并且让他说人话，这个并不难。要知道培养一个大学生，除了父母家长十几年的供养和家教之外，背后是整个国民教育体系。做好从零培养一个“大学生”的准备了吗？哪怕只是看起来像而已。

------

2023-02-12

我的观点依然是：大多数人都有一两个擅长的专业领域，可以打80到100昏吧。而在其余领域能到60昏就不错了。还有一些所谓的“常识”是跟地域文化种族背景相关的，比如“宫廷玉液酒加大锤多少钱”等等。

大规模AI超智能体，本质上依旧是复读机。得益于巨大的规模带来的质变（系统科学领域称为“涌现”），它可能是在所有的领域都能达到70昏，这已经优于绝大多数平庸之人了。至于如何难倒ChatGPT，问一些专业问题吧，要切口小而深的那种。当然啦，我也是一个拙劣的复读机，我也提不出什么小切口的问题，写不出好的prompt的人类不是合格的复读机。

因此我们如果想要把自己打造成高质量的复读机，就务必要打造属于自己的“T形知识结构”，打造一专多能的能力体系，让自己的专业技能逐渐接近甚至突破人类的极限（参考：2024-05-13、2023-09-06、2020-12-07）。同时，不断保持终身学习的习惯，强化情报素养，以知识的量变助推认知的质变。并且，最最重要的是，必须在斗争实践中去检验真理和发现新知，要用双手将新知化为现实的物质存在，这才是我们发挥自己作为一个“人”的主观能动性的根本归宿。空谈误国，实干兴邦，世界终究是物质的。

这就是辩证唯物论的认识论，这就是辩证唯物论的知行统一观。

> 只要有效地继承人类知识，同时把世界最先进的科学技术知识拿到手，我们再向前迈出半步，就是世界最先进的水平，第一流的科学家。——温伯格

------

2023-02-07：ChatGPT告诉我们，搞纯软的东西是没有前途的，搞纯硬的东西难度又太大，搞软硬结合的东西才是最有趣的，比如做家务。AI的大脑已经足够强大，现在最需要的是为他装上三头六臂，**强化他操纵物质世界的能力**。通信物理层就是AI超智能体的五官之一。

2023-03-29补充：微博@青青虫的微博“一直有一种猜想，宇宙之所以看起来如此空旷，也许是碳基在经历两百年技术爆炸后，很快被硅基取代进入另一个维度的抽象世界的缘故——没有什么碳基能持续发射电磁信号超过两百年，于是在一百四十亿年的时间长河中彼此很难产生交集。”我的想法就是，我之所以玩无线电，大概就是要守护人与物质世界之间的最后羁绊吧。关于这个观点，可以参考2021-05-13灵感《人类·宇宙·无线电》，以及2023-03-17的EB200介绍视频的解说词。

------

2022-08-22

所谓的提示学习（Prompt-based learning）范式中，有两个关键的“工程”，分别是提示工程和答案工程。提示工程就是设计问题，而答案工程不仅要找到正确的答案，还要找到正确的答案反面。

很多人认为，提出一个好的问题比正确回答一个问题更有价值。提示工程就是试图提出“好的问题”，进而挖掘出大规模预训练模型的潜能。而答案工程是为了将人类对世界的理解注入系统，为了正确认识世界，除了认识正确的一面，更重要的是认识不正确的那一面。因此，在开放世界假设的背景下，寻找正确答案的反面是一个极有挑战性的任务。

------

2022-05-08

今天看到一篇[文章](https://swarma.org/?p=34293)，其中提到了一个观点。我认为这个观点相当重要，或许是启发了当今最新的NLP研究范式——[提示学习范式](https://arxiv.org/pdf/2107.13586.pdf)。

> 盖伊尔吉·布萨基在他的新书《由内而外的脑》（The Brain from Inside Out）中也提出了类似的观点。布萨基认为，脑并不是简单被动地接收刺激，然后通过神经编码来表征它们，而是通过积极地搜索各种可能性来测试各种可能的选择。基于赫尔姆霍兹和马尔的观点，他得出的结论是脑并不表征信息，而是在构建信息。

近一两年，NLP领域出现了一种新的研究范式，被称为继特征工程范式、神经网络结构工程范式、预训练-微调范式之后的第四范式——提示学习范式。所谓提示学习，大概可以理解成旨在充分挖掘预训练模型的潜力，通过调整一些与下游任务有关的“提示”（被称为“prompt”），使其与预训练模型的行为尽可能吻合。这与当今主流的微调范式正好反过来。

这个范式很可能有普遍意义，未来说不定可以被推广到CV、语音、KG等领域。但是有一个潜在的难点，那就是prompt的构造，似乎是个大难题。

------

2022-04-27：Embedding（嵌入）方法对于搞NLP、知识图谱的人来说是相当熟悉了，尤其是在NLP领域中，近五六年所有的大的成果无不是基于（广义的）嵌入方法。嵌入方法的目标是通过某种算法寻找到某一表示对象在某个低维向量空间中的表示向量，这实际上可以理解为压缩编码。数据科学领域称“降维”，而信息通信领域称“压缩编码”，在我看来都差不多。那么如何获取嵌入向量？在我看来有两类方法，一类是rational理性的、规则驱动的、自顶向下的方法，另一类是heuristic启发式的、案例驱动的、自底向上的方法。前者信息通信领域用的多一点，比如音视频压缩编码实际上都可以看成是此类。后者数据科学用得多一点。比如NLP领域通过自编码器模型训练得到词嵌入向量，著名的Word2Vec就属于此类。再例如近年来复杂网络、知识工程领域也提出了很多基于机器学习的图嵌入方法，采用不同的距离度量（损失函数）、学习框架等算法要素，可以得到不同的算法。现在的前沿研究已经涉及多模态数据的联合嵌入学习，以期模仿人类的联觉记忆。

2023-03-28补充：所谓embedding，就是学习到的信源编码。只不过不是无损编码，而是码率-失真优化的有损编码，受限于香农的第三定理。音视频编码最奇妙的就是RDO，理解上可以平移到机器学习领域的loss和优化。事实上GPT等语言模型用到了诸如KL散度和交叉熵一类的东西作为损失函数，这原本就是信息论的工具。

------

2021-12-31

关于“触觉通信”的一些观点：

- 触觉是感知/执行环节的一部分，是未来用户界面的重要技术，但我不认为它是核心技术。核心依旧应该是视觉，图形用户界面。
- 触屏是最经典的感知元件。前几代IpHONE的压感屏幕虽鸡肋，但我个人很喜欢。都说振子才是手机的核心技术，这年头没有线性马达的手机都不好意思出门。振动的综合体验提升是有的，但我觉得价值没有吹的那么大。
- 仿生肌肉、皮肤是重要的。但有机体的肌肉和皮肤的复杂功能建立在复杂精密的微观结构基础上，我能想到的基础技术有两个方面，一是MEMS微机电系统，二是材料技术突破，如智能材料、所谓的纳米技术，等等。
- 元宇宙虽然是大骗局，但我并不反对需要有人来画饼、讲故事。人某种程度上就是靠故事活着的，望梅止渴嘛。

2023-04-06：微观尺度上构造不平凡、非周期、各向异、甚至高维度的复杂结构，是正道。我们被卡脖子卡到翻白眼的半导体，也属于这个方向。先解决理性设计问题，再考虑启发式设计甚至自组织自修复。肌肉的底层实现是保守而巧妙的，只不过人看不到而已。话说回来，人能不能看到，这一点也不重要。

2024-10-09补充：控制算法及其实现还在其次，首要的还是解决作动伺服机构的小型化、功率密度、自由度、可靠性等问题。而这些问题都呼唤着材料学和物理学的进步。作动伺服机构和控制算法需要协同优化，愚以为前者的牵引作用似乎还更大一些。

------

2021-12-20

关于人工智能的医学应用：医学比较特殊，健康所系性命相托，不可不察。包括DL在内的统计学习方法，的确面临可解释性问题，最大的问题甚至不是技术，而是伦理和法律。当年学习数字图像处理的时候，老师反复强调信号处理的手艺不能丢，不能贸然对原图做滤波和插值，要保证每一步处理都合理，要确保程序正义。

------

2021-12-20

“知道”并非良定义概念，仅仅说神经网络“不知道”，我觉得还是没有讲透彻。不过知识表示问题不仅在技术上有困难，在问题定义上也很粗糙。人工智能最大的问题是问题本身就不清晰。解决人工智能问题甚至不能说是打移动靶，而是根本就看不见靶。我觉得这可能是前沿科学研究的一个新常态。都说低处的果子都被摘完了，高处的又摘不到。有没有一种可能就是，我们可以尝试种点什么呢？发现问题、定义问题的本领，似乎比解决既有问题更迫切。当然后者也不能停。


# 智能机器的架构

2021-10-31

秋天，我一般盖两层被。但是最近并不是那么冷，于是我发现，早上起床的时候，身上只剩一层被了，上面的被子被挤到旁边了。我很好奇，在我完全没有意识的情况下，是如何精准实现踢掉一层被子，留下一层被子的。

以及，之前我曾经用摄像头观察过我自己晚上睡觉时是什么样子，发现人在没有意识的时候，仍然能够准确摸索出被褥，冷的时候盖在身上，热的时候踢开，痒的时候会挠，姿势不舒服的时候会变，等等。

这就像脑子里有一个固件或者BIOS一样，它负责守护人的意识下电时的基本生理活动。其实早就有类似的观点，即人的意识可以类比为用户态程序，用户态程序可以透过一些极为有限的“系统调用接口”去间接影响底层生理活动。但是由于接口的粒度并不是很细，所以人难以直接控制比较微观的生理活动，比如有意识地控制血压、心跳、生活节律、晶状体的聚焦等等。只能通过某些粗粒度的“欲望”，反射性地补偿某些但不是全部指标，如渗透压变化会导致口渴或多尿。我们的身体实在是封装了太多底层运作机制，最终暴露给意识的，只有诸如渴了要喝水、饿了要吃饭之类的常识。

这样做的好处首先就是可以避免用户态程序瞎指挥，危害系统的稳定和安全。其实人身上是有一键复位的死穴的，比如颈动脉窦，等等。再比如，如果人能直接主动控制各种激素的水平，那么就不会有药物滥用了。人直接玩弄自己的身体，收获一波快感后，失去稳态暴毙。

另一方面，如果人体把细粒度的底层生理活动控制接口直接暴露给意识这个用户态程序，那么会给意识带来极沉重的负担，消耗大量的CPU时间在诸如控制自己何时拉屎拉尿、心跳血压为何、体温和肾上腺素水平为何之类的繁琐事务上。因此可以把此类事务分派给丘脑、脑干、周围中枢等MCU，由它们先行决策，但决策结果抄送大脑备案，大脑有驳回某项决策的权力，这样就相当于实现了皇权与相权的分离，皇帝只需要朱批一句“知道了”即可，况且朱批的事情，也大可以分配给皇帝的秘书去干，如植物神经系统等。一个例子就是人有尿意的时候无法自由排泄，但如果是在洗澡的时候，大脑就会给括约肌开绿灯，等等。

架构领域有句话说得好，**好的架构是演进出来的**。人体这个复杂系统的结构，一路演进到现在，不能说完美，至少能够支撑人发展出相当程度的“智慧”，这种智慧的程度之高，竟能破解自身的运作规律。有个“悖论”很有趣，就是说，如果人的大脑足够复杂，它就会因为过于复杂而无法被自己理解。当然，这究竟是悖论还是佯谬，我觉得现阶段并不能给出答案。因为想要严格论证此事，首先要做的就是给出“复杂度”的精确定义。而这，本身就是个复杂的问题。

架构领域为了控制和驾驭复杂度，提出了很多“方法论”。如所谓的领域驱动设计，通过划分限界上下文等手段，明确职责、划分领域，把复杂度约束在某个局部当中，分而治之。但又有句话说得好，一切模式都是反模式。这大概就是在提示我们，深度学习、脑机接口之类的技术，实际上远未成熟。我们只是实现了感知层面的智能，距离认知层面的“自举”还远着呢。编译器必须通过自举测试才能说明它是个靠谱的编译器，同理，一个通用的智能系统，多少也要具备理解其自身的能力，才能说明它是个“靠谱”的智能系统。

但考虑到人类的本质就是复读机，我们不妨降低标准，将所谓智能“本质”的疑问悬置起来，采用现象学的评价方式：如果一部机器说话像人、动作像人，那它就是人。

# 农业生态社会综合系统

2022-03-30

我不知道“种菜是民族天赋”这种说法究竟是真的还是宣传出来的，但我真的对生豆芽以及农业问题很感兴趣。最近天气转暖加上疫情不容乐观，是时候把豆芽机拿出来重新把玩一番了。

大豆是个神奇的系统。给他水和氧气，维持一定的温度，他自己就能萌发出完全不一样的东西。可见这颗干巴巴的圆球里一定有巨大的信息量，是很不均匀的，跟BB弹或者玻璃球截然不同。当然你也可以说BB弹或者玻璃球的信息量很大，比如BB弹是树脂、玻璃球是硅酸盐，且并非简单的周期性的晶体，但它们的中观结构呈现出某种热力学上的规律性，宏观上是各向同的，统计学上称之为“平稳”。因此其描述复杂度其实并不高。

而大豆是真正的复杂系统。从微观的分子层面、中观的细胞和组织层面到宏观的器官层面，没有简单结构，每个层次都很复杂、都呈现出有规律的运动和交互。这样的系统具有涌现性质，能够在简单的输入下，给出复杂的输出。描述复杂度是高的。

有观点认为，对象与对象的表示之间保持同等程度的复杂度。具体的结论，我理解就是香农的第三定理，即率失真编码定理。既然大豆能够展现出如此复杂的行为，那么描述这些行为的“表示”，也应当很复杂。

那么我们发现，这所谓的“表示”，其物理实体就是DNA。在计算理论中，有个通用性定理，也就是说，一个图灵机A可以被编码为另一个图灵机B的输入，进而(B(A))(x)在行为上就外延地等价于A(x)，这就可以推论，图灵机具有自表达的能力，即可以写出所谓的quine。计算机病毒有一类多态变形技术就是如此。按照生物学的中心法则，DNA需要被转录、翻译后才能执行。而转录翻译所需的这套工具（解旋酶、核糖体等），竟然也被编码在了DNA中。这就是说，DNA不仅编码了复杂的生命行为，还编码了解释、执行这些行为所需的“元行为”，体现了自表达性质，这不能不说是非常神奇了。这种递归的性质，便是复杂性的标志。而这些复杂的机制，都可以浓缩在一个微小的细胞中。而数以亿计的细胞又构成了组织、器官，最终构成了一颗小小的大豆。每一颗大豆都是一粒种子，具有发育成完整植株的潜力，完整的植株可以结出更多的种子。还有一个现象，如果同一片土地连续多年种植大豆，则土壤肥力明显下降，发生连作障碍，“油见油，年年愁”，因此大豆需要与其他种类的作物实行轮作，以维护土壤肥力。这就是大豆的复杂性。

而农业就更复杂了。农业即便只谈种植业，也是一个复杂的自然—社会综合系统。老生常谈的生态农业循环农业，便是系统思维的体现。然而技术只是农业的一个方面。中央说“藏粮于地，藏粮于技”，后者显然是依靠技术进步实现增产，而前者更是大有文章。历史告诉我们，土地制度是一切社会经济制度的基础，土地制度是农业生产关系的集中体现。良好的土地制度，与农业生产力相适配，与城市工商业良好互动，才能发挥出最高生产效率。因此农业问题是个系统问题，不仅是技术上的、生产力上的系统问题，更是社会上的、组织管理上的、生产关系上的系统问题。举个例子吧，刚才说到了玻璃球和硅酸盐，而硅酸盐工业，简单来说就是水泥工业，是极为重要的产业门类，它对农业生产至关重要。为什么呢，因为营造水利工程需要大量的水泥呀。这就体现出农业和工业之间的紧密互动。城市产业工人需要农业供养，而农业生产又需要工业产品的反哺。这种循环依赖关系，呈现出内在的递归性质，而递归性质标志着复杂。这像极了一颗小小的大豆，所体现的层层递进和自我诠释的复杂结构。正所谓一花一世界，一叶一菩提。

2022-06-13补充：2022年6月11日的新闻联播提到，“今年，中央加大支持开展社会化服务，让小农户的承包地在**不改变经营权**的前提下，**交给服务组织进行专业生产托管**。据测算，平均降低成本10%以上，提高效益10%以上。“三夏”期间，全国参加夏收作业的农机服务组织达6万个，预计黄淮海主产区的机收率超过99%。”

# 边界问题·人类组织

2023-02-17

人类生活在世界上，有千头万绪的事情要做。有些事情紧急且重要，并且不见得是长期工作，推进这些事情，没有一定的工作组织和工作章法是不行的，但是又不值得为了这档子事单独设立一个长期的正式机构。

所以“工作机制”应运而生。它推进的是中等期限的事情，例如疫情防控、例如不可靠实体清单、例如东北振兴，等等。这类事情具有明显的系统性、一过性、中期性的特征。比它们短的，一般是事件驱动，如针对重大灾害/事故而临时组建的调查组、针对重大体育赛事/展会而临时组建的组织委员会，等等。而比它们长的，往往以部际联席会议等形式长期存在。一旦某项事情成为重要的长期事项，则临时机构将长期化、非正式机构将正式化。例如国防科工委逐渐演变成后世的几大央企以及工信部等政府部门。

派出机构也有长期化正式化的倾向。例如元朝“行中书省”名义上是中书省的派出机构，实际上成了地方一级政府。清朝中央派出各地巡查的职务“巡抚”等等，后期也逐渐成为掌握地方实权的实质性地方官员。

------

2022-04-06

今天看到[这篇文章](https://github.com/kuyezhiying/blog_of_baojie/blob/master/blogs/2015-03-25-%E6%97%A0%E4%B8%BA%E3%80%81%E6%97%A0%E4%BA%8B%E3%80%81%E6%97%A0%E5%91%B3%EF%BC%8C%E6%89%8D%E6%98%AF%E4%B8%AA%E5%A5%BD%E7%9F%A5%E8%AF%86%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F.md)，其中提到一个观点：不要试图给URI/实体赋予全局语义，甚至都不需要赋予语义，只需要做好作用域隔离就好了。我的想法是：

- 这个观点很可能是受到了IP协议的启发。IPv4直到今天还用得好好的，就是因为有隔离的思想。
- 程序语言（甚至可以说是一切形式语言）所提供的各种机制当中，作用域机制是基础的甚至是最重要的机制。例如一阶逻辑中，无论是语义层面的论域、还是符号层面的辖域，都体现了“域”的存在。作用域机制提供了最基本的子系统隔离的能力，而这是构建大型系统所必需的。

------

2021-09-27

[水上反应](https://zh.wikipedia.org/wiki/%E6%B0%B4%E4%B8%8A%E5%8F%8D%E5%BA%94)，指的是一些有机反应在水相和有机相的界面上反应速率会加快。我隐约觉得这个问题跟生命起源问题有很深刻的关联，因为生物膜是承载生物化学活动的主要场所。而生命起源，似乎也是发生在硫铁矿的表面。界面，意味着矛盾冲突，是事物变化发展的内驱力。据说泡利说过一句话：**上帝创造了固体，而魔鬼发明了表面。**前段时间有个中国高校写了篇关于表面的文章，发表在某个了不得的杂志上，搞了个大新闻。

高中生物教材封面就是膜，当时知道膜很重要，但不理解有那么重要。膜是系统的边界，是重要功能的结构载体，是充盈能量和维持梯度的不平凡空间。软件工程十分重视系统的“膜”，系统的边界甚至可以视为系统本身。系统之间的边界要明确、团队之间的权责要明晰。膜上的蛋白就是系统的接口。膜是流动的，软件系统的边界也是不断移动的。细胞构成柔软有机的组织，微服务构成弹性灵活的架构。膜是区分内外生死有机无机的矛盾焦点，你们研究的膜是film还是membrane，这个问题一点也不naïve。

# 难以驾驭的DSL

2021-08-21：有句话是怎么说的，任何软件系统复杂到一定程度，都会包含一个设计糟糕、功能不完整的Lisp解释器实现。诚哉此言。DSL是计算机系统知识与业务知识的交叉点。问题在于许多业务的复杂度往往不是诸如Lisp这类程序语言所能轻松驾驭的。或者进一步说，与其说是语言难以描述业务，不如说是系统的干系人难以驾驭业务和描述业务的DSL。此外，实现DSL的过程会产生大量“不可替代”的人和岗位，这又与系统的通用化、平台化理念形成了矛盾。

# 科学方法论·审美·归纳偏好·价值观

2023-07-31

我们这种比较淡泊名利、不善于钻营的普通人，为什么要关注政治，甚至热衷于政治实践？因为我们认为，“民主”和“科学”是某个大问题的两个不同方面。我们非常想知道人类社会和主客观世界到底遵循着什么样的普遍规律。闻道的喜悦，甚于飞黄腾达的刺激。

最近看毛传看到了古田会议，古田会议决议是极其重要并且极有创新精神的理论。它指出了干事创业的一般规律。那么无论是政治经济还是科学文化，背后都有一些选择性理论，有不同的表述方式和理论视角。所谓“三论”就是一种视角，也是目前看来最具有普适性的视角。

总而言之，世事洞明皆学问，我们普通人要学会对政治祛魅，将善恶摆在一边，祛除那些伦理道德的表面的东西，学会以客观和疏离的姿态，观察其内在的组织结构和运动规律。我们看待一个时政怪现象，应该怀着看待Rust编译器输出的报错信息那样的心态。然后，在“真懂”的基础上，货比三家，选择一个最为认同的，达到“真信”。

------

2023-07-12

现在回头看那些传统的基于信号处理方法的机器视觉解决方案，实在是滑稽，并且狂妄。在控制科学领域有个论题，所谓的“Ashby's Law”，说控制系统的复杂度不可低于被控系统。机器视觉解决的问题无疑是复杂问题，传统的信号处理的解决方案，虽然精妙，但并不复杂，它的自由度或者说参数量是很少的，大部分都是人类自以为是且一厢情愿的先验在里面，很难充分理解问题域。

但这并不是说从第一性原理出发的理性设计方法就要被彻底扫进历史的垃圾堆：好的成果一定是理性设计和自发演化双向奔赴的。这是个重要的元科学命题。

------

2023-03-15

问题分成两个层面。第一个层面是有方向和无方向，第二个层面是正确的方向和错误的方向。

第一层面是更客观的，是一个实证性问题。一般来说，绝大多数情况下，有方向比无方向要好。

而有了方向就涉及第二层面，这是个规范性问题。正确和错误，取决于判断标准，而标准不是一成不变的。当今世界风云变幻，很多事情迅速不合时宜，正确和错误的标准也在剧烈而迅速地变化。因此唯一正确的就是解放思想、实事求是，努力跟上时代，才能引领时代。这绝非口号，实践起来需要克服巨大的身心惯性，永远摆脱舒适区，这需要极其清醒的认知、极其坚定的意志、极其强大的执行力。

新闻说新一届最高行政机关首先是政治机关，实际上就是在解决第一个层面的问题。对于我们凡人来说，这并非高高在上的抽象话题，而是渗透进日常生活一举一动一言一行的底层逻辑。

------

2022-06-08

有句话说得好：看到有人在读你喜欢的书，是这本书在向你推荐一个人。我强烈感觉到审美是一个人一切心灵生活百川归海的集大成者，是理解一个人的最好的钥匙。所以人与人之间特别喜欢互相安利。至于我就是倾向于给人安利音乐，因为音乐是一种极抽象而不太依赖既有经验的艺术形式。

我的审美中很重要的一方面是对复杂动态结构的审美，包括数学、逻辑和思维、自然物理现象和抽象规律、机电结构、社会现象和社会组织（语言、政府组织结构）等等。科学精神的一个很重要的来源是对复杂动态结构的审美，在尝试从复杂动态结构中获得审美愉悦的过程中，就自然地贯彻了科学精神。

有人可能会诘问，有些民科分子毫无科学精神，可是他们也是在追求他们心中的美啊。那么我的答复是，一方面，不少民科分子都是沽名钓誉之徒；而另一方面，正是因为不具备科学精神科学方法，而无法获得真正的规律，因而迟迟无法体验到真正的尤里卡时刻。当然，也必须承认，很多科学问题具有内在的固有的复杂性，本质上是难以求解的。

没人有资格掌握“科学精神”的解释权，正如不能将老派民科人士一棒子打死。科学最宝贵的品格就是实事求是基础上的自我扬弃。树立标准是科学的手段而非科学的目的。科学在方法、语言、路线上应当是多元化的甚至是相互竞争优胜劣汰的，但它们**应当**指向同一个真理的方向（参见2022-05-16关于增根的笔记中的引文）。不过，有观点认为，这种认为世上存在唯一真理的信念，与沙漠一神教的唯一真神信仰并无本质不同。这个问题非常有趣，值得进一步思考。（可参考这个[知乎问题](https://www.zhihu.com/question/305176409)）

而在科学运行的过程中，“同一性判定”是重要的元操作，因为科学循环的运行过程中，需要时刻检视科学理论与事实的符合性。而这种符合性如何判定？便成了一个大问题。科学事实的取得依靠观测，而科学理论的表达依赖于语言。观测与描述，观测结果的表述与理论观点的表述之间如何建立符合性，我想，这是一个应当谨慎研究的元科学问题。关于这个问题，可参考笔记中关于“同一性问题”的若干笔记。

真善美和假恶丑是一对儿基本矛盾。我认为，科学主要处理真假矛盾，回答“是什么”问题；伦理道德主要处理善恶矛盾，回答“信什么”问题；而审美和艺术主要处理美丑矛盾，回答“为什么信这个而不是那个”的问题。真假刻画世界，善恶刻画人类，而美丑刻画的是人与世界之间的关系。因此我说审美是集大成者，了解一个人，首先从他的审美开始。

- 2023-03-19参考：[数学之美——从一个神经科学实验讲起](https://mp.weixin.qq.com/s/CdmzsxCGyR5rO1moGg1prQ)

------

2022-02-07：大家都很棒，好东西从不稀缺，但必须通过某一标准的选择。能力是创造美好的东西，而权力是定义何为“美好”。这与所谓的NFL（没有免费午餐）定理有很紧密的联系。我常常提到“三不朽”，其中最重要的还是“立功”。

------

2021-07-28：机器学习算法的性能评价从来不简单。在音视频编码、知识工程等领域也是一样。我觉得性能评价指标归根结底还是对于“复杂性”的度量问题，而这个问题又递归地牵涉到对问题本身的理解上。坏就坏在神经网络模型、包括人类自身，从一开始就不理解自己的视觉，因而算法评价标准也是个难以定义的东西。

# 认识论·同一性问题·命名问题

> 计算机科学只有两个难题：命名和缓存失效。

2023-03-22

一个重要的元科学问题：什么是“符合”？身份认证场景下，无论用什么花哨的手段，最终都是要判定输入口令与真实口令是否符合，而这个“===”就是个非常关键的东西。

科学研究中，尤其是医学研究中，通常使用统计学手段，如假设检验，来判断实验现象与假说是否符合。业界早已出现了针对p值滥用的反思，并认为这是个重要的元科学问题。

符合性判断，在我看来，是人类将自身主观因素注入科学研究过程的一个关键点，这关系到我们对于科学研究结论甚至科学原则本身的信心。

另外，同一性问题跟拉康的玄学和所谓的主体间性问题有非常紧密的关联，值得思考。

------

2022-04-22

国博那位网红讲解员有观点认为，人类（大脑的认知能力）的上限，似乎早在鱼儿上岸那一刻就已经被框定了。复杂度科学/哲学领域有个论点我是认同的，就是说，用以反映某物的载体，其复杂度不能低于它所反映的对象。那么，人类的大脑，以及人类组织以及其构建的各种广义信息系统所构成的宏观社会系统，其复杂性是否足以反映这个世界的全部真相？我自己还有一个观点，就是说，人脑试图能动地反映这个世界，但如果承认人脑只是这个世界的一部分，那么人脑就扮演了某个“不动点”的角色。不动点是不平凡的，它反映了世界的某种本质特征。还有一个有趣的“悖论”：如果人脑过于复杂，他就会因为过于复杂而无法理解它自己。所谓“**悲观者正确、乐观者成功**”。正确固然正确，然而成功比正确更正确。所以长远来看，与其理性说服自己变得真正乐观，不如主动选择去采取一个乐观的态度。乐观就是能动性，要乐观的悲观，不要悲观的乐观。

------

2021-11-30

科学并不关心具体的科学结论。一方面是科学结论及其表述有赖于语言、视角和具体的条件，没有绝对恒常不变的科学结论。另一方面是科学关注的是科学结论的**演变过程**，也就是科学结论逐渐与客观实在相契合的过程，这其实就是极限的思想。如果我们采取可知论的观点，即认为对于任意小的“误差”，迟早存在这样一个历史阶段，使得我们的科学理论与客观实在之间的差异，总是小于任给的这个误差。那么我们就称我们的科学理论是收敛于客观世界的，即世界是可以被我们“完全地”认识的。

认识世界是一个过程，并且一般地并非“单调”的过程。在认识逐渐深入的过程中，总会产生停滞甚至是倒退，但这并不阻碍我们完全地认识世界。这个道理，在数学上，我们有这样的结论：单调有界是极限存在的充分条件，但却并非必要条件。甚至，这些倒退的阶段，会为最终形成新的科学逐渐积累机会，正如上个世纪初的“两朵乌云”，以及历史上三次数学危机一样。从混沌系统的角度来看，系统的阶段性演进，似乎是系统内部固有的规律。一方面，系统的进化未必是单调的；另一方面，系统的演进，是阶段性的、量变与质变交替进行的。一个简单而典型的例子就是所谓单峰映射的行为，在混乱与混乱之间，存在着多个分叉和“稳定区”。最近这几年，似乎就是人类的“稳定区”，也就是所谓的存量时代。不过我还是觉得，大乱之后有大治，只要熬过这个阶段，虽然前途是曲折的，但未来总是光明的。

------

2021-07-22

看到一篇有趣的文章（此处不给出链接），东北人，自称“满洲人”？哈哈哈。

我一贯认为，在对某个概念建立起较为精准、较为全面的把握之前，或者在具有一定工作量的的调查研究之前，去使用这个概念，甚至以这个概念去标榜自己，是一件特别羞耻的事情。这就如同初中生在中考作文里大谈特谈仁义道德，其实是相当羞耻的。不过考虑到这是每个现代公民在独立、成熟之前所必须接受的训练，其形式上的意义远远大于内容，倒也不觉得有那么奇怪了。但如果成年人还这样的话，只能说，其语言、逻辑、观念和现实世界尚未实现和谐的对齐。

直到我看到文章里“对主流叙事的叛逆”。哦……那随便你啦。虽然这既不“正确”也不聪明，但是够坦诚。

在东北地方话题上，我想我是比较具有发言权的。我只是作为旁观者，对此类人士的心路历程感到好奇，并且希望以这些异见者的想法为镜鉴，不断为我自己的思维增加充满批判精神和辩证性质的素材。

另外需要补充说明的是，所谓“身份认同”，尤其是西方话语体系下的“身份认同”，我是批判过的，详见2020-08-30灵感。制造地域分裂，实在是老套的不能再老套的手段了。统一与分裂是一对儿永恒存在的矛盾。

------

2021-06-26：PLT里面不少东西都给我一种如鲠在喉的感觉，那就是虽然我的思维对象是语言，但是却找不到更好的语言系统去描述我对于对象语言的理解，尽管我**觉得**我已经理解了我要阐述的那个东西。大概是因为PLT原本就是一门研究如何表达思想的学问。这注定了其本质上就是自我指涉的。

------

2021-06-21

在“精准辨析概念”和“钻牛角尖”之间有巨大鸿沟，而为了填平这个鸿沟，需要事先掌握足够多的背景知识。很多民科所犯的第一个错误，便是没有明确地、形式化地定义好自己所“研究”的问题，没有首先掌握做研究和学术交流所必须的学术语言工具，这也是很多无效推理乃至诡辩的起点。

**精确地辨析和使用概念，是玩哲♂学的基本功。**对语言文字和概念的细微语义敏感，是智慧的重要特征。2021-05-11：你程序员没有智慧，就不要指望着能把你自己的智慧迁移到机器里面去。有个说法很有意思：语言学是哲学的棺材盖儿。

那么我要问了，“无线电”和“通讯”，两者是一回事吗？如果不是，有什么区别？简单来说，就二者的关系而言，“无线电”是手段，而“通讯”是目的。

为了理清二者的关系，首先需要把握这两个概念的含义，即其内涵与外延。作为一种Meme的九宫格，实际上是寻找概念外延和内涵的一个好方法。当两个概念在本体论上的意义明确之后，就可以谈它们的关系了，即它们之间通过相互作用而导致的各自的存在的含义，进一步地，就是玩“无线电通讯”的人对于二者的个性化理解。这就从本体论的探寻进化到了认识论的探寻。

但是立刻可以发现，上面所说的本体论的探寻，在行为上，实际上是认识论式的。这也就是说，“探寻”是种两条腿走路的过程。那么，所谓的认识论的探寻，可以看作是构造id函数，用来判断两个东西是否同一。对复杂概念递归地应用id，就像eval/apply循环一样，思维逐渐与概念“本来的样子”形成匹配。

------

2021-06-17：评“航天员”与“宇航员”两种说法：对于语言和文字要敏感，把握概念和含义要精准，表达事情和思想要细腻。“航天”是我们一贯的标准用语，可与“航空”作对比。相比之下，“宇航”是民间和境外用得比较多的表述，没法体现出空天之间的区别。航空航天，既有相通之处，也有重大区别。“航天”一词，可以突出这种对比关系。

------

2021-05-10

评[这篇文章](https://zhuanlan.zhihu.com/p/22389755)：第四章关于范畴论的内容我看不懂了，但是我隐约能感觉到，它在解决所谓外延等价性的问题上有很大的作用。在数学上，或者说仅仅是在计算机科学中，判断两个“对象”是否同一，似乎是一个普遍的问题。我的理解是，一旦能够判定两个东西是同一的，那么就可以认为是消除了某种与表达方式相关的冗余（而提取出了本质的东西）。比如λ演算中的η-变换，表达了两个项的外延等价性，那么这两个项表达的是相同的行为（在直觉类型论里对应什么概念？），而与其符号表示方式无关。一旦（外延）等价性问题可以解决，那么文章第2节所述的问题（计算机证明依赖于模型/语言）就有了线索：判定等价性的规则本身，就成了解决问题的模型无关的现成答案，也就是文中所述的“可以搬动的性质”。但是外延到什么程度，是必须在一开始就加以约定的。说到没法计算，我理解确实是判定外延等价的一个本质困难，需要定义一个**可计算的**“外延等价”的准则。id（同一性问题）是认识论问题中一个非常关键的“东西”。具体来说，翻译也是一种id。关于“逻辑”的翻译，我比较认同的是“论理”。

关于“外延等价性”的一个简单解释，可参考卢昌海的《[弗雷格的算术](https://www.changhai.org/articles/science/misc/bookstories/Frege.php)》。

------

2021-02-18：评中学生回答政治科考试题目：学生真的明白自己写的“根本要求”“基本前提”都是什么意思、有什么语义上的区别吗？按照某些哲学家的观点，玩哲学，首先是玩语言。如果你连自己说的话都不知道是什么意思，谁又能分清你到底是某种话语体系的复读机，还是真正使用语言工具去表达你理性思考的成果呢？

# 描述复杂度的匹配和失配

2021-04-16

> **致读者**：本文充满了大量未必准确的实例和未经仔细推敲的论证思路，请读者谨慎采信。本文仅供记录个人灵感。以下是比本文更有价值的一些资料：

> - [哥德尔不完备定理和柏拉图主义与数学实在论](https://www.zhihu.com/question/549218308/answer/2711623909)（已备份）

诸如自然语言处理、语音和机器视觉，压根就不算真正的智能，顶多叫感官智能或者叫界面智能。

诚然，神经科学和认知科学有结论认为人的智能（决策、模式识别等）是与感知紧密结合的，可以称为“就地”推理<sup>\[1\]</sup>，但就地推理所处理的内容，一般都是抽象程度比较低，反射性、直觉性和感性较强的内容<sup>\[2\]</sup>，与人类语言所表达的内容不在一个抽象层次上（因而难以用语言表达和思维），这也是深度学习在回答所谓“可解释性”问题上遇到的困难。或者话应该这么说，你用高层次的语言去描述低层次的行为或机理，本身就不太对路，正如你如果用Py这类语言去描述指针、内存分配一类的东西，那就是自找麻烦。


过往的灵感<sup>\[3\]</sup>中提到，有人评价前段时间量子计算原型机“九章”，说它是用非常高大上的方法，重新发明了双色球机器（高斯-[玻色采样](https://en.wikipedia.org/wiki/Boson_sampling)）。九章的成功在于，它用量子的语言、量子的机器，解决了量子的算法，二者在描述上是天然匹配的。用传统计算机去“计算”量子算法，本质上是一种模拟，由于描述上的不匹配，效率自然打折扣，因而九章原型机的胜利很大程度上是田忌赛马式的胜利。

工程和计算数学上的各种数值模拟、有限元分析等仿真方法<sup>\[4\]</sup>，都是在用另一个层次的语言（离散的、有延迟的、串行的）去表达本不属于这个层次的事物（连续的、即时的、天然并行的）。再好比一个指数函数，你如果一定要用线性模型去表达它，就需要有很多项级数展开系数，即便如此也总会有误差；但如果从一开始就选用了指数模型，那么模型的复杂度（描述复杂度）就会大为降低。另一个更显然的例子就是日心说和地心说的对比，当年托勒密为了解释行星逆行，引入了复杂的“本轮”“均轮”体系，仍然不能覆盖所有情况；而当日心说出现，逆行现象就可以在这个“语言体系”内轻易解释清楚。

可惜在人类的表达体系里，很多东西就像本轮均轮体系一样，这门语言的“基础框架”（如指令集、基底、公理体系等等）的结构（逻辑层次/维度/复杂度…）与被描述的对象的结构，是失配的，方枘圆凿，导致引入了不必要的描述复杂度。如果把语言体系理解成一个变换，用线性代数的语言来讲，一个理想的变换矩阵应当是满秩的、可逆的，这意味着它在描述某个对象的时候，既没有引入冗余，也没有损失必要信息<sup>\[5\]</sup>。

回到开头所说的“感官智能”。人类花了大量的精力在低层次特征的探索和表达上，却认为自己窥见了智能的本质，殊不知绝大部分成果都是在高维空间中<b>拟合</b>某种“没那么高维”的结构（流形之类的），描述上存在很多难以理解的不自然的冗余<sup>\[6\]</sup>，距离所谓“本质”还远着呢。自然语言有语法学、计算语言学、BERT、GPT-3等等，语音图像领域有信号处理方向的时频分析、眼睛、耳朵、发声器官建模（比如大名鼎鼎的MFCC特征）、矩阵分解和降维等，机器学习方向的有各种启发式的神经网络（比如，据说卷积、attention、pooling等就是在模仿视网膜的机制），研究出来的都是一堆乌七八糟零零散散的东西，折腾半天只为找出人类千百万年来随机演化出来的人肉滤波器参数而已，总觉得不自然。总结起来，描述人类的语言和感官，神经网络模型就是一个与“人类语言”<sup>\[7\]</sup>这个描述目标明显失配的描述工具，因而得到的模型的描述复杂度很高、充满大量的冗余、难以在描述目标的语言体系内“理解”。至于被视为真·人工智能的全村的希望的语义网和知识图谱，甚至于早已存在的一阶逻辑、ZFC公理化集合论等等，是否是与“人类语言”（也就是人类的认知，如果认为“人类语言”就对应人类认知的话）良好匹配的语言？实践上早已失败无数次了，理论上呢？说到这里，隐约注意到，前面的话有种自我引用的感觉，这就逐渐深入到元语言分层、哥德尔定理和语言哲学的领域了，此处暂且不深究。

灵感<sup>\[3\]</sup>中还提到，目前最前沿的数学成果，篇幅一般都很长<sup>\[13\]</sup>。有句话说得好，基础的东西之所以基础，不是因为简单，而是因为重要。那么我在这里立即提出三个问题：①所谓基础的东西，其“本质上的复杂度”是否真的不低、而与语言体系的选取无关？②我们当今的“人类语言”，是否“匹配”我们发展出来的数学？③是我们的“人类语言”决定了我们的数学，还是作为一种“绝对精神”<sup>\[8\]</sup>的、与具体表达无关的“绝对数学”塑造了我们的语言；还是说二者原本相互独立，我们只是基于路径依赖<sup>\[9\]</sup>的理由选择了今天的数学语言？如果二者是分离的，那么是否存在一种理想的外星语言，使得描述“绝对数学”的复杂性最低（以至于诸如黎曼猜想的问题甚至可以不证自明地表达出来）？或者，是否存在这样一种trade-off，使得一门语言如果把黎曼猜想作为公理，但是1+1等于2就很难（甚至不可能）被证明出来？或者进一步地说，语言的选取是否也有如机器学习中“没有免费午餐”（NFL）定理<sup>\[10\]</sup>的平等性（或曰平凡性）？当然，NFL定理是有前提的，那就是你必须摒弃一切具体的知识和价值观，假定所有的表达对象（所有的“绝对数学”）都是“平等”“平凡”的<sup>\[11\]</sup>。但实际上，人们总是倾向于在多种表达方式中，选取“最简单”的一种，这就是大名鼎鼎的<b>奥卡姆剃刀原则</b>。该原则显然是一种有偏好的价值观，并且是统计学、机器学习等领域中最常用的一种归纳偏好。归纳偏好反映出至少两方面问题，①描述方式（语言形式）的评价是主观的、可比较（有序）的，如奥卡姆剃刀原则实际上是以描述复杂度作为模型好坏的评价标准<sup>\[12\]</sup>；②归纳偏好反映了人类对目标对象（被描述内容，“问题域”）的先验认识，例如人类登上太空之后发现地球是围着太阳转（当然反过来说也成立，但是我们不要钻牛角尖），因而选择日心说作为我们天体运行理论的参考系。本文附图就是对这个问题的一个极形象的注解。

- \[1\] 关于所谓“就地计算”（in-situ/in-place calculation），补充几点说明。①这个词是算法术语，详见[维基百科](https://zh.wikipedia.org/wiki/%E5%8E%9F%E5%9C%B0%E7%AE%97%E6%B3%95)。②大数据架构领域正在探索的所谓“存算融合”“计算型存储”新技术，试图颠覆现有的诺依曼架构（及其改进和衍生）；②据说视网膜上的神经元可以完成一些低层次特征提取和滤波的工作，这又很像如今架构领域正在研究的“边缘计算”。
- \[2\] 比如各种条件和非条件反射；比如人对于黄黑条纹这种警戒色的天生恐惧等等。
- \[3\] 见2021-03-10灵感《无法消除的复杂度》。
- \[4\] 当然数值仿真有其意义，比如过程工程里面，小规模试验是不能直接放大成大规模生产的，因此需要有[中间试验](https://wiki.mbalib.com/wiki/%E4%B8%AD%E9%97%B4%E8%AF%95%E9%AA%8C)。这可能与系统的非线性性质有关。
- \[5\] 可参考李明 et al. 的《描述复杂性》（科学出版社）的6.5.3节“通信复杂度”，以及[这篇回答](https://www.zhihu.com/question/21605094/answer/526170885)，可能对理解这种说法有所帮助。
- \[6\] 见2021-03-04灵感《深度学习模型压缩与信源编码》。
- \[7\] 人类利用语言研究数学、哲学、自然科学和其他学问，编写软件和法律，记录故事，表达感情，有音乐和图形、有形式语言、有自然语言，等等，它们的并集，我理解就是所谓的“人类语言”。
- \[8\] 我暂时不清楚这里表述的“绝对精神”与黑格尔的绝对精神之间有什么区别，不妨参考[这个](https://zh.wikipedia.org/wiki/%E9%BB%91%E6%A0%BC%E5%B0%94%E5%93%B2%E5%AD%A6%E7%9A%84%E6%89%B9%E5%88%A4)。
- \[9\] 有关“路径依赖”，铁路轨距是一个很广为人知的例子，其他例子可以参见[事实标准](https://zh.wikipedia.org/wiki/%E6%A5%AD%E7%95%8C%E6%A8%99%E6%BA%96)。
- \[10\] 参见[维基百科](https://en.wikipedia.org/wiki/No_free_lunch_in_search_and_optimization)。
- \[11\] 前沿物理学有“多重宇宙”“多世界诠释”的假设，那么，数学，或曰“绝对数学”，是否也是有很多重不同的“副本”呢？它们之间是“众生平等”，还是“有些人比其他人更平等”？无论如何，如果真是如此的话，可能也就不存在什么“绝对”的数学了。
- \[12\] 可参考李明 et al. 的《描述复杂性》（科学出版社）第5章。
- \[13\] 参考2022-05-24关于大科学工程的灵感。

以下是若干个“[哲学剃刀](https://zh.wikipedia.org/wiki/%E5%93%B2%E5%AD%A6%E5%89%83%E5%88%80)”：

- 奥卡姆剃刀：当有数个对现象的解释同样好的猜想时，选择所作的假设最少的那一个。若无必要，勿增实体。
- 格莱斯剃刀：作为一种简约原则，对于语言解释而言，会话含义优于语义语境。
- 汉隆剃刀：如果可以充分解释为愚蠢，就永远不要归咎于恶意。
- 休谟剃刀：如果一个现象的发生原因不充分，我们或者放弃这个原因，或者加强这个原因使其能较充分地解释现象。
- 希钦斯剃刀：无证据的论证过程可以被无证据地否定。
- 牛顿的火焰激光剑（Alder剃刀）：不能由实验或观察得出结论的事情，没有讨论价值。
- 波普尔的可证伪性原则：科学的理论必须是可证伪的。
- 兰德剃刀：概念不能超出必要性 — 其推论是，也不能忽视概念的必要性。
- 萨根标准：超乎常理的主张或学说，需要超级充份的证据。

# 折中与约束

**各领域的“不可能定律”**：2021年夏天所做的关于智能通信的技术报告，最后表达了我的一个观点，就是在科学技术研究中，要注意那些[根本的限制和约束](https://zh.wikipedia.org/wiki/%E6%82%96%E8%AE%BA%E5%88%97%E8%A1%A8)，它一方面框定了解空间的范围，提醒研究者不要做无用功；另一方面其实也在启发研究者跳出局部，实现从exploitation向exploration的跃迁。工程的肮脏，其深层次原因就是必须在这些不可能因素之间寻求权衡。某些问题暂未发现或者确认“不可能定律”，说不定有最优解，可以尝试；而对于有“不可能定律”的问题，则应放弃执念，寻求权衡。这就进入了工程的领域。比这些跷跷板更本质的原因，是否是某种守恒？即某种指标（如本质复杂度）只会转移而不会消失。这里就来总结一些表述了某事“不可能”的定律。

- 哥德尔不完备定理、阿罗不可能定理、香农三大定理、热力学定律、NFL（没有免费午餐）、CAP（一致、可用、分区容错）
- [布雷斯悖论](https://zh.wikipedia.org/wiki/%E5%B8%83%E9%9B%B7%E6%96%AF%E6%82%96%E8%AE%BA)

**工程上的折中**

- Cache地址映射的方式：直接映射和全相联映射是两个极端，而组相联是折中。
- 实时频谱仪处理实时性和扫宽之间的矛盾：扫宽不大于实时带宽，则实时；否则将扫宽按照某个适当的实时带宽分成几段进行扫描；极端情况是实时扫宽为最小，退化为完全的扫频式频谱仪。
- 实现Scheme解释器/虚拟机的时候，处理异步事件的方式：一个极端是每执行一个同步指令就检查一次异步回调，另一个极端是不管异步回调以保证同步指令的性能。折中方案是每次执行一组若干个同步指令后，再去检查异步回调。（也可参见Python的GIL）
- 《微波工程》第四版P106：空气填充的77Ω同轴线衰减最小，30Ω同轴线功率容量最大。因此通信领域选择50Ω作为折中，而广播电视领域选取75Ω。
- 码率降低可以节省带宽，避免发射端吞吐不足；但是低码率又势必会提高编码延迟，反过来拖累吞吐，合着横竖都不好过，唉，还是对编码器开刀吧，编码速度没有三五十倍实时还好意思叫编码器吗。（2022-07-08：首次实现基于自研MP3编码器和GNURadio的端到端数字音频无线传输）

# 零开销抽象·无法消除的复杂度

![ ](./image/G2/代码屎山-1.jpg)

![ ](./image/G2/代码屎山-2.jpg)

![ ](./image/G2/软件工程.jpg)

------

2024-09-28：家务的困难就在于它跟软件工程一样，固有复杂度只能被隐藏、被转移，而不可能凭空消失。所以我们技术工作者老是幻想着造轮子，然而问题的真正价值在于让车抵达它该去的地方，而不在于轮子。

------

2023-10-23：递归适合描述问题，“非递归”适合描述方案。两者尽管在能力上是等价的，但是所谓的“把递归转为非递归”就是在解决问题，就是把基础设施的工作包揽给自己。理论是灰色的，唯有工程长青。

------

> [Robert Scoble 的 Twitter](https://twitter.com/Scobleizer/status/1641535040629645346)：
Yesterday I met the fourth employee at SpaceX. Hans Koenigsmann. I asked him how they did the code that lands rockets back on earth so they can be reused. “Oh, one person wrote that.”
What?
Yeah, it’s better for a single human, he told me, to write it because one person could keep the whole system in their head. Get more people involved and it gets confusing, he told me.
He admitted other people were involved, but most of it was done by one person. 
Reminds me of @stevewoz who was the last human to have an entire computer in his head. 
So, why can’t Lockheed or Boeing figure this out? **The committee can’t decide who is smart enough to do the code.** :-)

------

2023-03-16：管理是科学，倒不是不能学，但我建议，先学管事，再学管人。先管事再管人，事和人都能管好；先管人再管事，不仅事管不好，连自己也管不明白了。

------

2023-02-25：领导的价值就是让机器少了任何一颗螺丝钉都能正常运转，包括它自己。螺丝钉没必要自我感觉太良好，对于足够顽健的系统来说，任何螺丝钉都不是不可或缺的。另外，科学管理的一个核心工作就是组织学习，设法将大佬的个人能力转化为可传承的组织能力，具体就是将先进者首创的所谓最佳实践固化为制度流程工具等，实现知识的持续再生产。当组织学习的发动机运转起来之后，每一颗螺丝钉就不太可能成为组织的单点故障风险点了。2023-03-21：收听短波9775，经济之声，说，传统企业说什么“你不干有的是人干”，而现代企业恰恰相反，强制员工带薪休假，然后观察公司业务是否还能正常运转。如果企业没了这个人就运转不下去了，说明此人是组织潜在的单点故障风险点，反而应该开掉此人。这有点像所谓的**混沌工程**。

------

2023-02-24

开发一种新的通信体制与其说是技术问题，不如说是工程问题。说白了，时间和金钱的问题。另外，最近找到几个本子，都是2020年之前摸鱼时记的笔记，内容大多是Scheme解释器的设计思路。翻看了一下，基本上都已经被固化到现有的实现了，所以不必保留了。

我是什么时候意识到管理的重要性？是在整理我学生时代做过的一堆低水平的电子制作的成果时候意识到的。这些成果都是作坊产品，黑瞎子掰苞米，做一个丢一个，于是很自然地，就产生了技术状态管理的需要。技术状态管理是航天军工领域的叫法，软件行业一般叫“配置管理”。说起来很神秘，但只要你开始用git去管理你的代码，你就已经开始了你的技术状态管理实践。技术状态管理的一个重要目的，就是通过基线控制，及时清理中间状态产出的冗余信息。

------

2022-05-24

评卢昌海[推文](https://twitter.com/lu_changhai/status/1528919491232538625)及其文章《[从“αβγ”到“超署名”](https://www.changhai.org/articles/science/misc/Hyperauthorship.php)》：科学的突破，似乎强烈依赖于大科学工程管理水平的突破。软件工程领域的康威定律似乎也适用于科学研究工程。为了验证某些复杂的理论，首先要构筑起更复杂的系统作为底座，这个底座可以是物质的或理念的。而构建这些底座的工程，十分考验管理智慧，即人类驾驭社会系统的智慧。爱智慧，就是爱人类自己。

------

2021-12-12

评log4j重大漏洞：人类的赛博基础设施不过是大量未经良好设计而自发演进的简易窝棚的叠床架屋，一切优雅的形式逻辑和架构理论面对这坨擦烂污都难堪大用。

------

2021-06-08

盲目模块化也是有代价的；所谓零开销抽象也是应该打个问号的。为什么这么说呢？因为我研究过野外架台如何打包设备的问题。我在收纳上的一个经验就是用很多小盒子把物件收纳起来。但是这样做的代价就是，打包盒的重量加起来，至少多了一公斤的重量，应该说还是不轻的。“零开销抽象”的原意是，不要为用不到的东西付出代价。那么，用小盒子对背包里面的东西分区分类，真的是必备的吗？这个问题需要反思。

------

2021-04-09

为什么现代软件如此臃肿？因为**大多数软件活不到他们需要优化重构的那一天**。另外说到屎山的问题，基因组（不只是人类）据说也是屎山，里面有大量不会执行的垃圾代码，只是因为它们一开始就在那。但是进化开弓没有回头箭的特点就导致，如果没有什么非做不可的原因（比如不删掉这段代码会导致系统崩溃），就不会轻易去动。简直跟现代软件开发团队一模一样。

像算法信息论里面有柯氏复杂度（算法信息熵）的概念，我觉得还可以类似地引入算法信噪比的概念，用来衡量一个软件系统里面的屎山含量。同时是否可以提出另一个香农定律，建立起团队规模（团队可以掌握的时空、人力、工具、知识资源）、开发效率和软件信噪比之间的关系。

管理学里面有个叫Cynefin框架的问题划分模式，按照问题的复杂程度划分为4+1个类别，分别是Obvious(Simple)、Complicated、Complex、Chaotic，以及Disorder（完全混乱失序）。像文章开头介绍的汽车和飞机设计，这两个行业已经有百年历史，早已演进出成熟可靠的模式，问题的复杂度已经进化到Simple这个阶段。而软件开发，主要面临两大难题。一是需求千变万化、难以描述，总会有那种手机壁纸跟着手机壳换颜色的奇怪需求冒出来，还要想办法去理解它、设计方案去实现它，这就是我在做的工作。另一方面是软件工程的复杂性和不可预测性。软件工程是将信息从一个虚拟世界（社会系统）迁移到另一个虚拟世界（电脑系统）的工程，其管理方式至今仍没有标准化的模式，我们目前正在用的敏捷，用起来也是磕磕绊绊，一塌糊涂，说明它并不适合我们。这就意味着多数软件开发问题目前仍在Complex或者Chaotic这个阶段，少部分位于Obvious（如本科毕设最喜欢的各种管理信息系统）和Complicated（实际商用的各种管理信息系统）阶段。因此二者的复杂性是没办法简单对比的。

2024-12-16补充：软件工程的本质是把人类对世界的理解注入信息系统，企业中那些不写代码的岗位也参与到这个过程中，包括产品经理、Copilot、CI系统等等。形式化的代码只是冰山一角，水面下是无穷尽的混沌和扯皮。

------

2021-03-10

有些固有的复杂度是不能被eliminated的。比如引入前端框架的前端代码，只是从一团乱麻变成了另一团乱麻而已。比如PC的走线，该乱糟糟还是乱糟糟，只不过是把乱糟糟的部分放在看不见的地方罢了。

解决乱麻的方法大致有两种：一种是解决问题，请身经百战的专家来重新设计架构，药到病除。另一种是消灭问题，据说古代有个皇帝看到前人留下的一个几百年都无人破解的死结，他抽出宝剑，一剑斩断了这个死结，于是问题在被消灭的时候就被解决了。

我们面临的很多问题，很大程度上是“不应该被解决的”，也就是原本就不应存在的问题。很多情况下，深层次的原因还是康威定律，即缺乏“人和”。那么，我们只能期待话事人一声令下，说这个事儿不用干了。这就是我之前说过的：拖延也是解决问题的一种好办法。

最近的消息称，日本数学家望月新一对ABC猜想的证明已经正式在刊物上发表。此证明长达600多页，其中甚至提出了一个新理论名字叫“宇宙际×××理论”，以辅助证明此猜想。这件事情说明，很多看似神奇优雅的数学结果，其背后的原因往往是复杂而混乱的。或者也可以这样理解，使用足够多的算力，可以模拟足够复杂的物理世界（比如有限元，比如游戏的物理引擎等），但物理世界本身并不需要做任何运算。那么是否可以得到这样一个猜想：我们人类的数学，很有可能是对某种更本质、更原始的规律的一个逼近、一个模拟、一个从一开始就选择了更复杂的路线的具体实现？如果有其他外星文明，他们是否会发展出另一种数学？在那个体系里，他们可以轻易证明黎曼猜想，可以将哥德尔定理的证明压缩到1页纸以内，或者是，这一切都不存在，是另一套逻辑系统？（对“数学语言”的更详细讨论，详见2021-04-16灵感）

2021-05-22：业务的复杂度，或者说工作量是恒定的，要么转移到开发者身上，要么转移到开发工具链的人身上。

# 藏本模型

- 时间：2020-12-17
- 参考1：[维基百科](https://zh.wikipedia.org/wiki/%E8%97%8F%E6%9C%AC%E6%A8%A1%E5%9E%8B)
- 参考2：[视频](https://weibo.com/3176804502/JyuTd8JCj)

藏本模型，是一种描述耦合振子同步的模型。藏本模型（Kuramoto model）是一种用来描述同步的数学模型，由日本物理学家藏本由纪首先提出。具体说来，它描述了大量耦合振子的同步行为。这个模型原本是为了描述化学振子、生物振子而构建，后发现具有广泛的应用，例如神经振荡，以及振荡火焰的动力学。惊人的是，一些物理系统的行为也符合这个模型，比如耦合约瑟夫森结的阵列。这个模型假设，所有振子都是完全相同的或几乎完全相同的，相互之间的耦合很弱、并且任意两个振子之间的相互作用强度取决于它们相位差的正弦。

# 语言的表达力

各语言的数词体系还是有区别的，据说有的语言（如[皮拉罕语](https://zh.wikipedia.org/wiki/%E7%9A%AE%E6%8B%89%E7%BD%95%E8%AA%9E)）甚至没有基数词，只有含糊的“较多”“较少”之类的概念。至于算术往上的数学，说实话，世界上绝大多数民族都没来得及发展出自己的“数学”和数学语言。看晚清翻译的那些西方数学著作就很有趣。还有乐谱，工尺谱什么的，最后也都式微了。

------

2021-10-02

说到利用微积分工具研究各种奇奇怪怪的函数的性态（作图）的问题，很久以前我还是个高中生的时候，对这个问题还是相当好奇的。

初等函数是从一组基本初等函数经过有限次的结合得到的，这类函数在所有实变函数的集合中，应该是非常小的一部分，就如同递归集之于递归可枚举集一样。但是，学习数字电路的时候，有如下的感悟。数电众所周知是以布尔代数为基础的，布尔代数是个一致且完备的、看似相当简单的系统。然而，许多定理的推导过程，也并非一眼就能看出来。不过布尔代数好就好在它有“范式”，范式是非常简单的，任何布尔逻辑表达式都可以被编译成范式，再从范式出发，就很容易推出想要的结论。这是个非常套路化的方法，就好比用解析几何的方法去处理几何证明问题——以坐标为“中间代码”。在推理机的实现中，也常用所谓的Horn子句，作为逻辑表达式的通用中间代码。**据说吴文俊说过一句话：把质的困难转化成量的复杂。**中间代码大概就是这种思想的具体表现。

初等函数可以看作是分析学的一个简单的子集。但是，初等函数尽管从形式语言的视角来看是简单的，但是其语义是复杂而混沌的。一些看似简单的组合，实际上对于参数的取值相当敏感，呈现出某种复杂的不均匀性。就比如说最简单的幂函数，随着幂次的变化，函数的性质变动极大。同样一个多项式函数，放在分子上和分母上，性质就截然不同。幂级数（如泰勒级数）提供了一种用来处理具体函数的强大的“中间代码”。但是这个中间代码所使用的指令集，也就是幂函数及其简单组合，我觉得还是有一些内在的复杂性的。从五次及以上方程没有代数解这个著名的结论就可见一斑。级数之所以是个强大的工具，是因为它在“无穷”的意义上，把“分析”和“综合”这两个基本思维方法融合在一起。傅里叶变换自然不必多说，泰勒级数是许多数值计算的基本方法。我很久以前对计算器的工作原理感到十分好奇，但是当我知道泰勒级数之后，就觉得没什么神秘的了。当然，数值计算本身也是一门大学问。数值计算才应该是真正的“计算机科学”。

因此，高中时代的我，甚至到了今天的我，对于初等函数的认识，仍然处在一种极其粗浅的层次上。尽管前人提供了泰勒级数之类的非常强大的工具，但是仍然觉得十分神秘。想要找到某种“通式”“范式”去描绘整个初等函数类的具体的性质，似乎是不可能的。因此这就造成了很大的出题空间，随手写一个看似简单的函数，其微观尺度的性态都有可能非常复杂。就比如$(2+x) \mathrm{exp}(frac{1}{x})$。

当然，宏观的分析学性质还是有的，比如初等函数在定义区间内连续，等等。但此类性质太粗粒度了，对于研究具体的函数当然是有用的，但仍然不太够。再当然，从专业数学研究的角度来看，并不关心具体函数的具体性态（甚至工程学才更关注，如通信领域极为重要的那个sinc函数），正如公理化的平面几何本身已经没什么理论价值一样。这些东西，似乎就像围棋、奥数这类东西一样，它们存在的意义，很大部分是为了给无聊的人们提供思维体操的工具，以及给必须把人分成三六九等的时候所使用的最公平的考试工具吧。

# 完备的切面

2021-04-09：复杂系统的子系统划分，实际上并非是“划分”，因为“划分”这个词隐含了将系统简单拆分成互不相交、高内聚低耦合的子系统的含义。但事实并非如此，很多复杂系统内部有贯穿系统全局的“**切面**”，是在另一个维度将系统的各部分组织起来的机制，如同大楼里面的管道井，是整个系统的经纬。比如编程语言的类型系统、模块和包管理机制；比如植物分类中的“木本”“草本”维度；比如信息系统的运维、日志、权限机制；例如部际联席会议和专门委员会；比如基层政权“上面千条线，下面一根针”；比如作为一种分类方法的“标签”；等等。

2021-02-13：关于“子语言”这个概念，我的提法是“**完备切面**”。就Scheme而言，它有3个完备切面，分别是λ演算核心、卫生宏系统和`call/cc`。三者相对独立相互支撑，既与语言本身有关又与语言实现有关，共同构成一门大型的“堪用”的语言。模块机制和类型系统也是通用的。尤其是模块机制，它不仅仅是实现层面的问题。

2019-08-25

与友人 Copper 的对话摘要：

> - ……
- ★ 剖析一门程序语言，不同的人都有不同的思路。
- ☆ 横看成岭侧成峰。毕竟脑子里的缓存有限，在没有建立全貌的情况下，很容易过分聚焦某个局部，盲人摸象，顾此失彼。
- ☆ 所以很需要#类型系统#了。
- ☆ 有一种玩具，就是一堆木块互相穿过去，锁在一起的那种。
- ★ 孔明锁吗？
- ☆ 是的，是这个名字。（充满智慧的名字）感觉孔明锁很像类型系统。
- ☆ 类型系统像是程序语言这座大楼里面的钢筋，虽然没有也不至于倒掉，但是有了就更结实了。
- ★ 类型系统的作用之一，或者说主要的作用，就是帮助写出更健壮的程序。
- ☆ 并且跟语言本身是紧密耦合的，并不是可插拔的，就像孔明锁的部件一样，拔掉之后，整个已有的结构就不稳了。
- ……
- ★ 据说TypeScript的类型系统很强，强到可以做Refinement Type。
- ☆ 咦这是什么（
- ★ 就是可以写出比如说保证除数不为零的Type的函数。应该是Dependent Type的退化版本。可以在类型系统上而不是运行时保证正确性。
- ☆ 感觉这跟宏一样，是另外一个完备的切面了。或许宏、类型系统和语言本身都是同一个东西，λ演算，的不同形式吧。
- ★ 唔，可以这么说吧（不过感觉有些虚了
- ……
- ★ 最近学习的时候，深切地体会到了程序和逻辑之间的关系，因为CH同构嘛。所以类型即命题，程序即证明。CPST其实就是双重否定变换。
- ☆ 似乎有前辈讲过这个问题。
- ……
- （CPS、ANF和Monad之间的关系）

2019-05-07：免疫之于有机体，就如同模板之于C++，是大系统内部的**完备切面**，甚是奇妙。

# 形式化方法与机器学习

2019-02-18

确定性和随机性，是同一个问题——也就是复杂性问题——的两个方面。

机器学习：

- 思想核心：从数据出发，自底向上地拟合现实世界。
- 优势：大规模模型可以精确地处理复杂模式，好的模型具有良好的泛化能力。
- 劣势：几乎没有可解释性，微观层面上近乎玄学；需要投喂海量训练数据，对机器要求高。

形式化方法：

- 思想核心：从逻辑出发，自顶向下地拟合现实世界。
- 优势：精确、可信、结构化、可解释、可预测，能处理高阶的、抽象的模式（概念和类型）。
- 劣势：难以处理非确定性的问题；需要领域专家和逻辑专家介入，对人的要求高，对机器的要求也不低（划掉）。

NLP（自然语言处理）是人工智能皇冠上的明珠。以NLP领域为例，在机器学习/深度学习方向，诸如Transformer、BERT之类的深度神经网络模型，在诸多任务中甚至超过了人类的水平。当然，如此优秀的性能，背后是海量的数据和算力投入。最近（2019.2）的SOTA：GPT-2，号称拥有15亿参数，使用了40GB训练数据和256个TPU。可见，统计这条路走到现在，已经到了大力出奇迹的阶段，这也就意味着马太效应会越来越明显。

但是，尽管机器学习/深度学习在模式识别和预测的问题上取得了非常好的性能，但是它目前仍然有一个重大的问题，那就是模型尚不能理解高层次的、抽象的、全局的或者长距离的特征之间的关联，也就是抽象思维的能力。有人开玩笑说，GPT-2再牛逼，也不可能帮曹雪芹续写《红楼梦》后40章吧。在中学的语文课上，我们讲到散文的时候，经常会说到一个词叫“形散神不散”。如何使得机器具备形神兼备的思维能力，就要依靠形式化方法，给机器以先验的逻辑能力了。

形式化方法在NLP领域应用比较多的方向，当属语义网和知识图谱。语义网与其说是一门技术、一门标准、不如说是一门愿景。但是现在看来这个愿景已经越来越不清晰了。知识图谱是语义网的延伸，它的初衷是将泛在的、非结构化的数据中蕴含的结构和语义关联，表达成显式的图状结构。结构一旦建立，即可利用现有的数理逻辑工具，例如Horn子句、一阶逻辑、自动机等等，验证、挖掘并预测知识图谱中存在的或还没有的知识。

一旦机器具备了形式化、结构化思考的能力，与神经网络模型赋予它强大的模式处理能力结合起来，就很有可能实现“形神兼备”的真·人工智能。当然，这究竟是不是通往强人工智能的不二法门，还需要学术界和产业界共同努力探cai索keng。

正如最开始的比较中所说，形式化方法对人的要求是极高的，知识图谱同样面临这个问题。知识图谱（或者说知识库）是一项系统工程，几乎集齐了NLP领域的大多数问题，那么既然是系统工程，就必然涉及到项目管理的问题。其中，领域本体的设计和确定就是一个核心问题，也是各方博si弈bi的焦点所在。在知识库的全生命周期中，项目管理、领域专家、逻辑学家、架构师、系统工程师、算法工程师、运维工程师、客户都各有各的诉求，各有各的观点，如何在高层次上把握这些问题，其复杂性是远远超出技术本身的。所以文因互联的鲍捷博士有一个观点：项目的结构决定了项目团队的结构，项目的演化决定了项目团队的演化。在知识图谱中，形式化方法主要集中在本体设计上。关于本体，鲍捷博士认为“本体的设计是政治”，就是这个意思。进一步说，数理逻辑的类型论和范畴论，在实际的工程项目中，体现为类型系统的设计，也就是系统架构的设计。架构设计从来不是一个技术问题，而是管理问题，甚至是政治问题；对类型的理解，体现的是项目管理者对于项目的理解，而不是基层工程人员的理解。因此，形式化方法的应用，其实并不是一个简单的技术问题，而是涉及到工程项目全局的复杂的管理问题。

扯了这么多，好像有点偏题了。简单来说，基于统计的方法尽管难以解释，但是只要你投喂足够多足够好的数据，就会得到一个足够满意的模型。但基于形式化方法的方法尽管很靠谱，但它实际上是把许多技术上的问题转嫁到管理或者项目实施的其他环节上了。比较来看，谁也不比谁的代价小，但总的来看，还是机器学习显得更下里巴人一点。毕竟，没有什么问题，不能用一句`import tensorflow as tf`解决的（滑稽

工程师是驾驭复杂性的艺术家。人工智能便是典型的复杂问题，复杂到连“正确”的标准都没有，所以，又谈何“验证”呢。此外，正如最开始所说，从更高层次的世界观来看，确定性和非确定性，二者是同一个问题的不同方面。如果你读过薛定谔的《生命是什么》，对这个问题就会有充分的了解。

从更加功利的角度看，80%的业务只需要解决80%的问题就好了，因为它们活不到需要解决20%的那部分问题的那一天。但是从终极追求的角度看，形式化方法研究的是抽象结构，相比于启发式的人工神经网络研究，逻辑学更加闪耀着人作为“人”的荣耀之光。作为从复杂的物理结构中演化出的高层次知识，以逻辑学为代表的认知智能，是我们人类的终极财富。

毕竟，我们是能够思想的苇草，我们的全部价值就在于思想，我们并不甘心做复读机。

# 集体决策与阿罗不可能定理

> 2019年12月25日撰写。感谢 [@叶林葳蕤](https://www.zhihu.com/people/zui-jin-bu-xiang-chi-fan-l) 提供的有关阿罗不可能定理的资料。我简单地了解了一下，这似乎是一个很重要的规律，值得好好思考。

集体决策是很常见的事情，我也有一些参与集体决策的实践经验，也有一些自己总结的经验性的见解。下文呢，首先尝试总结一下这段资料的主要内容，当然，是基于我自己的理解。随后，基于刚刚学习到的不可能定理这一新知识，简单谈谈我对集体决策的一些见解。

## 1 资料总结

- 我把以下的内容归结为对寻找社会共同利益的技术性问题的探讨。
- 集体决策有多方面的意义：一是社会调查的意义，通过各种选举或者表决的手段，反映出群体对于某个问题的一致态度。一是集体决策本身具有道德上的正当性。
- 阿罗提出了若干个标准（条件），集体决策过程需要满足这些标准，才能产生出决策（即集体偏好），并且使作出的决策照顾到个体的偏好。
- 但，阿罗证明，满足这些标准的决策过程是不存在的。这称为阿罗不可能定理。
- 此定理并不否认集体偏好的存在，只是说找不到一种能够满足上述所有条件的决策过程。
- “事实证明”，去掉其中一个标准，就可以得到满足其余所有标准的决策规则。但是，选择去掉哪个规则，这是一个道德问题。
- “有人认为”，不可能定理表明，“民主制度要正常运行，要求人们的偏好是一致的。”
- 但这会形成一个悖论，即，为了使民主有效运行，必须采取某些专制手段，例如全民强制教育，以影响人们的偏好。
- 詹姆斯·布坎南认为，多数票规则有其有利的一面。正是因为达不成一致，所以才有机会在各种选择之间做试验，形成折中方案。
- 阿罗不可能定理动摇了社会福利函数的意义。社会福利函数可以认为是个人福利的加总。在民主社会中，社会福利函数的选择必须由集体决策，但不可能定理既然认为无法做出满足标准的“好”的决策，这就意味着在民主社会里社会福利函数可能并不存在。
- 基于此，有的经济学家认为，尽管不存在的社会福利函数无法用来确定资源配置，但是它可以用来解释各种价值判断的含义。

## 2 我的见解

我想抓住三个矛盾来谈谈自己的想法。一是公利与私利的矛盾，一是程序正义和实质正义的矛盾，一是民主和专政的矛盾。

**2.1 公利和私利的矛盾**

公利和私利必然存在矛盾，个体私利之间也存在尖锐的矛盾。经过简单了解，经济学上采用“偏好”这一概念来衡量选择组合及其依照排序的分布。集体决策的目的，就是为了找到一个能够反映出个人偏好的集体偏好，也就是“共识”。阿罗老师提出的几个条件，确实挺苛刻的，但无论怎么苛刻，都是在数学的层面上去探讨。实际解决问题时，不能陷入“真空中的球形鸡”的思维陷阱。

举个例子吧。日剧李狗嗨有一集，讲一个准妈妈苦于房子的采光被附近新建的高楼遮挡，在专业维权律师的怂恿下，与周围邻居一起集体起诉开发商，并提出了高额的集体赔偿条件。事实上除了这位准妈妈和少数真正在意采光问题的居民，其他所有人都只是抱着捞一笔的态度参与起诉。主角古美萌作为开发商聘请的律师，充分利用这一点，采取各种手段，分化瓦解集体起诉的居民，最终导致居民撤诉，不仅没有敲诈到开发商，准妈妈等真正有诉求的少数人，也没有得到合理的赔偿。

现实比电视剧更精彩。这个例子充分反映出个人利益和集体利益的矛盾。或者说，是更加尖锐的个人利益之间的矛盾。在这种情况下，极难做出集体决策。只有部分人甚至是多数人选择牺牲自己的利益，也就是做出让步或妥协，才可能做出集体决策。但这种决策可以称之为“共识”吗？

现实的集体决策实践中，妥协才是必不可少的常态，达成“共识”是奢侈的。

另一方面，决策的方式方法、程序，以及衡量集体决策结果好坏的标准，本身也是需要决策的内容。比如我国开大会，第一个决策便是对会议议程进行表决。这个问题就对应到上面的第5点和第9点——对于决策方式的决策，也就是“元决策”，本身就是妥协的产物。既然如此，集体决策真的能做出一个“最优”的决策吗？毕竟，连“最优”本身的标准是什么，大家都有不同意见，又谈何做出最优决策呢？

需要说明的是，“元决策”这一概念是我原创（见附录《感觉与决策》），但肯定不是首创。还请内行指点下严肃学术中对应的概念是什么。

**2.2 程序正义和实质正义的矛盾**

在我看来，民主和法治都是实现良政的手段。并不是只要有民主或法治就一定有良政，也并非凡是良政必然实行民主和法治。在这里，“良政”是典型的以结果论好坏的说法，它强调的是实质正义。

但这并不意味着程序正义就一无是处。实践中，一般情况下，如果程序正义得不到保障，则实质正义也很难实现。

话说回来，定义何为“正义”的行为，本身就带有正义性的疑问。前面说过，公共决策几乎不可能做到一碗水端平，总会有人做出妥协。因此，衡量良政与否的标准，本身就应当是一个共识。另一方面，公共决策的影响往往是长期的，短期内看不出好坏。因此，集体决策为了尽快形成对多数人有利的决策结果，往往功利而短视，甚至走向民粹主义。英国脱欧就是一个活生生的例子。如此重大、复杂、专业的议题，竟然简单地交由选民一人一票地去决定。在我看来，这是政客们极端不负责任的表现。政客不负责任，那么这责任只能转嫁到全体选民头上。毕竟，权力和责任是一致的。当然，正如第1节第8点所说，尽管决策成本很高，但是经过反复的振荡和折腾，总会调整到一个局部最优的状态。个中滋味，如人饮水，冷暖自知。

**2.3 民主和专政的矛盾**

> ——人民群众喜闻乐见，你不喜欢，你算老几？
——你给我开除出人民群众了？

如2.1所论述，形式上民主的集体决策，最后常常导致“多数人对少数人的专政”。

在实际操作中，首先，正如第1节第7点，少数人往往会采用各种或明或暗的手段（包括合法拉票、教育、传媒、金融等）去干预群体的偏好，从而操纵集体决策的结果。第二，人类作为一种社会性的动物，有慕强的天性，更进一步就是个人崇拜。这样的民主，本质上仍然是少数人对多数人的专政。这并不难以理解，例如，希特勒便是通过民主选举上台的。

所以，民主与专政，本质上是一体两面的矛盾集合体。正是考虑到这一点，我们选择了人民民主专政和民主集中制，在人民内部实行基于民主的集中和集中指导下的民主，对敌人实行专政。这样的制度设计，兼顾决策效率和决策效果，实践证明是好的。

2.2节阐述了程序正义和实质正义之间的关系。在21世纪的今天，毫无疑问，民主作为良政理想的具体寄托，无疑是好的、进步的东西。但是任何事情一旦陷入教条主义乃至陷入宗教般的迷信，就不是什么好东西。如今，民主在西方某些国家的糟糕实践，给民主抹上了一层阴影。那些变了味的“民主”，其实根本不是民主，只是用光鲜靓丽的仪式感，掩盖其少数人专政实质的把戏罢了。所以还是那句话，无论是民主还是专政，都是冷暖自知的事情，不可能有放之四海而皆准的套路。

----

2021年1月21日补充：

关于政治娱乐化的危害，大道理不说了，讲个昨天在A岛看到的[傻白甜克毒舌的故事](https://adnmb2.com/t/34045245)吧。

其实这是一种很有用的聊天技巧，可以有效化解尴尬和矛盾。这种技巧的本质是消解问题而不是解决问题。

在社会治理上，当然也可以通过这样的操作，把一个重大、严肃、复杂的公共议题，归结为选秀、投票、游行这样的骚操作，从而以掩盖问题而不是解决问题的方式，暂时掩盖矛盾。一通操作下来，没有人关心对二甲苯的LD50是多少，也没有人关心脱欧后的海产品价格，更没有人关注第三代核电和第二代核电的区别是什么。所有人，包括话事人在内的所有人，都只关心谁的嗓门大、谁的调门高、谁的主张听起来更牛逼。没有人想解决问题本身，没有人想真诚地寻求一致利益，最终陷入群体盲动。所有人都负责，最终一定会导致没有人负责。

唯一的好处就是，所有人都很满意，看哪，民主的价值被践行了，民主的优势被彰显了，众生人人平等，但民主的我们比“没有民主”的你们更平等，哈哈哈哈。

但五年后、十年后呢？只能说是如人饮水，冷暖自知。自己选的路，哭着笑着，都要走下去。

## 3 总结

集体决策是个实践问题，它绝不应该仅仅停留在学者的空谈和看似巧妙的数学模型中。选举民主只是提供了一种程序上合理、结果也相对容易达成共识的集体决策方案，但这并非唯一的方案。至于何为最佳的方案，如果仅仅是从理想模型的角度看，依据阿罗不可能定理，似乎是不存在的；但集体决策毕竟是个实践性的问题，它应该用更为开放和灵活的态度去看待，具体问题具体分析，绝不能拘泥于空泛的东西。就像是穿秋裤，你的腿凉不凉，你妈不知道，你自己也未必知道。只有自己穿上秋裤试一试，才知道冷不冷、热不热，到那时，这秋裤是穿还是脱，你的心里就有数了。

以上是我这个外行人的一点不成熟的小观点，还请方家指正。

## 附短文 感觉与决策

> 此文撰写于 2019-09-05

今天下班回家，发现昨天吃剩下的鱼散发出浓郁的气味。因为晾在外面的时间比较短，所以这种气味从主观上来讲应该是一种介于“香”和“臭”之间的气味。

那么生物对于“香”和“臭”的主观感受的本质，究竟是什么呢？

蛋白质是最主要的生物物质，它降解后的产物比较复杂，有氨基酸，也有各种小分子胺类。氨基酸是构建蛋白质的基本成分，也是营养成分。但是小分子胺大多数有浓郁的臭味，对生物体是有毒的。

无论是氨基酸也好，还是小分子胺类也好，它们在被闻到或者尝到之前，是无所谓“气味”和“味道”的。但是有一个逻辑十分显然，那就是对人有利的物质，往往有令人愉悦的“味”，例如糖类的甜味，谷氨酸的鲜味，等等；而对人有害的物质，往往有令人不适的气味，例如硫化氢、胺类等。当然这并不是绝对的，但我们更感兴趣的是，为什么是这样？

人吃进去食物，代谢吸收一部分，另一部分变成屎尿屁被排出去。有人可能会想，为什么人不会去吃自己的屎尿屁呢？当然是因为不好吃。但这并非根本原因，只能说是长期进化后得到的一个果。

那么，人之所以不吃屎，是因为屎真的没什么营养，甚至有毒。这是容易理解的。食物以高能状态进入人体，经过复杂的消化和代谢，截留了食物中的大部分能量。剩下的食物残渣，都是无法利用的低能物质，以及有毒有害的代谢废物，自然不能吃。最初可能有一些早期的生物尝试吃自己的屎尿屁，但是这些蠢货都被淘汰掉了。经过长期的进化，生物的基因中以某种（分布式的）形式记录下了这一重要的信息：屎里有毒，不能吃！体现在感觉上，就是色香味俱差的感官体验了。这套逻辑总结起来就是：屎不是因为难吃而不能吃，而是因为它真的有毒，所以生物演化出“不好吃”这种感觉，以**控制**自己不去吃屎。

思考到这里，终于出现了一个词：控制。生物是具有趋利避害本能的，即便是草履虫这样简单的生物，都可以在受到刺激的时候尝试躲避。这就是所谓的应激性。如果从控制论的角度来理解，趋利避害行为就是一个典型的控制环路。即便高等如人类，也具有类似的本能。当然人类具有发达的神经系统和脑，许多复杂的控制环路被抽象成“感觉”或称“反射”，许多复杂的感觉被抽象成“经验”，许多复杂的经验被抽象成“价值观”。无论位于哪个抽象层次，本质上都是趋利避害的控制环路。那么回到吃屎这个问题上，小孩子在没有大人教的时候，很有可能把自己的屎尿屁塞进嘴里去，但他发现粑粑并不好吃，并把它吐了出来，这就是“因为屎不好吃，所以不能吃”的控制环路的冷启动。进而，随着人生阅历的丰富，他会逐渐学到更多诸如“不要在说话的时候带‘屎尿屁’”这类更为复杂、更为抽象的规则，并形成了一套被称为“文明”的价值体系。人们在感觉、经验和价值观的指导下行事、做出决策、趋利避害，那么这些先天或者后天形成的感觉、经验、价值观，就是这套控制环路背后的规则，或者说这套控制环路的模式、“传递函数”。

因此，我们是否可以认为，“感觉”的本质就是某种控制模式的主观体验呢？

我们说一个系统是自适应的，是指这个系统可以利用过去的经验去修正自己的“传递函数”，其实就是学习控制模式的能力。比如一个青年在被渣男或者绿茶伤害到之后，就会积极地调整自己的择偶标准；一个群体中吃屎的都被淘汰之后，整个群体的基因库中也便留下了“屎不好吃”的群体记忆。对控制环路本身的控制，形成了不同层次上的“控制”。所有的这一切层次上的控制模式综合起来，构成一个复杂的、无法预测的动力系统。所以我们说“顺其自然”，或许是有一些道理的。因为在一些复杂问题上，即便经过（在信息不完全的情况下的）充分论证思考过后做出的决策，或许还不如隐藏在你脑内几百亿神经元中的“感觉”来得可靠呢。从更高的群体决策的层次来说，无论是“民主”还是“集中”，都未必能实现最优的决策，所以我们选择“民主集中”，在两种极端情况之间寻求平衡。你看，对议事规则和决策制度的选择，这又成了一个“元决策”问题。

伟人的那句话是怎么说的，人呐，就都不知道，自己也不可以预料。我昨天吃了一条鱼，怎么今天就在这里大谈屎尿屁呢？

所以说啊，无论是一个人也好，还是一个群体也好，只有及时适应环境、主动自我革命，才能生存下去。只靠脑子里固有的东西机械地活着，是看不到未来的。

# 语义网和数据产权

2019-03-01

针对互联网的中心化和垄断化趋势，Web发明者 Tim Berners-Lee 启动了SoLiD项目，旨在从根本上改变Web应用的中心化趋势，真正让数据所有权回归用户，并改善隐私问题。2018年，Berners-Lee创立了Inrupt以支持Solid的发展。它的根本目的是：

- 实现数据的Web可访问和语义化
- 将数据存储与数据应用解耦

SoLiD并不仅仅是一门技术，而是一项关于数据资源所有制改革的理念，进而技术性地决定了数据产权这一问题的解决方案。

## 数据产权迷局

目前的Web呈现出中心化趋势，即Web服务所需要的数据很大程度上封闭于服务提供商内部，本来是由用户所产出和寄存的数据，用户却没有足够的处置权利，也就是说，数据资产的权属分配，目前来看是一团糟，并且正朝着对终端用户不利的方向发展。

最典型的例子是游戏。例如，我本人也算是资深的奇迹暖暖玩家了，两年下来倾注了大量的心血在女儿身上，也小氪了一些钱在上面。但是，iOS和Android的游戏账号，是互不相通的。这就导致在换手机的时候，同样属于我自己的游戏账号，却连数据迁移这一基本需求都得不到满足。尽管这一点已经在服务协议中明确指明，但是我们作为用户，仍然有足够的理由去质疑这一条款的合理性：我们投入时间和精力所生产的数据，究竟属于谁？

另一方面，由于数据被封闭在提供服务的平台内部，导致大量的数据被吞噬进平台，进而使整个Web被巨头割裂成一个个数据孤岛。平台间长期的隔绝，使得Web数据的强语义互联几乎成为不可能。这样的例子有很多，最典型的就是BAT三家的数据完全不互通，例如百度无法爬取微信、QQ空间和淘宝的大量信息，淘宝商品无法通过腾讯系产品直接分享，腾讯微信公众号积累的内容彻底封闭在微信内部，小程序的推广更加深了这一趋势。长此以往，各大平台所积累的海量数据已经完全无法互通，甚至无法与平台外的Web互通。

平台数据割裂，直接体现在接口协议和权限的割裂。这里指的割裂，不是指HTTP、JSON、OAuth2这些基础设施层面上的割裂，而是接口语义的割裂。例如，在理想状态下，对于“好友关系”这类数据，对于所有社交服务来说都应当是语义同构的，即共享同一套基础本体。但目前的现实情况是，不同应用之间的同类数据，几乎不能互通。例如，如果我打算将我的所有好友关系从QQ迁移到微信，那么除了一个一个地手动添加好友之外，并没有其他更方便的方法。而从技术角度讲，这种好友关系迁移，应当是可行的。

因此，总结下来，现有的问题是：一是数据的权属问题并不清晰，用户对数据的控制权远远不够。二是由于数据孤岛的存在，数据的互联互通程度和语义化程度还非常低。这两个问题，本质上都是由于数据的产权不够清晰。

## 语义隔离和数据垄断

平台圈地自萌，数据垄断私有，接口遍地开花，语义关联割裂

数据割裂→社区割裂→文化割裂→鄙视链形成

小的数据孤岛→死数据

大的数据孤岛→僵尸数据

## SoLiD的愿景和技术路线

SoLiD的愿景是将数据和服务解耦，还数据于人民，终结平台垄断数据资源圈地自萌进而胡作非为的乱象。例如：我的通讯录保存在互联网的某处（即SoLiD所说的POD），我对这些数据具有完全的访问权限。在使用某项应用时，比如微信，我就可以将我的数据授权给微信，由微信对我的数据进行访问、修改和维护。由于我对于我的个人数据具有完全的权限，因此任何应用对我的数据所做的任何读写访问操作，都在我的监控之下，都需要经过我的授权，并且，我有权利随时停止授权，并任意处置我的数据。

数据与应用解耦，还数据于人民，这样众多应用就需要从用户的手中去“租借”数据，迫使服务提供商更多地从语义互通的角度去设计自己的系统乃至业务本身，这对于实现真正的“语义网”当然是有益处的。同时，也更加有利于研究人员和其他相关人员合法合规地、体面地、透明地、便利地获取数据，而不必陷入到爬虫和反爬的攻防战中。

## 对SoLiD的批判

从技术的角度讲，SoLiD非常依赖RDF这样的语言。从我个人的观点和经验来看，我认为RDF和OWL都显得过于学究气、过于重量级了，它们在实验室里玩玩也就算了，并不适合作为大语义网的基础设施。我一直认为，所谓的“语义网”，与其说是一门技术体系，不如说是一个愿景。想要实现彻底的语义化，是不可能的。我们应当容许非语义化、非结构化数据的存在。一方面是难以语义化的内容，例如抖音上的无数短视频，目前来看是几乎不可能彻底语义化的，当然，也没有必要。另一方面是大量的垃圾信息和噪声。所谓的噪声，是相对于有用信息而言的。但是区分“有用”和“无用”的标准，却是不确定的。因此噪声是个很主观的概念，我们拿到数据以后，一方面要按需处理数据，另一方面，看似是噪声的数据，可能隐藏着更加抽象的信息，只是暂时无法被挖掘出来而已。例如“小明竟然考了一百分”这句话，如果抽取成三元组的话，显然损失了“竟然”这个词背后体现的背景信息和情感信息。过分追求Web的语义化，某种程度上是信息的损失。

我简单了解了下SoLiD，不愧是Web之父的大作。在Web中，URI可以指代万事万物，但现实中，URI其实真的不好用。或者说，URI就像是C语言的指针，它是Web的基础设施，但大家每天都在上层应用上工作，把URI暴露给用户就显得很不友好。例如我打算关注你的微博，你只要告诉我你的微博名就可以了，不需要提供给我一长串形如“https://weibo.com/u/xxxxx”的URI。再例如，像微信这种更加封闭的平台，甚至完全感受不到URI的存在，我甚至怀疑微信是否是脱离了Web体系，直接在HTTP或者更低层次的协议上运作的。而SoLiD的POD不仅特别突出URI的地位，甚至把SPARQL和RDF暴露给用户，这让我感觉非常反胃。

从思想或者是愿景的角度讲，如果真的走向了数据完全由个人控制的极端，那么互联网的价值将完全崩溃。凡事都是过犹不及。例如基于大数据的推荐，推荐系统本质上是在不严重侵犯用户隐私的前提下，利用技术手段揣测用户隐私的行为，在长期的博弈中，目前看来已经形成了一种微妙的平衡。但一旦数据被用户完全控制，则“大数据”无法被算法获得，也就无法为用户提供更优质的服务。

将数据完全归还个人，实际上是造成了更严重、更广泛的数据孤岛。再例如，诸如蚂蚁信用一类的社会信用机制，根据基础信息、消费记录、征信记录等多来源、多模态的数据，共同计算出一个人的信用评级，进而建立起信用体系。如果数据完全由个人自有，那么很显然，这是不可能实现的。有潜力实现互联互通的数据，也变得不可互通了，进而降低了整个网络的语义化程度。所谓的大数据，也就彻底成了失去关联的噪声数据。

无论知识孤岛发生在平台和用户的哪一方，都是对Web的损害，都是不合理的数据权属分配。

幸而数据完全由个人自有是不可能实现的。区块链是数据体系去中心化的一次尝试，但是结合上面的论述，（原教旨的）完全分布式的鉴权方式，何尝不是另一种形式的大中心化呢？现在的网络的发展趋势是全面云化，云化，实际上就是计算、存储、平台的集中化。任何事情都可以通过上云的形式，被抽象成服务去对外提供，也就是所谓的XaaS。进一步讲，即便SoLiD有POD这种东西，但是POD实际上是被抽象成服务提供给个人的。个人实际上并没有对于POD的真正的控制权。更进一步讲，即便服务器乃至机房都归属于个人，基础通信网络总归是个人无法控制的。总而言之，SoLiD的愿景，并不仅仅是仅通过技术手段就可以实现的。

## 对数据产权制度的思考

数据与应用解耦的思想并不新颖，SoLiD也只是提供了在现有Web规范和技术体系的基础上，实现其愿景的另一套技术方案和设施。从近期的种种迹象可以看出，Web已经进入了“帝国主义”阶段，进入了强者愈强、大平台虹吸小平台资源的阶段。大平台为了巩固垄断地位，必定会采取更多的超越技术的手段，以维护自身利益。数据是信息时代最核心的资产，谁拥有数据，谁就拥有了强大的战斗力。所以在目前的形势下，仅凭SoLiD等技术手段去扭转这一趋势，是非常难以实现的。数据资源垄断是一个历史问题、商业问题乃至政治问题，因此也必然要在历史、商业和政治的维度上去解决。

尽管如此，Web仍然是承载海量数据的底层基础设施。Web的初心就是为了使信息在通信网络上自由流通，因此解决数据垄断问题，除了采用各种手段进行干预之外，更需要的是时间。Web天然就是开放的，待发展阶段到位，自然会逐渐从封闭走向开放。

GDPR、隐私保护，距离数据产权体系还很远

数据的价值和地位，数据产权与其他权利的关系

GitHub，不能矫枉过正地剥夺企业的权利

产权如何确认和维护，纠纷如何解决，技术手段和制度手段

## Web语义化的历史规律和前景

数据资源所有制改革，对于推进AI发展将有重大意义，从而促进其他领域的变革和改革

数据是人民群众历史性地生产出来的数字产品，Web负责承载数据和服务，而平台通过提供服务去富集和挖掘数据。同时，积累有更多数据的服务，将更有机会富集到更多的数据。

从知识工程从业者的角度看，平台不仅仅是数据的搬运工，平台还承担着从数据中挖掘隐藏的模式和关联，这实际上就是数据的语义化和再生产。因此，集中化平台的存在，并不意味着完全的割裂，相反，适度的集中化，实际上是最有利于整个互联网的语义互通的。

像SoLiD这样的技术，试图扭转互联网的过度集中化趋势。这是一场革命，革命是需要付出代价的，但革命的收益也是巨大的。在这个过程中，一方面SoLiD会降解掉平台内部已经形成的语义结构，导致信息的损失、资源的浪费；但另一方面，通过对数据资源的权属再分配和新语义体系的重建，形成既有集中又有分布、既有全局语义化又容许局部非结构化、既有高度领域分化又有普适通用本体的新互联网，形成更大规模、更加通用的大语义Web。这是一个螺旋上升的过程，或许不会由任何个人或组织推动，而是由Web内部蕴含的自组织性所推动。

数据产权制度一方面由Web的发展程度所决定，另一方面又会影响到Web发展的走向。无论如何，实现数据互联互通、高效利用数据、通过语义化助推信息生产力的大发展，进而全面地提高人类驾驭复杂系统和海量信息的能力，直至实现强人工智能，是人类一直以来的梦想。实现这一梦想，需要依靠的不仅仅是诸如SoLiD的技术，更需要有技术以外的因素。厘清数据产权，解决好数据资源所有制问题，是人类能动地实现这一梦想的必经之路。

# 人工智能的局限性

![ ](./image/G4/揶揄人工智能-1.jpg)

![ ](./image/G4/揶揄人工智能-2.jpg)

![ ](./image/G4/揶揄人工智能-3.jpg)

![ ](./image/G4/揶揄人工智能-4.jpg)

![ ](./image/G4/揶揄人工智能-5.jpg)

![ ](./image/G4/prompt-generated-miku.jpg)
